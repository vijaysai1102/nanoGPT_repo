{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/nanoGPT_results\"\n",
        "!mkdir -p \"$SAVE_DIR\"\n",
        "\n",
        "print(\"Results will be saved to:\", SAVE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlHTgYmLAL7T",
        "outputId": "f2aa3243-9d95-47d3-c36e-f16b83a81c06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Results will be saved to: /content/drive/MyDrive/nanoGPT_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/karpathy/nanoGPT.git\n",
        "%cd nanoGPT\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install tqdm numpy requests matplotlib ninja\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVLVTgBRMoWc",
        "outputId": "97ef07c8-f8a3-42c5-c580-0c6938413351"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 686, done.\u001b[K\n",
            "remote: Total 686 (delta 0), reused 0 (delta 0), pack-reused 686 (from 1)\u001b[K\n",
            "Receiving objects: 100% (686/686), 974.06 KiB | 7.73 MiB/s, done.\n",
            "Resolving deltas: 100% (380/380), done.\n",
            "/content/nanoGPT\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data/shakespeare_char\n",
        "!python prepare.py\n",
        "%cd ../..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8_63N5xMoYp",
        "outputId": "9fe3b838-b6d3-4661-a403-8330ec88fe24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nanoGPT/data/shakespeare_char\n",
            "length of dataset in characters: 1,115,394\n",
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n",
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n",
            "/content/nanoGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_experiments.py\n",
        "import os, sys, itertools, subprocess, re, csv, time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "SAVE_DIR = os.environ.get(\"SAVE_DIR\", \"/content/drive/MyDrive/nanoGPT_results\")\n",
        "\n",
        "# Full Hyperparameter Grid\n",
        "BLOCK_SIZES = [64, 128]\n",
        "N_LAYERS = [4, 6]\n",
        "N_HEADS = [4, 8]\n",
        "N_EMBDS = [128, 256]\n",
        "BATCH_SIZES = [8, 16]\n",
        "MAX_ITERS = [1000, 2000]\n",
        "DROPOUTS = [0.1, 0.2]\n",
        "\n",
        "# Member → fixed hyperparams\n",
        "MEMBER_MAP = {\n",
        "    1: (64, 4),\n",
        "    2: (64, 6),\n",
        "    3: (128, 4),\n",
        "    4: (128, 6),\n",
        "}\n",
        "\n",
        "CONFIG_TEMPLATE = r\"\"\"\n",
        "out_dir = \"{save_dir}/{out_name}\"\n",
        "dataset = \"shakespeare_char\"\n",
        "eval_interval = 200\n",
        "log_interval = 10\n",
        "always_save_checkpoint = True\n",
        "\n",
        "batch_size = {batch_size}\n",
        "block_size = {block_size}\n",
        "n_layer = {n_layer}\n",
        "n_head = {n_head}\n",
        "n_embd = {n_embd}\n",
        "dropout = {dropout}\n",
        "\n",
        "learning_rate = 3e-4\n",
        "max_iters = {max_iters}\n",
        "lr_decay_iters = {max_iters}\n",
        "\n",
        "seed = {seed}\n",
        "device = \"{device}\"\n",
        "\n",
        "num_workers = 0\n",
        "compile = False\n",
        "\"\"\"\n",
        "\n",
        "def list_experiments(member_id):\n",
        "    block_size, n_layer = MEMBER_MAP[member_id]\n",
        "    grid = list(itertools.product(N_HEADS, N_EMBDS, BATCH_SIZES, MAX_ITERS, DROPOUTS))\n",
        "    exps = []\n",
        "    for seed, (nh, ne, bs, mi, do) in enumerate(grid, 1):\n",
        "        out_name = f\"b{block_size}_L{n_layer}_H{nh}_E{ne}_BS{bs}_MI{mi}_D{int(do*100)}_s{seed}\"\n",
        "        exps.append({\n",
        "            \"block_size\": block_size, \"n_layer\": n_layer,\n",
        "            \"n_head\": nh, \"n_embd\": ne,\n",
        "            \"batch_size\": bs, \"max_iters\": mi,\n",
        "            \"dropout\": do, \"seed\": seed,\n",
        "            \"out_name\": out_name\n",
        "        })\n",
        "    return exps\n",
        "\n",
        "def parse_losses(stdout_line):\n",
        "    m = re.search(r\"train loss ([0-9.]+).*val loss ([0-9.]+)\", stdout_line)\n",
        "    if m:\n",
        "        return float(m.group(1)), float(m.group(2))\n",
        "    return None, None\n",
        "\n",
        "def extract_model_params(logtext):\n",
        "    m = re.search(r\"number of parameters:\\s*([0-9.]+)M\", logtext)\n",
        "    if m:\n",
        "        return float(m.group(1)) * 1e6\n",
        "    return None\n",
        "\n",
        "def run_training(cfg, device):\n",
        "    cfg_file = Path(f\"{cfg['out_name']}.py\")\n",
        "    cfg_file.write_text(CONFIG_TEMPLATE.format(**cfg, save_dir=SAVE_DIR, device=device))\n",
        "\n",
        "    p = subprocess.Popen(\n",
        "        [\"python\", \"train.py\", str(cfg_file)],\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "    )\n",
        "\n",
        "    train_loss = None\n",
        "    val_loss = None\n",
        "    param_count = None\n",
        "    log_buf = \"\"\n",
        "\n",
        "    for line in p.stdout:\n",
        "        print(line, end=\"\")\n",
        "        log_buf += line\n",
        "        tl, vl = parse_losses(line)\n",
        "        if tl is not None:\n",
        "            train_loss, val_loss = tl, vl\n",
        "\n",
        "        if param_count is None:\n",
        "            param_count = extract_model_params(log_buf)\n",
        "\n",
        "    p.wait()\n",
        "    loss_gap = val_loss - train_loss if train_loss and val_loss else None\n",
        "    return train_loss, val_loss, loss_gap, param_count, cfg_file\n",
        "\n",
        "def main():\n",
        "    member_id = int(sys.argv[1])\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    result_csv = Path(SAVE_DIR) / \"results.csv\"\n",
        "    if not result_csv.exists():\n",
        "        with open(result_csv, \"w\") as f:\n",
        "            csv.writer(f).writerow([\n",
        "                \"Experiment\",\n",
        "                \"Train Loss\",\n",
        "                \"Val Loss\",\n",
        "                \"Loss Gap\",\n",
        "                \"Total Params\",\n",
        "                \"Config Path\"\n",
        "            ])\n",
        "\n",
        "    exps = list_experiments(member_id)\n",
        "    print(f\"Running {len(exps)} experiments for Member {member_id}\")\n",
        "\n",
        "    for i, exp in enumerate(exps, 1):\n",
        "        print(f\"\\n=== Experiment {i}/{len(exps)}: {exp['out_name']} ===\")\n",
        "        tr, vl, gap, params, cfg_path = run_training(exp, device)\n",
        "\n",
        "        with open(result_csv, \"a\") as f:\n",
        "            csv.writer(f).writerow([\n",
        "                exp[\"out_name\"], tr, vl, gap, params, str(cfg_path.resolve())\n",
        "            ])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXxVcystMobA",
        "outputId": "a29ea839-fc76-4966-8bb6-9c23f525a176"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_experiments.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SAVE_DIR\"] = SAVE_DIR\n"
      ],
      "metadata": {
        "id": "g5fizIjDModg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_experiments.py 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNIe63wtMog5",
        "outputId": "a36a49bb-e702-4cc0-8bf9-2d43eaef0a99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "iter 1440: loss 2.0077, time 333.80ms, mfu 0.19%\n",
            "iter 1450: loss 2.0032, time 330.85ms, mfu 0.19%\n",
            "iter 1460: loss 2.0561, time 334.39ms, mfu 0.19%\n",
            "iter 1470: loss 2.0435, time 332.94ms, mfu 0.19%\n",
            "iter 1480: loss 2.0185, time 339.24ms, mfu 0.19%\n",
            "iter 1490: loss 2.0510, time 339.46ms, mfu 0.20%\n",
            "iter 1500: loss 2.0001, time 331.83ms, mfu 0.20%\n",
            "iter 1510: loss 1.9322, time 332.76ms, mfu 0.20%\n",
            "iter 1520: loss 2.0687, time 346.77ms, mfu 0.20%\n",
            "iter 1530: loss 2.1293, time 330.32ms, mfu 0.20%\n",
            "iter 1540: loss 1.9811, time 331.14ms, mfu 0.20%\n",
            "iter 1550: loss 2.0159, time 332.54ms, mfu 0.20%\n",
            "iter 1560: loss 1.9273, time 331.55ms, mfu 0.20%\n",
            "iter 1570: loss 1.9883, time 328.13ms, mfu 0.20%\n",
            "iter 1580: loss 2.0048, time 329.16ms, mfu 0.20%\n",
            "iter 1590: loss 1.9918, time 346.00ms, mfu 0.20%\n",
            "step 1600: train loss 1.8402, val loss 1.9423\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E128_BS16_MI2000_D20_s8\n",
            "iter 1600: loss 1.9252, time 1690.66ms, mfu 0.18%\n",
            "iter 1610: loss 2.0581, time 335.17ms, mfu 0.19%\n",
            "iter 1620: loss 1.9112, time 335.64ms, mfu 0.19%\n",
            "iter 1630: loss 2.0017, time 327.16ms, mfu 0.19%\n",
            "iter 1640: loss 1.9393, time 333.48ms, mfu 0.19%\n",
            "iter 1650: loss 1.9485, time 327.79ms, mfu 0.19%\n",
            "iter 1660: loss 1.8974, time 333.91ms, mfu 0.19%\n",
            "iter 1670: loss 1.9079, time 327.36ms, mfu 0.20%\n",
            "iter 1680: loss 1.8130, time 332.90ms, mfu 0.20%\n",
            "iter 1690: loss 1.9351, time 333.63ms, mfu 0.20%\n",
            "iter 1700: loss 1.8822, time 331.11ms, mfu 0.20%\n",
            "iter 1710: loss 1.8853, time 325.28ms, mfu 0.20%\n",
            "iter 1720: loss 1.9792, time 335.68ms, mfu 0.20%\n",
            "iter 1730: loss 1.9165, time 344.62ms, mfu 0.20%\n",
            "iter 1740: loss 1.9018, time 331.24ms, mfu 0.20%\n",
            "iter 1750: loss 1.9148, time 332.69ms, mfu 0.20%\n",
            "iter 1760: loss 1.9599, time 332.24ms, mfu 0.20%\n",
            "iter 1770: loss 1.8524, time 336.97ms, mfu 0.20%\n",
            "iter 1780: loss 1.9538, time 337.47ms, mfu 0.20%\n",
            "iter 1790: loss 1.8386, time 346.64ms, mfu 0.20%\n",
            "step 1800: train loss 1.7548, val loss 1.9007\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E128_BS16_MI2000_D20_s8\n",
            "iter 1800: loss 1.9345, time 1751.92ms, mfu 0.18%\n",
            "iter 1810: loss 1.8969, time 336.26ms, mfu 0.19%\n",
            "iter 1820: loss 2.0012, time 338.81ms, mfu 0.19%\n",
            "iter 1830: loss 1.9326, time 338.06ms, mfu 0.19%\n",
            "iter 1840: loss 1.8059, time 344.21ms, mfu 0.19%\n",
            "iter 1850: loss 1.7972, time 336.55ms, mfu 0.19%\n",
            "iter 1860: loss 1.8848, time 336.33ms, mfu 0.19%\n",
            "iter 1870: loss 1.7972, time 337.20ms, mfu 0.19%\n",
            "iter 1880: loss 1.8699, time 335.12ms, mfu 0.19%\n",
            "iter 1890: loss 1.8044, time 337.46ms, mfu 0.19%\n",
            "iter 1900: loss 1.8484, time 341.76ms, mfu 0.19%\n",
            "iter 1910: loss 1.9168, time 347.49ms, mfu 0.19%\n",
            "iter 1920: loss 1.8377, time 339.23ms, mfu 0.20%\n",
            "iter 1930: loss 1.8499, time 342.64ms, mfu 0.20%\n",
            "iter 1940: loss 1.8359, time 349.74ms, mfu 0.20%\n",
            "iter 1950: loss 1.8790, time 336.92ms, mfu 0.20%\n",
            "iter 1960: loss 1.8500, time 343.03ms, mfu 0.20%\n",
            "iter 1970: loss 1.9367, time 339.56ms, mfu 0.20%\n",
            "iter 1980: loss 1.8006, time 343.51ms, mfu 0.20%\n",
            "iter 1990: loss 1.8471, time 335.39ms, mfu 0.20%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 9/32: b64_L4_H4_E256_BS8_MI1000_D10_s9 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS8_MI1000_D10_s9.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D10_s9\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 9\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2853, val loss 4.2801\n",
            "iter 0: loss 4.3034, time 1905.42ms, mfu -100.00%\n",
            "iter 10: loss 4.2172, time 316.77ms, mfu 0.41%\n",
            "iter 20: loss 4.0957, time 310.25ms, mfu 0.41%\n",
            "iter 30: loss 3.8559, time 320.27ms, mfu 0.41%\n",
            "iter 40: loss 3.6711, time 330.71ms, mfu 0.41%\n",
            "iter 50: loss 3.5999, time 314.57ms, mfu 0.41%\n",
            "iter 60: loss 3.5084, time 315.36ms, mfu 0.41%\n",
            "iter 70: loss 3.4219, time 314.52ms, mfu 0.41%\n",
            "iter 80: loss 3.4448, time 316.10ms, mfu 0.41%\n",
            "iter 90: loss 3.2085, time 315.88ms, mfu 0.41%\n",
            "iter 100: loss 3.0935, time 315.80ms, mfu 0.41%\n",
            "iter 110: loss 3.0007, time 318.53ms, mfu 0.41%\n",
            "iter 120: loss 3.0133, time 323.50ms, mfu 0.41%\n",
            "iter 130: loss 2.9677, time 325.23ms, mfu 0.41%\n",
            "iter 140: loss 2.8436, time 317.71ms, mfu 0.41%\n",
            "iter 150: loss 2.8332, time 320.90ms, mfu 0.41%\n",
            "iter 160: loss 2.7623, time 321.12ms, mfu 0.41%\n",
            "iter 170: loss 2.7862, time 321.34ms, mfu 0.41%\n",
            "iter 180: loss 2.8696, time 320.57ms, mfu 0.41%\n",
            "iter 190: loss 2.7439, time 315.37ms, mfu 0.41%\n",
            "step 200: train loss 2.6753, val loss 2.6884\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 200: loss 2.7695, time 1614.70ms, mfu 0.37%\n",
            "iter 210: loss 2.6771, time 315.27ms, mfu 0.38%\n",
            "iter 220: loss 2.5706, time 315.38ms, mfu 0.38%\n",
            "iter 230: loss 2.6663, time 310.77ms, mfu 0.39%\n",
            "iter 240: loss 2.6594, time 313.87ms, mfu 0.39%\n",
            "iter 250: loss 2.6079, time 316.48ms, mfu 0.39%\n",
            "iter 260: loss 2.6880, time 318.61ms, mfu 0.39%\n",
            "iter 270: loss 2.4497, time 310.28ms, mfu 0.39%\n",
            "iter 280: loss 2.5806, time 309.83ms, mfu 0.40%\n",
            "iter 290: loss 2.6016, time 321.12ms, mfu 0.40%\n",
            "iter 300: loss 2.5310, time 321.31ms, mfu 0.40%\n",
            "iter 310: loss 2.4873, time 319.58ms, mfu 0.40%\n",
            "iter 320: loss 2.5575, time 319.22ms, mfu 0.40%\n",
            "iter 330: loss 2.4142, time 318.81ms, mfu 0.40%\n",
            "iter 340: loss 2.5028, time 338.38ms, mfu 0.40%\n",
            "iter 350: loss 2.4591, time 313.67ms, mfu 0.40%\n",
            "iter 360: loss 2.3574, time 313.88ms, mfu 0.40%\n",
            "iter 370: loss 2.4168, time 315.82ms, mfu 0.40%\n",
            "iter 380: loss 2.3268, time 314.15ms, mfu 0.40%\n",
            "iter 390: loss 2.4598, time 314.12ms, mfu 0.40%\n",
            "step 400: train loss 2.3618, val loss 2.3793\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 400: loss 2.4226, time 1623.57ms, mfu 0.37%\n",
            "iter 410: loss 2.3062, time 326.22ms, mfu 0.37%\n",
            "iter 420: loss 2.4341, time 311.14ms, mfu 0.38%\n",
            "iter 430: loss 2.2826, time 312.77ms, mfu 0.38%\n",
            "iter 440: loss 2.3929, time 308.55ms, mfu 0.39%\n",
            "iter 450: loss 2.4668, time 319.82ms, mfu 0.39%\n",
            "iter 460: loss 2.3581, time 313.95ms, mfu 0.39%\n",
            "iter 470: loss 2.3487, time 312.69ms, mfu 0.39%\n",
            "iter 480: loss 2.3281, time 312.12ms, mfu 0.40%\n",
            "iter 490: loss 2.3163, time 320.33ms, mfu 0.40%\n",
            "iter 500: loss 2.3210, time 313.88ms, mfu 0.40%\n",
            "iter 510: loss 2.2429, time 314.50ms, mfu 0.40%\n",
            "iter 520: loss 2.2757, time 315.47ms, mfu 0.40%\n",
            "iter 530: loss 2.3115, time 316.98ms, mfu 0.40%\n",
            "iter 540: loss 2.2465, time 314.68ms, mfu 0.40%\n",
            "iter 550: loss 2.1514, time 323.66ms, mfu 0.40%\n",
            "iter 560: loss 2.2810, time 314.76ms, mfu 0.40%\n",
            "iter 570: loss 2.1416, time 311.93ms, mfu 0.40%\n",
            "iter 580: loss 2.2534, time 312.70ms, mfu 0.41%\n",
            "iter 590: loss 2.1647, time 311.64ms, mfu 0.41%\n",
            "step 600: train loss 2.1150, val loss 2.1423\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 600: loss 2.1785, time 1655.07ms, mfu 0.37%\n",
            "iter 610: loss 2.2581, time 316.17ms, mfu 0.38%\n",
            "iter 620: loss 2.2488, time 306.16ms, mfu 0.38%\n",
            "iter 630: loss 2.2699, time 313.00ms, mfu 0.39%\n",
            "iter 640: loss 2.1474, time 317.26ms, mfu 0.39%\n",
            "iter 650: loss 2.1381, time 315.77ms, mfu 0.39%\n",
            "iter 660: loss 2.1198, time 314.95ms, mfu 0.39%\n",
            "iter 670: loss 2.1889, time 314.82ms, mfu 0.39%\n",
            "iter 680: loss 2.0746, time 314.30ms, mfu 0.40%\n",
            "iter 690: loss 2.0667, time 316.92ms, mfu 0.40%\n",
            "iter 700: loss 2.0982, time 314.30ms, mfu 0.40%\n",
            "iter 710: loss 1.9845, time 320.05ms, mfu 0.40%\n",
            "iter 720: loss 2.0496, time 312.87ms, mfu 0.40%\n",
            "iter 730: loss 2.0819, time 313.02ms, mfu 0.40%\n",
            "iter 740: loss 2.0219, time 309.90ms, mfu 0.40%\n",
            "iter 750: loss 1.9833, time 328.30ms, mfu 0.40%\n",
            "iter 760: loss 2.0363, time 319.38ms, mfu 0.40%\n",
            "iter 770: loss 1.9554, time 318.67ms, mfu 0.40%\n",
            "iter 780: loss 1.9951, time 318.85ms, mfu 0.40%\n",
            "iter 790: loss 2.1353, time 318.63ms, mfu 0.40%\n",
            "step 800: train loss 1.9189, val loss 1.9882\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 800: loss 2.1129, time 1628.84ms, mfu 0.37%\n",
            "iter 810: loss 2.0982, time 313.50ms, mfu 0.38%\n",
            "iter 820: loss 1.9311, time 322.97ms, mfu 0.38%\n",
            "iter 830: loss 1.9434, time 312.81ms, mfu 0.38%\n",
            "iter 840: loss 1.9609, time 313.31ms, mfu 0.39%\n",
            "iter 850: loss 1.9527, time 318.88ms, mfu 0.39%\n",
            "iter 860: loss 1.9399, time 315.21ms, mfu 0.39%\n",
            "iter 870: loss 2.0771, time 318.19ms, mfu 0.39%\n",
            "iter 880: loss 1.9962, time 316.27ms, mfu 0.39%\n",
            "iter 890: loss 1.9296, time 313.43ms, mfu 0.40%\n",
            "iter 900: loss 1.9062, time 328.14ms, mfu 0.40%\n",
            "iter 910: loss 1.9651, time 320.28ms, mfu 0.40%\n",
            "iter 920: loss 1.8182, time 316.37ms, mfu 0.40%\n",
            "iter 930: loss 1.7859, time 315.39ms, mfu 0.40%\n",
            "iter 940: loss 2.0655, time 315.42ms, mfu 0.40%\n",
            "iter 950: loss 1.8101, time 312.59ms, mfu 0.40%\n",
            "iter 960: loss 1.9448, time 312.43ms, mfu 0.40%\n",
            "iter 970: loss 1.8491, time 314.67ms, mfu 0.40%\n",
            "iter 980: loss 1.9208, time 318.80ms, mfu 0.40%\n",
            "iter 990: loss 2.0369, time 311.42ms, mfu 0.41%\n",
            "step 1000: train loss 1.7524, val loss 1.8922\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 1000: loss 1.6824, time 1631.04ms, mfu 0.37%\n",
            "\n",
            "=== Experiment 10/32: b64_L4_H4_E256_BS8_MI1000_D20_s10 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS8_MI1000_D20_s10.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D20_s10\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 10\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2853, val loss 4.2801\n",
            "iter 0: loss 4.2901, time 1891.30ms, mfu -100.00%\n",
            "iter 10: loss 4.2239, time 314.75ms, mfu 0.41%\n",
            "iter 20: loss 4.1063, time 322.42ms, mfu 0.41%\n",
            "iter 30: loss 3.9135, time 322.42ms, mfu 0.41%\n",
            "iter 40: loss 3.7243, time 321.28ms, mfu 0.41%\n",
            "iter 50: loss 3.6460, time 315.26ms, mfu 0.41%\n",
            "iter 60: loss 3.5481, time 317.10ms, mfu 0.41%\n",
            "iter 70: loss 3.4576, time 324.29ms, mfu 0.41%\n",
            "iter 80: loss 3.5036, time 313.59ms, mfu 0.41%\n",
            "iter 90: loss 3.2698, time 319.03ms, mfu 0.41%\n",
            "iter 100: loss 3.1631, time 314.14ms, mfu 0.41%\n",
            "iter 110: loss 3.0696, time 315.86ms, mfu 0.41%\n",
            "iter 120: loss 3.0895, time 314.89ms, mfu 0.41%\n",
            "iter 130: loss 3.0262, time 315.03ms, mfu 0.41%\n",
            "iter 140: loss 2.9045, time 313.84ms, mfu 0.41%\n",
            "iter 150: loss 2.9003, time 314.75ms, mfu 0.41%\n",
            "iter 160: loss 2.8292, time 311.41ms, mfu 0.41%\n",
            "iter 170: loss 2.8266, time 313.00ms, mfu 0.41%\n",
            "iter 180: loss 2.9137, time 322.11ms, mfu 0.41%\n",
            "iter 190: loss 2.7839, time 316.47ms, mfu 0.41%\n",
            "step 200: train loss 2.6964, val loss 2.7059\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 200: loss 2.8103, time 1612.15ms, mfu 0.38%\n",
            "iter 210: loss 2.7160, time 315.15ms, mfu 0.38%\n",
            "iter 220: loss 2.6070, time 322.57ms, mfu 0.38%\n",
            "iter 230: loss 2.7234, time 318.91ms, mfu 0.39%\n",
            "iter 240: loss 2.7143, time 317.33ms, mfu 0.39%\n",
            "iter 250: loss 2.6452, time 316.12ms, mfu 0.39%\n",
            "iter 260: loss 2.7163, time 313.30ms, mfu 0.39%\n",
            "iter 270: loss 2.4839, time 316.06ms, mfu 0.39%\n",
            "iter 280: loss 2.6245, time 317.11ms, mfu 0.40%\n",
            "iter 290: loss 2.6336, time 320.07ms, mfu 0.40%\n",
            "iter 300: loss 2.5698, time 313.77ms, mfu 0.40%\n",
            "iter 310: loss 2.5298, time 314.65ms, mfu 0.40%\n",
            "iter 320: loss 2.6177, time 313.59ms, mfu 0.40%\n",
            "iter 330: loss 2.4842, time 318.04ms, mfu 0.40%\n",
            "iter 340: loss 2.5438, time 312.15ms, mfu 0.40%\n",
            "iter 350: loss 2.5056, time 312.58ms, mfu 0.40%\n",
            "iter 360: loss 2.4079, time 314.25ms, mfu 0.41%\n",
            "iter 370: loss 2.4729, time 314.51ms, mfu 0.41%\n",
            "iter 380: loss 2.4163, time 311.03ms, mfu 0.41%\n",
            "iter 390: loss 2.5116, time 311.70ms, mfu 0.41%\n",
            "step 400: train loss 2.4136, val loss 2.4301\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 400: loss 2.4839, time 1618.89ms, mfu 0.38%\n",
            "iter 410: loss 2.3753, time 311.71ms, mfu 0.38%\n",
            "iter 420: loss 2.4904, time 313.69ms, mfu 0.38%\n",
            "iter 430: loss 2.3603, time 311.64ms, mfu 0.39%\n",
            "iter 440: loss 2.4727, time 318.75ms, mfu 0.39%\n",
            "iter 450: loss 2.5199, time 318.50ms, mfu 0.39%\n",
            "iter 460: loss 2.4380, time 315.61ms, mfu 0.39%\n",
            "iter 470: loss 2.4363, time 314.96ms, mfu 0.39%\n",
            "iter 480: loss 2.4431, time 317.88ms, mfu 0.40%\n",
            "iter 490: loss 2.3758, time 311.88ms, mfu 0.40%\n",
            "iter 500: loss 2.4144, time 311.70ms, mfu 0.40%\n",
            "iter 510: loss 2.3288, time 312.93ms, mfu 0.40%\n",
            "iter 520: loss 2.3660, time 318.02ms, mfu 0.40%\n",
            "iter 530: loss 2.4254, time 312.92ms, mfu 0.40%\n",
            "iter 540: loss 2.3481, time 316.44ms, mfu 0.40%\n",
            "iter 550: loss 2.2740, time 311.79ms, mfu 0.41%\n",
            "iter 560: loss 2.3709, time 318.82ms, mfu 0.41%\n",
            "iter 570: loss 2.2368, time 320.41ms, mfu 0.41%\n",
            "iter 580: loss 2.3222, time 318.74ms, mfu 0.41%\n",
            "iter 590: loss 2.2658, time 319.42ms, mfu 0.41%\n",
            "step 600: train loss 2.2121, val loss 2.2231\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 600: loss 2.2876, time 1614.32ms, mfu 0.37%\n",
            "iter 610: loss 2.3409, time 312.24ms, mfu 0.38%\n",
            "iter 620: loss 2.3397, time 318.81ms, mfu 0.38%\n",
            "iter 630: loss 2.3774, time 319.75ms, mfu 0.38%\n",
            "iter 640: loss 2.2281, time 313.10ms, mfu 0.39%\n",
            "iter 650: loss 2.2580, time 312.84ms, mfu 0.39%\n",
            "iter 660: loss 2.2511, time 310.11ms, mfu 0.39%\n",
            "iter 670: loss 2.2772, time 314.01ms, mfu 0.39%\n",
            "iter 680: loss 2.2027, time 319.27ms, mfu 0.40%\n",
            "iter 690: loss 2.1735, time 317.58ms, mfu 0.40%\n",
            "iter 700: loss 2.1916, time 315.25ms, mfu 0.40%\n",
            "iter 710: loss 2.1012, time 333.46ms, mfu 0.40%\n",
            "iter 720: loss 2.1780, time 314.12ms, mfu 0.40%\n",
            "iter 730: loss 2.1944, time 316.52ms, mfu 0.40%\n",
            "iter 740: loss 2.1467, time 320.81ms, mfu 0.40%\n",
            "iter 750: loss 2.0950, time 313.03ms, mfu 0.40%\n",
            "iter 760: loss 2.1485, time 313.28ms, mfu 0.40%\n",
            "iter 770: loss 2.0672, time 311.83ms, mfu 0.40%\n",
            "iter 780: loss 2.1524, time 316.09ms, mfu 0.41%\n",
            "iter 790: loss 2.2413, time 317.22ms, mfu 0.41%\n",
            "step 800: train loss 2.0309, val loss 2.0759\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 800: loss 2.1967, time 1623.70ms, mfu 0.37%\n",
            "iter 810: loss 2.2169, time 318.55ms, mfu 0.38%\n",
            "iter 820: loss 2.0408, time 327.28ms, mfu 0.38%\n",
            "iter 830: loss 2.0555, time 315.11ms, mfu 0.38%\n",
            "iter 840: loss 2.0545, time 318.51ms, mfu 0.38%\n",
            "iter 850: loss 2.0281, time 316.51ms, mfu 0.39%\n",
            "iter 860: loss 2.0774, time 314.82ms, mfu 0.39%\n",
            "iter 870: loss 2.1751, time 312.17ms, mfu 0.39%\n",
            "iter 880: loss 2.1092, time 308.36ms, mfu 0.39%\n",
            "iter 890: loss 2.0958, time 309.45ms, mfu 0.40%\n",
            "iter 900: loss 2.0375, time 316.65ms, mfu 0.40%\n",
            "iter 910: loss 2.1073, time 314.59ms, mfu 0.40%\n",
            "iter 920: loss 1.9475, time 311.14ms, mfu 0.40%\n",
            "iter 930: loss 1.9114, time 321.51ms, mfu 0.40%\n",
            "iter 940: loss 2.2143, time 311.20ms, mfu 0.40%\n",
            "iter 950: loss 1.9951, time 311.75ms, mfu 0.40%\n",
            "iter 960: loss 2.0722, time 312.26ms, mfu 0.41%\n",
            "iter 970: loss 1.9715, time 320.74ms, mfu 0.41%\n",
            "iter 980: loss 2.0618, time 320.15ms, mfu 0.41%\n",
            "iter 990: loss 2.1542, time 310.75ms, mfu 0.41%\n",
            "step 1000: train loss 1.8651, val loss 1.9719\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 1000: loss 1.8636, time 1630.25ms, mfu 0.37%\n",
            "\n",
            "=== Experiment 11/32: b64_L4_H4_E256_BS8_MI2000_D10_s11 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS8_MI2000_D10_s11.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 11\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2853, val loss 4.2801\n",
            "iter 0: loss 4.3034, time 1906.16ms, mfu -100.00%\n",
            "iter 10: loss 4.2172, time 314.80ms, mfu 0.41%\n",
            "iter 20: loss 4.0957, time 318.19ms, mfu 0.41%\n",
            "iter 30: loss 3.8559, time 336.96ms, mfu 0.41%\n",
            "iter 40: loss 3.6711, time 309.38ms, mfu 0.41%\n",
            "iter 50: loss 3.5999, time 318.13ms, mfu 0.41%\n",
            "iter 60: loss 3.5084, time 309.45ms, mfu 0.41%\n",
            "iter 70: loss 3.4219, time 314.73ms, mfu 0.41%\n",
            "iter 80: loss 3.4448, time 316.32ms, mfu 0.41%\n",
            "iter 90: loss 3.2085, time 308.49ms, mfu 0.41%\n",
            "iter 100: loss 3.0935, time 315.57ms, mfu 0.41%\n",
            "iter 110: loss 3.0007, time 313.82ms, mfu 0.41%\n",
            "iter 120: loss 3.0133, time 313.53ms, mfu 0.41%\n",
            "iter 130: loss 2.9677, time 311.98ms, mfu 0.41%\n",
            "iter 140: loss 2.8436, time 319.69ms, mfu 0.41%\n",
            "iter 150: loss 2.8332, time 312.58ms, mfu 0.41%\n",
            "iter 160: loss 2.7623, time 309.54ms, mfu 0.41%\n",
            "iter 170: loss 2.7862, time 311.81ms, mfu 0.41%\n",
            "iter 180: loss 2.8696, time 316.40ms, mfu 0.41%\n",
            "iter 190: loss 2.7439, time 318.54ms, mfu 0.41%\n",
            "step 200: train loss 2.6753, val loss 2.6884\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 200: loss 2.7695, time 1627.92ms, mfu 0.38%\n",
            "iter 210: loss 2.6771, time 314.91ms, mfu 0.38%\n",
            "iter 220: loss 2.5706, time 311.34ms, mfu 0.39%\n",
            "iter 230: loss 2.6663, time 313.88ms, mfu 0.39%\n",
            "iter 240: loss 2.6594, time 312.99ms, mfu 0.39%\n",
            "iter 250: loss 2.6079, time 311.30ms, mfu 0.39%\n",
            "iter 260: loss 2.6880, time 308.01ms, mfu 0.40%\n",
            "iter 270: loss 2.4497, time 312.34ms, mfu 0.40%\n",
            "iter 280: loss 2.5806, time 311.01ms, mfu 0.40%\n",
            "iter 290: loss 2.6016, time 315.69ms, mfu 0.40%\n",
            "iter 300: loss 2.5310, time 313.51ms, mfu 0.40%\n",
            "iter 310: loss 2.4873, time 311.58ms, mfu 0.40%\n",
            "iter 320: loss 2.5575, time 314.13ms, mfu 0.41%\n",
            "iter 330: loss 2.4142, time 318.15ms, mfu 0.41%\n",
            "iter 340: loss 2.5028, time 317.69ms, mfu 0.41%\n",
            "iter 350: loss 2.4591, time 312.84ms, mfu 0.41%\n",
            "iter 360: loss 2.3574, time 316.15ms, mfu 0.41%\n",
            "iter 370: loss 2.4168, time 313.28ms, mfu 0.41%\n",
            "iter 380: loss 2.3268, time 313.22ms, mfu 0.41%\n",
            "iter 390: loss 2.4598, time 313.19ms, mfu 0.41%\n",
            "step 400: train loss 2.3618, val loss 2.3793\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 400: loss 2.4226, time 1613.68ms, mfu 0.38%\n",
            "iter 410: loss 2.3062, time 316.24ms, mfu 0.38%\n",
            "iter 420: loss 2.4341, time 314.98ms, mfu 0.38%\n",
            "iter 430: loss 2.2826, time 316.88ms, mfu 0.39%\n",
            "iter 440: loss 2.3929, time 319.02ms, mfu 0.39%\n",
            "iter 450: loss 2.4668, time 310.00ms, mfu 0.39%\n",
            "iter 460: loss 2.3581, time 310.82ms, mfu 0.39%\n",
            "iter 470: loss 2.3487, time 311.96ms, mfu 0.40%\n",
            "iter 480: loss 2.3281, time 322.43ms, mfu 0.40%\n",
            "iter 490: loss 2.3163, time 313.14ms, mfu 0.40%\n",
            "iter 500: loss 2.3210, time 310.14ms, mfu 0.40%\n",
            "iter 510: loss 2.2429, time 311.51ms, mfu 0.40%\n",
            "iter 520: loss 2.2757, time 317.62ms, mfu 0.40%\n",
            "iter 530: loss 2.3115, time 312.68ms, mfu 0.40%\n",
            "iter 540: loss 2.2465, time 310.59ms, mfu 0.41%\n",
            "iter 550: loss 2.1514, time 311.86ms, mfu 0.41%\n",
            "iter 560: loss 2.2810, time 327.42ms, mfu 0.41%\n",
            "iter 570: loss 2.1416, time 314.24ms, mfu 0.41%\n",
            "iter 580: loss 2.2534, time 313.37ms, mfu 0.41%\n",
            "iter 590: loss 2.1647, time 312.79ms, mfu 0.41%\n",
            "step 600: train loss 2.1150, val loss 2.1423\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 600: loss 2.1785, time 1643.70ms, mfu 0.37%\n",
            "iter 610: loss 2.2581, time 309.93ms, mfu 0.38%\n",
            "iter 620: loss 2.2488, time 314.65ms, mfu 0.38%\n",
            "iter 630: loss 2.2699, time 319.76ms, mfu 0.38%\n",
            "iter 640: loss 2.1474, time 314.60ms, mfu 0.39%\n",
            "iter 650: loss 2.1381, time 312.56ms, mfu 0.39%\n",
            "iter 660: loss 2.1198, time 317.86ms, mfu 0.39%\n",
            "iter 670: loss 2.1889, time 316.26ms, mfu 0.39%\n",
            "iter 680: loss 2.0746, time 321.80ms, mfu 0.39%\n",
            "iter 690: loss 2.0667, time 318.46ms, mfu 0.40%\n",
            "iter 700: loss 2.0982, time 320.49ms, mfu 0.40%\n",
            "iter 710: loss 1.9845, time 317.42ms, mfu 0.40%\n",
            "iter 720: loss 2.0496, time 310.73ms, mfu 0.40%\n",
            "iter 730: loss 2.0819, time 311.24ms, mfu 0.40%\n",
            "iter 740: loss 2.0219, time 311.75ms, mfu 0.40%\n",
            "iter 750: loss 1.9833, time 310.70ms, mfu 0.40%\n",
            "iter 760: loss 2.0363, time 308.80ms, mfu 0.41%\n",
            "iter 770: loss 1.9554, time 309.22ms, mfu 0.41%\n",
            "iter 780: loss 1.9951, time 309.14ms, mfu 0.41%\n",
            "iter 790: loss 2.1353, time 311.51ms, mfu 0.41%\n",
            "step 800: train loss 1.9189, val loss 1.9882\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 800: loss 2.1129, time 1620.16ms, mfu 0.38%\n",
            "iter 810: loss 2.0982, time 312.96ms, mfu 0.38%\n",
            "iter 820: loss 1.9311, time 313.61ms, mfu 0.38%\n",
            "iter 830: loss 1.9434, time 310.42ms, mfu 0.39%\n",
            "iter 840: loss 1.9609, time 309.49ms, mfu 0.39%\n",
            "iter 850: loss 1.9527, time 308.70ms, mfu 0.39%\n",
            "iter 860: loss 1.9399, time 333.99ms, mfu 0.39%\n",
            "iter 870: loss 2.0771, time 317.73ms, mfu 0.39%\n",
            "iter 880: loss 1.9962, time 316.06ms, mfu 0.40%\n",
            "iter 890: loss 1.9296, time 314.41ms, mfu 0.40%\n",
            "iter 900: loss 1.9062, time 312.08ms, mfu 0.40%\n",
            "iter 910: loss 1.9651, time 314.61ms, mfu 0.40%\n",
            "iter 920: loss 1.8182, time 310.05ms, mfu 0.40%\n",
            "iter 930: loss 1.7859, time 312.38ms, mfu 0.40%\n",
            "iter 940: loss 2.0655, time 318.22ms, mfu 0.40%\n",
            "iter 950: loss 1.8101, time 314.33ms, mfu 0.41%\n",
            "iter 960: loss 1.9448, time 312.13ms, mfu 0.41%\n",
            "iter 970: loss 1.8491, time 324.76ms, mfu 0.41%\n",
            "iter 980: loss 1.9208, time 313.92ms, mfu 0.41%\n",
            "iter 990: loss 2.0369, time 313.31ms, mfu 0.41%\n",
            "step 1000: train loss 1.7524, val loss 1.8922\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1000: loss 1.6824, time 1635.26ms, mfu 0.37%\n",
            "iter 1010: loss 1.8089, time 316.77ms, mfu 0.38%\n",
            "iter 1020: loss 1.7000, time 307.96ms, mfu 0.38%\n",
            "iter 1030: loss 1.9319, time 308.60ms, mfu 0.39%\n",
            "iter 1040: loss 1.9271, time 309.22ms, mfu 0.39%\n",
            "iter 1050: loss 1.7055, time 313.53ms, mfu 0.39%\n",
            "iter 1060: loss 1.7983, time 314.65ms, mfu 0.39%\n",
            "iter 1070: loss 1.8135, time 316.43ms, mfu 0.40%\n",
            "iter 1080: loss 1.7279, time 316.67ms, mfu 0.40%\n",
            "iter 1090: loss 1.7583, time 309.92ms, mfu 0.40%\n",
            "iter 1100: loss 1.6659, time 314.64ms, mfu 0.40%\n",
            "iter 1110: loss 1.8819, time 310.72ms, mfu 0.40%\n",
            "iter 1120: loss 1.7491, time 320.70ms, mfu 0.40%\n",
            "iter 1130: loss 1.7412, time 318.56ms, mfu 0.40%\n",
            "iter 1140: loss 1.6909, time 317.27ms, mfu 0.40%\n",
            "iter 1150: loss 1.6674, time 311.56ms, mfu 0.40%\n",
            "iter 1160: loss 1.6246, time 319.40ms, mfu 0.41%\n",
            "iter 1170: loss 1.5822, time 312.88ms, mfu 0.41%\n",
            "iter 1180: loss 1.6188, time 313.28ms, mfu 0.41%\n",
            "iter 1190: loss 1.7028, time 311.37ms, mfu 0.41%\n",
            "step 1200: train loss 1.6161, val loss 1.7952\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1200: loss 1.6564, time 1682.35ms, mfu 0.37%\n",
            "iter 1210: loss 1.7892, time 307.62ms, mfu 0.38%\n",
            "iter 1220: loss 1.6516, time 308.01ms, mfu 0.38%\n",
            "iter 1230: loss 1.7989, time 312.46ms, mfu 0.39%\n",
            "iter 1240: loss 1.5141, time 312.33ms, mfu 0.39%\n",
            "iter 1250: loss 1.6535, time 312.49ms, mfu 0.39%\n",
            "iter 1260: loss 1.6631, time 313.70ms, mfu 0.39%\n",
            "iter 1270: loss 1.7582, time 312.92ms, mfu 0.40%\n",
            "iter 1280: loss 1.6907, time 309.60ms, mfu 0.40%\n",
            "iter 1290: loss 1.5629, time 309.39ms, mfu 0.40%\n",
            "iter 1300: loss 1.6746, time 309.25ms, mfu 0.40%\n",
            "iter 1310: loss 1.5395, time 323.90ms, mfu 0.40%\n",
            "iter 1320: loss 1.7451, time 310.63ms, mfu 0.40%\n",
            "iter 1330: loss 1.8269, time 314.90ms, mfu 0.40%\n",
            "iter 1340: loss 1.6996, time 308.95ms, mfu 0.41%\n",
            "iter 1350: loss 1.5514, time 312.45ms, mfu 0.41%\n",
            "iter 1360: loss 1.6146, time 313.75ms, mfu 0.41%\n",
            "iter 1370: loss 1.6732, time 311.32ms, mfu 0.41%\n",
            "iter 1380: loss 1.4827, time 317.48ms, mfu 0.41%\n",
            "iter 1390: loss 1.6414, time 331.86ms, mfu 0.41%\n",
            "step 1400: train loss 1.5480, val loss 1.7167\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1400: loss 1.5630, time 1604.37ms, mfu 0.37%\n",
            "iter 1410: loss 1.5992, time 314.38ms, mfu 0.38%\n",
            "iter 1420: loss 1.7682, time 311.16ms, mfu 0.38%\n",
            "iter 1430: loss 1.6420, time 311.28ms, mfu 0.39%\n",
            "iter 1440: loss 1.6437, time 313.58ms, mfu 0.39%\n",
            "iter 1450: loss 1.6084, time 315.13ms, mfu 0.39%\n",
            "iter 1460: loss 1.4477, time 325.90ms, mfu 0.39%\n",
            "iter 1470: loss 1.5080, time 321.88ms, mfu 0.39%\n",
            "iter 1480: loss 1.7030, time 319.85ms, mfu 0.39%\n",
            "iter 1490: loss 1.4437, time 321.24ms, mfu 0.40%\n",
            "iter 1500: loss 1.4422, time 318.04ms, mfu 0.40%\n",
            "iter 1510: loss 1.5482, time 314.51ms, mfu 0.40%\n",
            "iter 1520: loss 1.5678, time 310.40ms, mfu 0.40%\n",
            "iter 1530: loss 1.5427, time 311.66ms, mfu 0.40%\n",
            "iter 1540: loss 1.6443, time 320.62ms, mfu 0.40%\n",
            "iter 1550: loss 1.5304, time 312.26ms, mfu 0.40%\n",
            "iter 1560: loss 1.4947, time 313.37ms, mfu 0.40%\n",
            "iter 1570: loss 1.5387, time 314.64ms, mfu 0.41%\n",
            "iter 1580: loss 1.5467, time 311.69ms, mfu 0.41%\n",
            "iter 1590: loss 1.6622, time 311.05ms, mfu 0.41%\n",
            "step 1600: train loss 1.4901, val loss 1.6633\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1600: loss 1.6202, time 1630.14ms, mfu 0.37%\n",
            "iter 1610: loss 1.6681, time 311.92ms, mfu 0.38%\n",
            "iter 1620: loss 1.5871, time 309.86ms, mfu 0.38%\n",
            "iter 1630: loss 1.4834, time 309.20ms, mfu 0.39%\n",
            "iter 1640: loss 1.5116, time 313.46ms, mfu 0.39%\n",
            "iter 1650: loss 1.6113, time 324.50ms, mfu 0.39%\n",
            "iter 1660: loss 1.4166, time 311.56ms, mfu 0.39%\n",
            "iter 1670: loss 1.3799, time 314.37ms, mfu 0.39%\n",
            "iter 1680: loss 1.4917, time 315.81ms, mfu 0.40%\n",
            "iter 1690: loss 1.4067, time 324.00ms, mfu 0.40%\n",
            "iter 1700: loss 1.5330, time 312.86ms, mfu 0.40%\n",
            "iter 1710: loss 1.4361, time 318.01ms, mfu 0.40%\n",
            "iter 1720: loss 1.4316, time 315.55ms, mfu 0.40%\n",
            "iter 1730: loss 1.3874, time 313.62ms, mfu 0.40%\n",
            "iter 1740: loss 1.6366, time 317.75ms, mfu 0.40%\n",
            "iter 1750: loss 1.4544, time 315.23ms, mfu 0.40%\n",
            "iter 1760: loss 1.4545, time 324.46ms, mfu 0.40%\n",
            "iter 1770: loss 1.4853, time 308.95ms, mfu 0.41%\n",
            "iter 1780: loss 1.6111, time 307.71ms, mfu 0.41%\n",
            "iter 1790: loss 1.3476, time 312.54ms, mfu 0.41%\n",
            "step 1800: train loss 1.4253, val loss 1.6339\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1800: loss 1.4193, time 1633.04ms, mfu 0.37%\n",
            "iter 1810: loss 1.6767, time 314.74ms, mfu 0.38%\n",
            "iter 1820: loss 1.5797, time 312.72ms, mfu 0.38%\n",
            "iter 1830: loss 1.5357, time 314.74ms, mfu 0.39%\n",
            "iter 1840: loss 1.4957, time 315.91ms, mfu 0.39%\n",
            "iter 1850: loss 1.6307, time 313.99ms, mfu 0.39%\n",
            "iter 1860: loss 1.5137, time 314.73ms, mfu 0.39%\n",
            "iter 1870: loss 1.4554, time 314.13ms, mfu 0.39%\n",
            "iter 1880: loss 1.5835, time 314.11ms, mfu 0.40%\n",
            "iter 1890: loss 1.4197, time 312.17ms, mfu 0.40%\n",
            "iter 1900: loss 1.4730, time 312.09ms, mfu 0.40%\n",
            "iter 1910: loss 1.4360, time 323.81ms, mfu 0.40%\n",
            "iter 1920: loss 1.5493, time 312.31ms, mfu 0.40%\n",
            "iter 1930: loss 1.5262, time 311.54ms, mfu 0.40%\n",
            "iter 1940: loss 1.5108, time 310.94ms, mfu 0.40%\n",
            "iter 1950: loss 1.5690, time 321.03ms, mfu 0.40%\n",
            "iter 1960: loss 1.4308, time 314.54ms, mfu 0.41%\n",
            "iter 1970: loss 1.4595, time 310.58ms, mfu 0.41%\n",
            "iter 1980: loss 1.5286, time 313.77ms, mfu 0.41%\n",
            "iter 1990: loss 1.4270, time 316.45ms, mfu 0.41%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 12/32: b64_L4_H4_E256_BS8_MI2000_D20_s12 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS8_MI2000_D20_s12.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 12\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2853, val loss 4.2801\n",
            "iter 0: loss 4.2901, time 1901.15ms, mfu -100.00%\n",
            "iter 10: loss 4.2239, time 325.01ms, mfu 0.40%\n",
            "iter 20: loss 4.1063, time 314.84ms, mfu 0.40%\n",
            "iter 30: loss 3.9135, time 313.47ms, mfu 0.40%\n",
            "iter 40: loss 3.7243, time 313.40ms, mfu 0.40%\n",
            "iter 50: loss 3.6460, time 329.56ms, mfu 0.40%\n",
            "iter 60: loss 3.5481, time 314.22ms, mfu 0.40%\n",
            "iter 70: loss 3.4576, time 315.51ms, mfu 0.40%\n",
            "iter 80: loss 3.5036, time 316.36ms, mfu 0.40%\n",
            "iter 90: loss 3.2698, time 317.16ms, mfu 0.41%\n",
            "iter 100: loss 3.1631, time 323.54ms, mfu 0.40%\n",
            "iter 110: loss 3.0696, time 319.51ms, mfu 0.40%\n",
            "iter 120: loss 3.0895, time 321.35ms, mfu 0.40%\n",
            "iter 130: loss 3.0262, time 318.27ms, mfu 0.41%\n",
            "iter 140: loss 2.9045, time 316.08ms, mfu 0.41%\n",
            "iter 150: loss 2.9003, time 319.95ms, mfu 0.41%\n",
            "iter 160: loss 2.8292, time 321.03ms, mfu 0.41%\n",
            "iter 170: loss 2.8266, time 314.56ms, mfu 0.41%\n",
            "iter 180: loss 2.9137, time 317.39ms, mfu 0.41%\n",
            "iter 190: loss 2.7839, time 316.19ms, mfu 0.41%\n",
            "step 200: train loss 2.6964, val loss 2.7059\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 200: loss 2.8103, time 1653.71ms, mfu 0.37%\n",
            "iter 210: loss 2.7160, time 325.28ms, mfu 0.38%\n",
            "iter 220: loss 2.6070, time 318.50ms, mfu 0.38%\n",
            "iter 230: loss 2.7234, time 321.81ms, mfu 0.38%\n",
            "iter 240: loss 2.7143, time 317.71ms, mfu 0.38%\n",
            "iter 250: loss 2.6452, time 317.55ms, mfu 0.39%\n",
            "iter 260: loss 2.7163, time 317.76ms, mfu 0.39%\n",
            "iter 270: loss 2.4839, time 316.50ms, mfu 0.39%\n",
            "iter 280: loss 2.6245, time 318.28ms, mfu 0.39%\n",
            "iter 290: loss 2.6336, time 315.35ms, mfu 0.39%\n",
            "iter 300: loss 2.5698, time 315.25ms, mfu 0.40%\n",
            "iter 310: loss 2.5298, time 320.79ms, mfu 0.40%\n",
            "iter 320: loss 2.6177, time 318.10ms, mfu 0.40%\n",
            "iter 330: loss 2.4842, time 324.20ms, mfu 0.40%\n",
            "iter 340: loss 2.5438, time 317.74ms, mfu 0.40%\n",
            "iter 350: loss 2.5056, time 317.65ms, mfu 0.40%\n",
            "iter 360: loss 2.4079, time 318.44ms, mfu 0.40%\n",
            "iter 370: loss 2.4729, time 315.32ms, mfu 0.40%\n",
            "iter 380: loss 2.4163, time 317.50ms, mfu 0.40%\n",
            "iter 390: loss 2.5116, time 334.07ms, mfu 0.40%\n",
            "step 400: train loss 2.4136, val loss 2.4301\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 400: loss 2.4839, time 1646.62ms, mfu 0.37%\n",
            "iter 410: loss 2.3753, time 314.70ms, mfu 0.37%\n",
            "iter 420: loss 2.4904, time 316.55ms, mfu 0.38%\n",
            "iter 430: loss 2.3603, time 313.99ms, mfu 0.38%\n",
            "iter 440: loss 2.4727, time 315.28ms, mfu 0.38%\n",
            "iter 450: loss 2.5199, time 315.15ms, mfu 0.39%\n",
            "iter 460: loss 2.4380, time 314.61ms, mfu 0.39%\n",
            "iter 470: loss 2.4363, time 314.16ms, mfu 0.39%\n",
            "iter 480: loss 2.4431, time 317.70ms, mfu 0.39%\n",
            "iter 490: loss 2.3758, time 313.40ms, mfu 0.40%\n",
            "iter 500: loss 2.4144, time 331.16ms, mfu 0.40%\n",
            "iter 510: loss 2.3288, time 315.54ms, mfu 0.40%\n",
            "iter 520: loss 2.3660, time 323.45ms, mfu 0.40%\n",
            "iter 530: loss 2.4254, time 316.51ms, mfu 0.40%\n",
            "iter 540: loss 2.3481, time 316.84ms, mfu 0.40%\n",
            "iter 550: loss 2.2740, time 318.01ms, mfu 0.40%\n",
            "iter 560: loss 2.3709, time 320.61ms, mfu 0.40%\n",
            "iter 570: loss 2.2368, time 318.38ms, mfu 0.40%\n",
            "iter 580: loss 2.3222, time 317.85ms, mfu 0.40%\n",
            "iter 590: loss 2.2658, time 315.24ms, mfu 0.40%\n",
            "step 600: train loss 2.2121, val loss 2.2231\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 600: loss 2.2876, time 1651.50ms, mfu 0.37%\n",
            "iter 610: loss 2.3409, time 336.65ms, mfu 0.37%\n",
            "iter 620: loss 2.3397, time 316.77ms, mfu 0.38%\n",
            "iter 630: loss 2.3774, time 313.54ms, mfu 0.38%\n",
            "iter 640: loss 2.2281, time 318.11ms, mfu 0.38%\n",
            "iter 650: loss 2.2580, time 318.00ms, mfu 0.39%\n",
            "iter 660: loss 2.2511, time 315.03ms, mfu 0.39%\n",
            "iter 670: loss 2.2772, time 320.15ms, mfu 0.39%\n",
            "iter 680: loss 2.2027, time 321.06ms, mfu 0.39%\n",
            "iter 690: loss 2.1735, time 315.12ms, mfu 0.39%\n",
            "iter 700: loss 2.1916, time 322.67ms, mfu 0.39%\n",
            "iter 710: loss 2.1012, time 313.80ms, mfu 0.40%\n",
            "iter 720: loss 2.1780, time 328.79ms, mfu 0.40%\n",
            "iter 730: loss 2.1944, time 311.51ms, mfu 0.40%\n",
            "iter 740: loss 2.1467, time 318.42ms, mfu 0.40%\n",
            "iter 750: loss 2.0950, time 320.34ms, mfu 0.40%\n",
            "iter 760: loss 2.1485, time 318.75ms, mfu 0.40%\n",
            "iter 770: loss 2.0672, time 316.14ms, mfu 0.40%\n",
            "iter 780: loss 2.1524, time 317.78ms, mfu 0.40%\n",
            "iter 790: loss 2.2413, time 311.09ms, mfu 0.40%\n",
            "step 800: train loss 2.0309, val loss 2.0759\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 800: loss 2.1967, time 1619.50ms, mfu 0.37%\n",
            "iter 810: loss 2.2169, time 311.06ms, mfu 0.38%\n",
            "iter 820: loss 2.0408, time 315.61ms, mfu 0.38%\n",
            "iter 830: loss 2.0555, time 313.31ms, mfu 0.38%\n",
            "iter 840: loss 2.0545, time 315.74ms, mfu 0.39%\n",
            "iter 850: loss 2.0281, time 319.08ms, mfu 0.39%\n",
            "iter 860: loss 2.0774, time 316.90ms, mfu 0.39%\n",
            "iter 870: loss 2.1751, time 319.42ms, mfu 0.39%\n",
            "iter 880: loss 2.1092, time 317.75ms, mfu 0.39%\n",
            "iter 890: loss 2.0958, time 317.74ms, mfu 0.39%\n",
            "iter 900: loss 2.0375, time 321.16ms, mfu 0.40%\n",
            "iter 910: loss 2.1073, time 322.63ms, mfu 0.40%\n",
            "iter 920: loss 1.9475, time 322.19ms, mfu 0.40%\n",
            "iter 930: loss 1.9114, time 319.09ms, mfu 0.40%\n",
            "iter 940: loss 2.2143, time 318.16ms, mfu 0.40%\n",
            "iter 950: loss 1.9951, time 324.38ms, mfu 0.40%\n",
            "iter 960: loss 2.0722, time 318.86ms, mfu 0.40%\n",
            "iter 970: loss 1.9715, time 312.48ms, mfu 0.40%\n",
            "iter 980: loss 2.0618, time 318.81ms, mfu 0.40%\n",
            "iter 990: loss 2.1542, time 322.79ms, mfu 0.40%\n",
            "step 1000: train loss 1.8651, val loss 1.9719\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1000: loss 1.8636, time 1617.78ms, mfu 0.37%\n",
            "iter 1010: loss 1.9528, time 312.69ms, mfu 0.37%\n",
            "iter 1020: loss 1.9034, time 324.34ms, mfu 0.38%\n",
            "iter 1030: loss 2.1031, time 315.46ms, mfu 0.38%\n",
            "iter 1040: loss 2.0553, time 317.64ms, mfu 0.38%\n",
            "iter 1050: loss 1.8932, time 321.55ms, mfu 0.39%\n",
            "iter 1060: loss 1.9867, time 320.20ms, mfu 0.39%\n",
            "iter 1070: loss 1.9251, time 323.43ms, mfu 0.39%\n",
            "iter 1080: loss 1.8652, time 320.90ms, mfu 0.39%\n",
            "iter 1090: loss 1.8678, time 319.31ms, mfu 0.39%\n",
            "iter 1100: loss 1.8899, time 317.54ms, mfu 0.39%\n",
            "iter 1110: loss 1.9920, time 315.63ms, mfu 0.40%\n",
            "iter 1120: loss 1.8917, time 320.26ms, mfu 0.40%\n",
            "iter 1130: loss 1.9282, time 323.79ms, mfu 0.40%\n",
            "iter 1140: loss 1.8963, time 324.90ms, mfu 0.40%\n",
            "iter 1150: loss 1.8109, time 319.37ms, mfu 0.40%\n",
            "iter 1160: loss 1.7987, time 320.01ms, mfu 0.40%\n",
            "iter 1170: loss 1.7329, time 335.16ms, mfu 0.40%\n",
            "iter 1180: loss 1.7606, time 314.13ms, mfu 0.40%\n",
            "iter 1190: loss 1.8492, time 316.54ms, mfu 0.40%\n",
            "step 1200: train loss 1.7253, val loss 1.8984\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1200: loss 1.8312, time 1647.82ms, mfu 0.37%\n",
            "iter 1210: loss 1.8954, time 320.64ms, mfu 0.37%\n",
            "iter 1220: loss 1.7675, time 320.71ms, mfu 0.38%\n",
            "iter 1230: loss 1.9166, time 316.66ms, mfu 0.38%\n",
            "iter 1240: loss 1.6798, time 315.95ms, mfu 0.38%\n",
            "iter 1250: loss 1.7853, time 321.73ms, mfu 0.38%\n",
            "iter 1260: loss 1.8219, time 322.60ms, mfu 0.39%\n",
            "iter 1270: loss 1.8796, time 320.99ms, mfu 0.39%\n",
            "iter 1280: loss 1.8471, time 315.84ms, mfu 0.39%\n",
            "iter 1290: loss 1.7586, time 320.53ms, mfu 0.39%\n",
            "iter 1300: loss 1.8032, time 318.79ms, mfu 0.39%\n",
            "iter 1310: loss 1.7006, time 322.06ms, mfu 0.39%\n",
            "iter 1320: loss 1.8722, time 322.45ms, mfu 0.39%\n",
            "iter 1330: loss 1.9330, time 317.17ms, mfu 0.40%\n",
            "iter 1340: loss 1.7790, time 316.91ms, mfu 0.40%\n",
            "iter 1350: loss 1.6659, time 323.01ms, mfu 0.40%\n",
            "iter 1360: loss 1.7756, time 316.48ms, mfu 0.40%\n",
            "iter 1370: loss 1.7998, time 320.38ms, mfu 0.40%\n",
            "iter 1380: loss 1.6228, time 316.30ms, mfu 0.40%\n",
            "iter 1390: loss 1.7621, time 323.22ms, mfu 0.40%\n",
            "step 1400: train loss 1.6497, val loss 1.8080\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1400: loss 1.6686, time 1616.47ms, mfu 0.37%\n",
            "iter 1410: loss 1.7109, time 317.62ms, mfu 0.37%\n",
            "iter 1420: loss 1.9330, time 322.30ms, mfu 0.38%\n",
            "iter 1430: loss 1.7475, time 315.10ms, mfu 0.38%\n",
            "iter 1440: loss 1.7322, time 320.09ms, mfu 0.38%\n",
            "iter 1450: loss 1.7281, time 319.00ms, mfu 0.38%\n",
            "iter 1460: loss 1.5993, time 320.87ms, mfu 0.39%\n",
            "iter 1470: loss 1.6576, time 315.82ms, mfu 0.39%\n",
            "iter 1480: loss 1.8442, time 315.91ms, mfu 0.39%\n",
            "iter 1490: loss 1.5906, time 313.98ms, mfu 0.39%\n",
            "iter 1500: loss 1.5717, time 319.65ms, mfu 0.39%\n",
            "iter 1510: loss 1.7155, time 316.96ms, mfu 0.40%\n",
            "iter 1520: loss 1.6717, time 317.36ms, mfu 0.40%\n",
            "iter 1530: loss 1.7003, time 323.61ms, mfu 0.40%\n",
            "iter 1540: loss 1.7800, time 328.68ms, mfu 0.40%\n",
            "iter 1550: loss 1.6077, time 318.80ms, mfu 0.40%\n",
            "iter 1560: loss 1.6057, time 316.18ms, mfu 0.40%\n",
            "iter 1570: loss 1.6611, time 316.08ms, mfu 0.40%\n",
            "iter 1580: loss 1.7121, time 320.17ms, mfu 0.40%\n",
            "iter 1590: loss 1.7947, time 319.54ms, mfu 0.40%\n",
            "step 1600: train loss 1.5796, val loss 1.7512\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1600: loss 1.7398, time 1645.43ms, mfu 0.37%\n",
            "iter 1610: loss 1.7853, time 321.54ms, mfu 0.37%\n",
            "iter 1620: loss 1.7053, time 321.01ms, mfu 0.38%\n",
            "iter 1630: loss 1.6155, time 314.51ms, mfu 0.38%\n",
            "iter 1640: loss 1.6390, time 318.40ms, mfu 0.38%\n",
            "iter 1650: loss 1.7040, time 325.10ms, mfu 0.38%\n",
            "iter 1660: loss 1.4966, time 320.39ms, mfu 0.39%\n",
            "iter 1670: loss 1.4558, time 320.84ms, mfu 0.39%\n",
            "iter 1680: loss 1.6276, time 322.35ms, mfu 0.39%\n",
            "iter 1690: loss 1.5822, time 324.52ms, mfu 0.39%\n",
            "iter 1700: loss 1.6430, time 326.30ms, mfu 0.39%\n",
            "iter 1710: loss 1.5785, time 320.96ms, mfu 0.39%\n",
            "iter 1720: loss 1.5155, time 317.60ms, mfu 0.39%\n",
            "iter 1730: loss 1.5433, time 322.96ms, mfu 0.40%\n",
            "iter 1740: loss 1.7162, time 314.97ms, mfu 0.40%\n",
            "iter 1750: loss 1.5899, time 316.16ms, mfu 0.40%\n",
            "iter 1760: loss 1.5747, time 326.05ms, mfu 0.40%\n",
            "iter 1770: loss 1.5727, time 317.00ms, mfu 0.40%\n",
            "iter 1780: loss 1.7314, time 312.76ms, mfu 0.40%\n",
            "iter 1790: loss 1.4378, time 318.18ms, mfu 0.40%\n",
            "step 1800: train loss 1.5107, val loss 1.7039\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1800: loss 1.5128, time 1643.12ms, mfu 0.37%\n",
            "iter 1810: loss 1.7908, time 310.72ms, mfu 0.37%\n",
            "iter 1820: loss 1.6976, time 314.02ms, mfu 0.38%\n",
            "iter 1830: loss 1.7246, time 323.22ms, mfu 0.38%\n",
            "iter 1840: loss 1.6274, time 319.48ms, mfu 0.38%\n",
            "iter 1850: loss 1.7260, time 319.07ms, mfu 0.39%\n",
            "iter 1860: loss 1.6074, time 318.90ms, mfu 0.39%\n",
            "iter 1870: loss 1.5451, time 321.28ms, mfu 0.39%\n",
            "iter 1880: loss 1.7036, time 317.22ms, mfu 0.39%\n",
            "iter 1890: loss 1.5088, time 317.28ms, mfu 0.39%\n",
            "iter 1900: loss 1.5871, time 315.98ms, mfu 0.39%\n",
            "iter 1910: loss 1.5028, time 327.46ms, mfu 0.39%\n",
            "iter 1920: loss 1.6409, time 321.16ms, mfu 0.40%\n",
            "iter 1930: loss 1.5908, time 319.56ms, mfu 0.40%\n",
            "iter 1940: loss 1.6134, time 322.00ms, mfu 0.40%\n",
            "iter 1950: loss 1.6838, time 317.30ms, mfu 0.40%\n",
            "iter 1960: loss 1.5514, time 316.13ms, mfu 0.40%\n",
            "iter 1970: loss 1.5533, time 314.52ms, mfu 0.40%\n",
            "iter 1980: loss 1.6257, time 314.05ms, mfu 0.40%\n",
            "iter 1990: loss 1.5123, time 317.97ms, mfu 0.40%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 13/32: b64_L4_H4_E256_BS16_MI1000_D10_s13 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS16_MI1000_D10_s13.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D10_s13\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 13\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2850, val loss 4.2800\n",
            "iter 0: loss 4.2845, time 2045.29ms, mfu -100.00%\n",
            "iter 10: loss 4.2329, time 337.05ms, mfu 0.77%\n",
            "iter 20: loss 4.0872, time 337.33ms, mfu 0.77%\n",
            "iter 30: loss 3.9134, time 328.34ms, mfu 0.77%\n",
            "iter 40: loss 3.6769, time 337.94ms, mfu 0.77%\n",
            "iter 50: loss 3.5766, time 326.06ms, mfu 0.77%\n",
            "iter 60: loss 3.4802, time 325.58ms, mfu 0.78%\n",
            "iter 70: loss 3.3339, time 330.02ms, mfu 0.78%\n",
            "iter 80: loss 3.3343, time 331.64ms, mfu 0.78%\n",
            "iter 90: loss 3.2445, time 329.59ms, mfu 0.78%\n",
            "iter 100: loss 3.0774, time 329.03ms, mfu 0.78%\n",
            "iter 110: loss 2.9866, time 331.11ms, mfu 0.78%\n",
            "iter 120: loss 2.9420, time 326.89ms, mfu 0.78%\n",
            "iter 130: loss 2.9232, time 327.77ms, mfu 0.78%\n",
            "iter 140: loss 2.8680, time 328.43ms, mfu 0.78%\n",
            "iter 150: loss 2.7627, time 339.87ms, mfu 0.78%\n",
            "iter 160: loss 2.7824, time 334.29ms, mfu 0.78%\n",
            "iter 170: loss 2.7969, time 327.88ms, mfu 0.78%\n",
            "iter 180: loss 2.7546, time 326.15ms, mfu 0.78%\n",
            "iter 190: loss 2.7765, time 329.98ms, mfu 0.78%\n",
            "step 200: train loss 2.6642, val loss 2.6767\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 200: loss 2.7127, time 1775.24ms, mfu 0.72%\n",
            "iter 210: loss 2.7411, time 332.99ms, mfu 0.73%\n",
            "iter 220: loss 2.6661, time 331.22ms, mfu 0.73%\n",
            "iter 230: loss 2.6658, time 382.40ms, mfu 0.73%\n",
            "iter 240: loss 2.6761, time 331.53ms, mfu 0.73%\n",
            "iter 250: loss 2.5714, time 325.90ms, mfu 0.74%\n",
            "iter 260: loss 2.6294, time 340.85ms, mfu 0.74%\n",
            "iter 270: loss 2.5082, time 331.80ms, mfu 0.75%\n",
            "iter 280: loss 2.5480, time 328.14ms, mfu 0.75%\n",
            "iter 290: loss 2.5376, time 332.26ms, mfu 0.75%\n",
            "iter 300: loss 2.5949, time 328.90ms, mfu 0.76%\n",
            "iter 310: loss 2.4882, time 328.20ms, mfu 0.76%\n",
            "iter 320: loss 2.4709, time 327.68ms, mfu 0.76%\n",
            "iter 330: loss 2.3954, time 338.38ms, mfu 0.76%\n",
            "iter 340: loss 2.3873, time 327.72ms, mfu 0.77%\n",
            "iter 350: loss 2.4489, time 327.80ms, mfu 0.77%\n",
            "iter 360: loss 2.4394, time 330.48ms, mfu 0.77%\n",
            "iter 370: loss 2.3369, time 338.72ms, mfu 0.77%\n",
            "iter 380: loss 2.4341, time 330.67ms, mfu 0.77%\n",
            "iter 390: loss 2.3407, time 328.61ms, mfu 0.77%\n",
            "step 400: train loss 2.3197, val loss 2.3305\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 400: loss 2.3357, time 1817.34ms, mfu 0.71%\n",
            "iter 410: loss 2.3930, time 329.87ms, mfu 0.72%\n",
            "iter 420: loss 2.3726, time 331.71ms, mfu 0.72%\n",
            "iter 430: loss 2.3426, time 326.27ms, mfu 0.73%\n",
            "iter 440: loss 2.2379, time 326.84ms, mfu 0.74%\n",
            "iter 450: loss 2.3637, time 329.39ms, mfu 0.74%\n",
            "iter 460: loss 2.3137, time 328.21ms, mfu 0.75%\n",
            "iter 470: loss 2.2952, time 338.32ms, mfu 0.75%\n",
            "iter 480: loss 2.1616, time 326.88ms, mfu 0.75%\n",
            "iter 490: loss 2.1805, time 325.42ms, mfu 0.76%\n",
            "iter 500: loss 2.2590, time 330.08ms, mfu 0.76%\n",
            "iter 510: loss 2.2195, time 335.68ms, mfu 0.76%\n",
            "iter 520: loss 2.0559, time 338.12ms, mfu 0.76%\n",
            "iter 530: loss 2.1382, time 324.77ms, mfu 0.77%\n",
            "iter 540: loss 2.1809, time 326.96ms, mfu 0.77%\n",
            "iter 550: loss 2.1880, time 336.57ms, mfu 0.77%\n",
            "iter 560: loss 2.2362, time 329.41ms, mfu 0.77%\n",
            "iter 570: loss 2.1188, time 330.61ms, mfu 0.77%\n",
            "iter 580: loss 2.0417, time 340.39ms, mfu 0.77%\n",
            "iter 590: loss 2.1059, time 330.40ms, mfu 0.77%\n",
            "step 600: train loss 2.0363, val loss 2.0859\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 600: loss 2.1667, time 1775.01ms, mfu 0.71%\n",
            "iter 610: loss 2.1026, time 330.35ms, mfu 0.72%\n",
            "iter 620: loss 2.1244, time 334.47ms, mfu 0.72%\n",
            "iter 630: loss 2.0641, time 332.71ms, mfu 0.73%\n",
            "iter 640: loss 2.1339, time 334.39ms, mfu 0.73%\n",
            "iter 650: loss 2.0767, time 334.29ms, mfu 0.74%\n",
            "iter 660: loss 2.0140, time 330.15ms, mfu 0.74%\n",
            "iter 670: loss 2.0875, time 333.88ms, mfu 0.75%\n",
            "iter 680: loss 1.9584, time 328.11ms, mfu 0.75%\n",
            "iter 690: loss 1.9836, time 340.96ms, mfu 0.75%\n",
            "iter 700: loss 1.9769, time 326.38ms, mfu 0.76%\n",
            "iter 710: loss 2.1178, time 328.18ms, mfu 0.76%\n",
            "iter 720: loss 1.9686, time 329.67ms, mfu 0.76%\n",
            "iter 730: loss 1.9564, time 328.76ms, mfu 0.77%\n",
            "iter 740: loss 2.0319, time 333.11ms, mfu 0.77%\n",
            "iter 750: loss 1.9985, time 332.03ms, mfu 0.77%\n",
            "iter 760: loss 1.8995, time 333.60ms, mfu 0.77%\n",
            "iter 770: loss 1.9505, time 333.56ms, mfu 0.77%\n",
            "iter 780: loss 1.9150, time 332.42ms, mfu 0.77%\n",
            "iter 790: loss 1.8800, time 328.17ms, mfu 0.77%\n",
            "step 800: train loss 1.8346, val loss 1.9411\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 800: loss 1.9126, time 1775.42ms, mfu 0.71%\n",
            "iter 810: loss 1.9754, time 335.10ms, mfu 0.72%\n",
            "iter 820: loss 1.9326, time 333.56ms, mfu 0.72%\n",
            "iter 830: loss 1.9794, time 334.06ms, mfu 0.73%\n",
            "iter 840: loss 1.9326, time 334.25ms, mfu 0.73%\n",
            "iter 850: loss 1.7963, time 328.49ms, mfu 0.74%\n",
            "iter 860: loss 1.8642, time 336.40ms, mfu 0.74%\n",
            "iter 870: loss 1.8847, time 333.23ms, mfu 0.75%\n",
            "iter 880: loss 1.7455, time 327.92ms, mfu 0.75%\n",
            "iter 890: loss 1.8632, time 328.64ms, mfu 0.75%\n",
            "iter 900: loss 1.8291, time 338.68ms, mfu 0.76%\n",
            "iter 910: loss 1.7988, time 324.79ms, mfu 0.76%\n",
            "iter 920: loss 1.7945, time 331.95ms, mfu 0.76%\n",
            "iter 930: loss 1.9040, time 324.28ms, mfu 0.77%\n",
            "iter 940: loss 1.8404, time 348.20ms, mfu 0.76%\n",
            "iter 950: loss 1.7939, time 333.59ms, mfu 0.77%\n",
            "iter 960: loss 1.7351, time 328.47ms, mfu 0.77%\n",
            "iter 970: loss 1.7618, time 331.28ms, mfu 0.77%\n",
            "iter 980: loss 1.8038, time 327.19ms, mfu 0.77%\n",
            "iter 990: loss 1.8469, time 328.32ms, mfu 0.77%\n",
            "step 1000: train loss 1.6530, val loss 1.8159\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 1000: loss 1.7883, time 1755.77ms, mfu 0.71%\n",
            "\n",
            "=== Experiment 14/32: b64_L4_H4_E256_BS16_MI1000_D20_s14 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS16_MI1000_D20_s14.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D20_s14\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 14\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2850, val loss 4.2800\n",
            "iter 0: loss 4.2730, time 2019.51ms, mfu -100.00%\n",
            "iter 10: loss 4.2315, time 329.32ms, mfu 0.79%\n",
            "iter 20: loss 4.1037, time 352.04ms, mfu 0.78%\n",
            "iter 30: loss 3.9665, time 334.34ms, mfu 0.78%\n",
            "iter 40: loss 3.7292, time 328.01ms, mfu 0.78%\n",
            "iter 50: loss 3.6142, time 324.56ms, mfu 0.79%\n",
            "iter 60: loss 3.5198, time 327.84ms, mfu 0.79%\n",
            "iter 70: loss 3.3738, time 326.91ms, mfu 0.79%\n",
            "iter 80: loss 3.4002, time 328.66ms, mfu 0.79%\n",
            "iter 90: loss 3.3333, time 327.68ms, mfu 0.79%\n",
            "iter 100: loss 3.1516, time 328.43ms, mfu 0.79%\n",
            "iter 110: loss 3.0573, time 327.74ms, mfu 0.79%\n",
            "iter 120: loss 3.0091, time 326.42ms, mfu 0.79%\n",
            "iter 130: loss 2.9933, time 327.75ms, mfu 0.79%\n",
            "iter 140: loss 2.9215, time 333.86ms, mfu 0.79%\n",
            "iter 150: loss 2.8241, time 328.87ms, mfu 0.79%\n",
            "iter 160: loss 2.8441, time 325.15ms, mfu 0.79%\n",
            "iter 170: loss 2.8462, time 323.02ms, mfu 0.79%\n",
            "iter 180: loss 2.8004, time 327.33ms, mfu 0.79%\n",
            "iter 190: loss 2.8319, time 330.21ms, mfu 0.79%\n",
            "step 200: train loss 2.6858, val loss 2.6943\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 200: loss 2.7566, time 1758.41ms, mfu 0.73%\n",
            "iter 210: loss 2.7959, time 343.54ms, mfu 0.73%\n",
            "iter 220: loss 2.7104, time 324.18ms, mfu 0.74%\n",
            "iter 230: loss 2.7103, time 327.75ms, mfu 0.74%\n",
            "iter 240: loss 2.7288, time 332.42ms, mfu 0.75%\n",
            "iter 250: loss 2.6088, time 326.14ms, mfu 0.75%\n",
            "iter 260: loss 2.6672, time 331.21ms, mfu 0.75%\n",
            "iter 270: loss 2.5593, time 331.57ms, mfu 0.76%\n",
            "iter 280: loss 2.5997, time 351.17ms, mfu 0.76%\n",
            "iter 290: loss 2.5790, time 328.04ms, mfu 0.76%\n",
            "iter 300: loss 2.6470, time 335.70ms, mfu 0.76%\n",
            "iter 310: loss 2.5504, time 330.28ms, mfu 0.76%\n",
            "iter 320: loss 2.5299, time 339.74ms, mfu 0.76%\n",
            "iter 330: loss 2.4607, time 332.09ms, mfu 0.76%\n",
            "iter 340: loss 2.4506, time 325.54ms, mfu 0.77%\n",
            "iter 350: loss 2.4983, time 320.60ms, mfu 0.77%\n",
            "iter 360: loss 2.5082, time 329.53ms, mfu 0.77%\n",
            "iter 370: loss 2.4020, time 332.94ms, mfu 0.77%\n",
            "iter 380: loss 2.4859, time 333.18ms, mfu 0.77%\n",
            "iter 390: loss 2.4005, time 330.51ms, mfu 0.78%\n",
            "step 400: train loss 2.3829, val loss 2.3900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 400: loss 2.4064, time 1750.35ms, mfu 0.71%\n",
            "iter 410: loss 2.4550, time 322.09ms, mfu 0.72%\n",
            "iter 420: loss 2.4256, time 327.89ms, mfu 0.73%\n",
            "iter 430: loss 2.4152, time 331.99ms, mfu 0.73%\n",
            "iter 440: loss 2.3216, time 332.52ms, mfu 0.74%\n",
            "iter 450: loss 2.4192, time 326.31ms, mfu 0.74%\n",
            "iter 460: loss 2.3992, time 330.16ms, mfu 0.75%\n",
            "iter 470: loss 2.3835, time 324.06ms, mfu 0.75%\n",
            "iter 480: loss 2.2425, time 320.27ms, mfu 0.76%\n",
            "iter 490: loss 2.2764, time 325.25ms, mfu 0.76%\n",
            "iter 500: loss 2.3621, time 338.33ms, mfu 0.76%\n",
            "iter 510: loss 2.3225, time 326.12ms, mfu 0.77%\n",
            "iter 520: loss 2.1634, time 324.30ms, mfu 0.77%\n",
            "iter 530: loss 2.2345, time 324.59ms, mfu 0.77%\n",
            "iter 540: loss 2.2840, time 329.41ms, mfu 0.77%\n",
            "iter 550: loss 2.2918, time 328.91ms, mfu 0.78%\n",
            "iter 560: loss 2.3251, time 324.58ms, mfu 0.78%\n",
            "iter 570: loss 2.2381, time 328.37ms, mfu 0.78%\n",
            "iter 580: loss 2.1426, time 325.65ms, mfu 0.78%\n",
            "iter 590: loss 2.1770, time 330.30ms, mfu 0.78%\n",
            "step 600: train loss 2.1307, val loss 2.1626\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 600: loss 2.2942, time 1741.95ms, mfu 0.72%\n",
            "iter 610: loss 2.1845, time 319.25ms, mfu 0.73%\n",
            "iter 620: loss 2.2296, time 321.91ms, mfu 0.74%\n",
            "iter 630: loss 2.1813, time 325.75ms, mfu 0.74%\n",
            "iter 640: loss 2.2262, time 330.17ms, mfu 0.75%\n",
            "iter 650: loss 2.1863, time 325.11ms, mfu 0.75%\n",
            "iter 660: loss 2.1370, time 322.90ms, mfu 0.76%\n",
            "iter 670: loss 2.2148, time 323.15ms, mfu 0.76%\n",
            "iter 680: loss 2.0723, time 333.26ms, mfu 0.76%\n",
            "iter 690: loss 2.0935, time 325.88ms, mfu 0.77%\n",
            "iter 700: loss 2.0796, time 325.50ms, mfu 0.77%\n",
            "iter 710: loss 2.2140, time 321.34ms, mfu 0.77%\n",
            "iter 720: loss 2.1091, time 326.84ms, mfu 0.78%\n",
            "iter 730: loss 2.0848, time 327.45ms, mfu 0.78%\n",
            "iter 740: loss 2.1743, time 324.46ms, mfu 0.78%\n",
            "iter 750: loss 2.1163, time 336.87ms, mfu 0.78%\n",
            "iter 760: loss 2.0377, time 324.58ms, mfu 0.78%\n",
            "iter 770: loss 2.0608, time 327.24ms, mfu 0.78%\n",
            "iter 780: loss 2.0584, time 329.16ms, mfu 0.78%\n",
            "iter 790: loss 1.9995, time 342.68ms, mfu 0.78%\n",
            "step 800: train loss 1.9421, val loss 2.0161\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 800: loss 2.0287, time 1785.70ms, mfu 0.72%\n",
            "iter 810: loss 2.0934, time 327.68ms, mfu 0.72%\n",
            "iter 820: loss 2.0733, time 332.62ms, mfu 0.73%\n",
            "iter 830: loss 2.1231, time 328.24ms, mfu 0.74%\n",
            "iter 840: loss 2.0707, time 328.44ms, mfu 0.74%\n",
            "iter 850: loss 1.9247, time 334.84ms, mfu 0.74%\n",
            "iter 860: loss 2.0270, time 330.92ms, mfu 0.75%\n",
            "iter 870: loss 2.0116, time 327.76ms, mfu 0.75%\n",
            "iter 880: loss 1.8907, time 332.96ms, mfu 0.76%\n",
            "iter 890: loss 1.9846, time 333.60ms, mfu 0.76%\n",
            "iter 900: loss 1.9627, time 328.33ms, mfu 0.76%\n",
            "iter 910: loss 1.9590, time 333.94ms, mfu 0.76%\n",
            "iter 920: loss 1.9093, time 326.15ms, mfu 0.77%\n",
            "iter 930: loss 2.0333, time 331.22ms, mfu 0.77%\n",
            "iter 940: loss 1.9720, time 321.92ms, mfu 0.77%\n",
            "iter 950: loss 1.9349, time 325.91ms, mfu 0.77%\n",
            "iter 960: loss 1.8700, time 324.82ms, mfu 0.78%\n",
            "iter 970: loss 1.8770, time 326.41ms, mfu 0.78%\n",
            "iter 980: loss 1.9396, time 324.33ms, mfu 0.78%\n",
            "iter 990: loss 1.9667, time 329.08ms, mfu 0.78%\n",
            "step 1000: train loss 1.7654, val loss 1.9078\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 1000: loss 1.9307, time 1768.53ms, mfu 0.72%\n",
            "\n",
            "=== Experiment 15/32: b64_L4_H4_E256_BS16_MI2000_D10_s15 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS16_MI2000_D10_s15.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 15\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2850, val loss 4.2800\n",
            "iter 0: loss 4.2845, time 2018.05ms, mfu -100.00%\n",
            "iter 10: loss 4.2329, time 327.67ms, mfu 0.79%\n",
            "iter 20: loss 4.0872, time 331.46ms, mfu 0.79%\n",
            "iter 30: loss 3.9134, time 326.02ms, mfu 0.79%\n",
            "iter 40: loss 3.6769, time 328.70ms, mfu 0.79%\n",
            "iter 50: loss 3.5766, time 325.33ms, mfu 0.79%\n",
            "iter 60: loss 3.4802, time 328.04ms, mfu 0.79%\n",
            "iter 70: loss 3.3339, time 326.02ms, mfu 0.79%\n",
            "iter 80: loss 3.3343, time 324.01ms, mfu 0.79%\n",
            "iter 90: loss 3.2445, time 327.39ms, mfu 0.79%\n",
            "iter 100: loss 3.0774, time 326.53ms, mfu 0.79%\n",
            "iter 110: loss 2.9866, time 326.97ms, mfu 0.79%\n",
            "iter 120: loss 2.9420, time 334.35ms, mfu 0.79%\n",
            "iter 130: loss 2.9232, time 333.90ms, mfu 0.79%\n",
            "iter 140: loss 2.8680, time 327.74ms, mfu 0.79%\n",
            "iter 150: loss 2.7627, time 323.62ms, mfu 0.79%\n",
            "iter 160: loss 2.7824, time 326.69ms, mfu 0.79%\n",
            "iter 170: loss 2.7969, time 337.44ms, mfu 0.79%\n",
            "iter 180: loss 2.7546, time 331.50ms, mfu 0.79%\n",
            "iter 190: loss 2.7765, time 325.74ms, mfu 0.79%\n",
            "step 200: train loss 2.6642, val loss 2.6767\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 200: loss 2.7127, time 1774.37ms, mfu 0.73%\n",
            "iter 210: loss 2.7411, time 327.75ms, mfu 0.73%\n",
            "iter 220: loss 2.6661, time 326.32ms, mfu 0.74%\n",
            "iter 230: loss 2.6658, time 328.12ms, mfu 0.74%\n",
            "iter 240: loss 2.6761, time 333.04ms, mfu 0.75%\n",
            "iter 250: loss 2.5714, time 324.23ms, mfu 0.75%\n",
            "iter 260: loss 2.6294, time 326.21ms, mfu 0.76%\n",
            "iter 270: loss 2.5082, time 330.53ms, mfu 0.76%\n",
            "iter 280: loss 2.5480, time 331.96ms, mfu 0.76%\n",
            "iter 290: loss 2.5376, time 329.52ms, mfu 0.76%\n",
            "iter 300: loss 2.5949, time 329.58ms, mfu 0.77%\n",
            "iter 310: loss 2.4882, time 331.44ms, mfu 0.77%\n",
            "iter 320: loss 2.4709, time 326.64ms, mfu 0.77%\n",
            "iter 330: loss 2.3954, time 326.31ms, mfu 0.77%\n",
            "iter 340: loss 2.3873, time 327.09ms, mfu 0.78%\n",
            "iter 350: loss 2.4489, time 334.56ms, mfu 0.78%\n",
            "iter 360: loss 2.4394, time 329.57ms, mfu 0.78%\n",
            "iter 370: loss 2.3369, time 331.21ms, mfu 0.78%\n",
            "iter 380: loss 2.4341, time 329.68ms, mfu 0.78%\n",
            "iter 390: loss 2.3407, time 329.52ms, mfu 0.78%\n",
            "step 400: train loss 2.3197, val loss 2.3305\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 400: loss 2.3357, time 1770.23ms, mfu 0.72%\n",
            "iter 410: loss 2.3930, time 326.37ms, mfu 0.72%\n",
            "iter 420: loss 2.3726, time 331.92ms, mfu 0.73%\n",
            "iter 430: loss 2.3426, time 331.77ms, mfu 0.74%\n",
            "iter 440: loss 2.2379, time 327.43ms, mfu 0.74%\n",
            "iter 450: loss 2.3637, time 328.99ms, mfu 0.75%\n",
            "iter 460: loss 2.3137, time 330.75ms, mfu 0.75%\n",
            "iter 470: loss 2.2952, time 330.94ms, mfu 0.75%\n",
            "iter 480: loss 2.1616, time 332.16ms, mfu 0.76%\n",
            "iter 490: loss 2.1805, time 331.96ms, mfu 0.76%\n",
            "iter 500: loss 2.2590, time 325.70ms, mfu 0.76%\n",
            "iter 510: loss 2.2195, time 325.36ms, mfu 0.77%\n",
            "iter 520: loss 2.0559, time 326.52ms, mfu 0.77%\n",
            "iter 530: loss 2.1382, time 325.65ms, mfu 0.77%\n",
            "iter 540: loss 2.1809, time 323.68ms, mfu 0.77%\n",
            "iter 550: loss 2.1880, time 328.31ms, mfu 0.78%\n",
            "iter 560: loss 2.2362, time 335.90ms, mfu 0.78%\n",
            "iter 570: loss 2.1188, time 328.68ms, mfu 0.78%\n",
            "iter 580: loss 2.0417, time 324.36ms, mfu 0.78%\n",
            "iter 590: loss 2.1059, time 326.09ms, mfu 0.78%\n",
            "step 600: train loss 2.0363, val loss 2.0859\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 600: loss 2.1667, time 1811.48ms, mfu 0.72%\n",
            "iter 610: loss 2.1026, time 324.85ms, mfu 0.73%\n",
            "iter 620: loss 2.1244, time 329.24ms, mfu 0.73%\n",
            "iter 630: loss 2.0641, time 335.83ms, mfu 0.74%\n",
            "iter 640: loss 2.1339, time 326.55ms, mfu 0.74%\n",
            "iter 650: loss 2.0767, time 328.38ms, mfu 0.75%\n",
            "iter 660: loss 2.0140, time 325.72ms, mfu 0.75%\n",
            "iter 670: loss 2.0875, time 332.42ms, mfu 0.75%\n",
            "iter 680: loss 1.9584, time 327.66ms, mfu 0.76%\n",
            "iter 690: loss 1.9836, time 325.78ms, mfu 0.76%\n",
            "iter 700: loss 1.9769, time 325.08ms, mfu 0.77%\n",
            "iter 710: loss 2.1178, time 326.01ms, mfu 0.77%\n",
            "iter 720: loss 1.9686, time 325.10ms, mfu 0.77%\n",
            "iter 730: loss 1.9564, time 327.28ms, mfu 0.77%\n",
            "iter 740: loss 2.0319, time 330.08ms, mfu 0.78%\n",
            "iter 750: loss 1.9985, time 327.84ms, mfu 0.78%\n",
            "iter 760: loss 1.8995, time 329.35ms, mfu 0.78%\n",
            "iter 770: loss 1.9505, time 325.54ms, mfu 0.78%\n",
            "iter 780: loss 1.9150, time 327.24ms, mfu 0.78%\n",
            "iter 790: loss 1.8800, time 325.43ms, mfu 0.78%\n",
            "step 800: train loss 1.8346, val loss 1.9411\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 800: loss 1.9126, time 1770.99ms, mfu 0.72%\n",
            "iter 810: loss 1.9754, time 327.79ms, mfu 0.73%\n",
            "iter 820: loss 1.9326, time 334.34ms, mfu 0.73%\n",
            "iter 830: loss 1.9794, time 333.54ms, mfu 0.74%\n",
            "iter 840: loss 1.9326, time 330.48ms, mfu 0.74%\n",
            "iter 850: loss 1.7963, time 343.32ms, mfu 0.74%\n",
            "iter 860: loss 1.8642, time 327.19ms, mfu 0.75%\n",
            "iter 870: loss 1.8847, time 322.73ms, mfu 0.75%\n",
            "iter 880: loss 1.7455, time 324.91ms, mfu 0.76%\n",
            "iter 890: loss 1.8632, time 325.34ms, mfu 0.76%\n",
            "iter 900: loss 1.8291, time 327.48ms, mfu 0.77%\n",
            "iter 910: loss 1.7988, time 328.19ms, mfu 0.77%\n",
            "iter 920: loss 1.7945, time 325.72ms, mfu 0.77%\n",
            "iter 930: loss 1.9040, time 322.83ms, mfu 0.77%\n",
            "iter 940: loss 1.8404, time 323.28ms, mfu 0.78%\n",
            "iter 950: loss 1.7939, time 326.42ms, mfu 0.78%\n",
            "iter 960: loss 1.7351, time 321.63ms, mfu 0.78%\n",
            "iter 970: loss 1.7618, time 329.54ms, mfu 0.78%\n",
            "iter 980: loss 1.8038, time 329.23ms, mfu 0.78%\n",
            "iter 990: loss 1.8469, time 324.77ms, mfu 0.78%\n",
            "step 1000: train loss 1.6530, val loss 1.8159\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1000: loss 1.7883, time 1759.96ms, mfu 0.72%\n",
            "iter 1010: loss 1.6956, time 330.78ms, mfu 0.73%\n",
            "iter 1020: loss 1.7004, time 328.28ms, mfu 0.73%\n",
            "iter 1030: loss 1.7602, time 342.78ms, mfu 0.74%\n",
            "iter 1040: loss 1.7543, time 330.00ms, mfu 0.74%\n",
            "iter 1050: loss 1.6338, time 323.09ms, mfu 0.75%\n",
            "iter 1060: loss 1.8544, time 322.11ms, mfu 0.75%\n",
            "iter 1070: loss 1.7642, time 328.92ms, mfu 0.76%\n",
            "iter 1080: loss 1.6425, time 325.93ms, mfu 0.76%\n",
            "iter 1090: loss 1.6480, time 325.03ms, mfu 0.76%\n",
            "iter 1100: loss 1.7065, time 332.05ms, mfu 0.77%\n",
            "iter 1110: loss 1.7658, time 329.84ms, mfu 0.77%\n",
            "iter 1120: loss 1.7639, time 328.54ms, mfu 0.77%\n",
            "iter 1130: loss 1.6603, time 330.33ms, mfu 0.77%\n",
            "iter 1140: loss 1.6296, time 358.22ms, mfu 0.77%\n",
            "iter 1150: loss 1.6711, time 328.34ms, mfu 0.77%\n",
            "iter 1160: loss 1.5845, time 325.71ms, mfu 0.77%\n",
            "iter 1170: loss 1.5901, time 329.12ms, mfu 0.77%\n",
            "iter 1180: loss 1.6810, time 329.84ms, mfu 0.78%\n",
            "iter 1190: loss 1.5977, time 327.65ms, mfu 0.78%\n",
            "step 1200: train loss 1.5366, val loss 1.7201\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1200: loss 1.5562, time 1789.93ms, mfu 0.71%\n",
            "iter 1210: loss 1.6689, time 336.04ms, mfu 0.72%\n",
            "iter 1220: loss 1.6161, time 327.86ms, mfu 0.73%\n",
            "iter 1230: loss 1.6411, time 331.83ms, mfu 0.73%\n",
            "iter 1240: loss 1.6157, time 336.25ms, mfu 0.74%\n",
            "iter 1250: loss 1.5014, time 325.47ms, mfu 0.74%\n",
            "iter 1260: loss 1.6460, time 329.71ms, mfu 0.75%\n",
            "iter 1270: loss 1.5685, time 327.95ms, mfu 0.75%\n",
            "iter 1280: loss 1.5207, time 332.18ms, mfu 0.75%\n",
            "iter 1290: loss 1.5593, time 329.22ms, mfu 0.76%\n",
            "iter 1300: loss 1.5275, time 327.26ms, mfu 0.76%\n",
            "iter 1310: loss 1.6536, time 332.49ms, mfu 0.76%\n",
            "iter 1320: loss 1.5140, time 335.24ms, mfu 0.76%\n",
            "iter 1330: loss 1.4667, time 334.39ms, mfu 0.77%\n",
            "iter 1340: loss 1.4701, time 331.52ms, mfu 0.77%\n",
            "iter 1350: loss 1.5506, time 333.66ms, mfu 0.77%\n",
            "iter 1360: loss 1.5889, time 330.62ms, mfu 0.77%\n",
            "iter 1370: loss 1.4718, time 334.61ms, mfu 0.77%\n",
            "iter 1380: loss 1.5710, time 331.86ms, mfu 0.77%\n",
            "iter 1390: loss 1.5512, time 331.65ms, mfu 0.77%\n",
            "step 1400: train loss 1.4594, val loss 1.6460\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1400: loss 1.5482, time 1797.29ms, mfu 0.71%\n",
            "iter 1410: loss 1.4615, time 327.10ms, mfu 0.72%\n",
            "iter 1420: loss 1.6147, time 331.05ms, mfu 0.73%\n",
            "iter 1430: loss 1.5277, time 334.45ms, mfu 0.73%\n",
            "iter 1440: loss 1.4985, time 329.16ms, mfu 0.74%\n",
            "iter 1450: loss 1.5145, time 328.91ms, mfu 0.74%\n",
            "iter 1460: loss 1.4743, time 336.94ms, mfu 0.74%\n",
            "iter 1470: loss 1.5428, time 327.24ms, mfu 0.75%\n",
            "iter 1480: loss 1.5173, time 327.76ms, mfu 0.75%\n",
            "iter 1490: loss 1.5017, time 333.99ms, mfu 0.76%\n",
            "iter 1500: loss 1.5569, time 327.15ms, mfu 0.76%\n",
            "iter 1510: loss 1.5153, time 330.75ms, mfu 0.76%\n",
            "iter 1520: loss 1.4628, time 335.83ms, mfu 0.76%\n",
            "iter 1530: loss 1.4061, time 333.41ms, mfu 0.76%\n",
            "iter 1540: loss 1.5324, time 331.84ms, mfu 0.77%\n",
            "iter 1550: loss 1.4953, time 329.02ms, mfu 0.77%\n",
            "iter 1560: loss 1.4519, time 332.41ms, mfu 0.77%\n",
            "iter 1570: loss 1.4810, time 335.34ms, mfu 0.77%\n",
            "iter 1580: loss 1.4972, time 334.60ms, mfu 0.77%\n",
            "iter 1590: loss 1.4813, time 330.80ms, mfu 0.77%\n",
            "step 1600: train loss 1.3982, val loss 1.6074\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1600: loss 1.5423, time 1780.15ms, mfu 0.71%\n",
            "iter 1610: loss 1.4149, time 326.98ms, mfu 0.72%\n",
            "iter 1620: loss 1.5784, time 329.43ms, mfu 0.73%\n",
            "iter 1630: loss 1.4441, time 338.63ms, mfu 0.73%\n",
            "iter 1640: loss 1.4699, time 325.27ms, mfu 0.74%\n",
            "iter 1650: loss 1.5103, time 320.83ms, mfu 0.74%\n",
            "iter 1660: loss 1.4145, time 324.30ms, mfu 0.75%\n",
            "iter 1670: loss 1.4884, time 336.15ms, mfu 0.75%\n",
            "iter 1680: loss 1.4754, time 333.42ms, mfu 0.75%\n",
            "iter 1690: loss 1.4518, time 325.68ms, mfu 0.76%\n",
            "iter 1700: loss 1.5309, time 329.35ms, mfu 0.76%\n",
            "iter 1710: loss 1.4637, time 326.12ms, mfu 0.76%\n",
            "iter 1720: loss 1.4828, time 330.58ms, mfu 0.77%\n",
            "iter 1730: loss 1.5133, time 330.26ms, mfu 0.77%\n",
            "iter 1740: loss 1.3596, time 332.87ms, mfu 0.77%\n",
            "iter 1750: loss 1.4396, time 335.34ms, mfu 0.77%\n",
            "iter 1760: loss 1.4938, time 325.72ms, mfu 0.77%\n",
            "iter 1770: loss 1.3598, time 327.57ms, mfu 0.77%\n",
            "iter 1780: loss 1.4629, time 330.32ms, mfu 0.78%\n",
            "iter 1790: loss 1.4976, time 326.42ms, mfu 0.78%\n",
            "step 1800: train loss 1.3472, val loss 1.5563\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1800: loss 1.3424, time 1749.96ms, mfu 0.72%\n",
            "iter 1810: loss 1.4983, time 328.68ms, mfu 0.72%\n",
            "iter 1820: loss 1.3960, time 330.47ms, mfu 0.73%\n",
            "iter 1830: loss 1.4957, time 325.92ms, mfu 0.74%\n",
            "iter 1840: loss 1.4244, time 325.67ms, mfu 0.74%\n",
            "iter 1850: loss 1.3800, time 336.49ms, mfu 0.74%\n",
            "iter 1860: loss 1.3552, time 328.92ms, mfu 0.75%\n",
            "iter 1870: loss 1.4010, time 329.58ms, mfu 0.75%\n",
            "iter 1880: loss 1.4126, time 330.84ms, mfu 0.76%\n",
            "iter 1890: loss 1.4561, time 327.92ms, mfu 0.76%\n",
            "iter 1900: loss 1.3709, time 328.25ms, mfu 0.76%\n",
            "iter 1910: loss 1.3813, time 324.89ms, mfu 0.77%\n",
            "iter 1920: loss 1.4753, time 327.83ms, mfu 0.77%\n",
            "iter 1930: loss 1.4090, time 330.38ms, mfu 0.77%\n",
            "iter 1940: loss 1.4498, time 325.19ms, mfu 0.77%\n",
            "iter 1950: loss 1.4111, time 324.14ms, mfu 0.78%\n",
            "iter 1960: loss 1.4532, time 334.82ms, mfu 0.78%\n",
            "iter 1970: loss 1.3495, time 331.06ms, mfu 0.78%\n",
            "iter 1980: loss 1.4106, time 332.64ms, mfu 0.78%\n",
            "iter 1990: loss 1.3049, time 328.41ms, mfu 0.78%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 16/32: b64_L4_H4_E256_BS16_MI2000_D20_s16 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H4_E256_BS16_MI2000_D20_s16.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 16\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2850, val loss 4.2800\n",
            "iter 0: loss 4.2730, time 2035.62ms, mfu -100.00%\n",
            "iter 10: loss 4.2315, time 331.44ms, mfu 0.78%\n",
            "iter 20: loss 4.1037, time 339.98ms, mfu 0.78%\n",
            "iter 30: loss 3.9665, time 330.32ms, mfu 0.78%\n",
            "iter 40: loss 3.7292, time 327.01ms, mfu 0.78%\n",
            "iter 50: loss 3.6142, time 331.31ms, mfu 0.78%\n",
            "iter 60: loss 3.5198, time 339.25ms, mfu 0.78%\n",
            "iter 70: loss 3.3738, time 331.26ms, mfu 0.78%\n",
            "iter 80: loss 3.4002, time 330.37ms, mfu 0.78%\n",
            "iter 90: loss 3.3333, time 335.23ms, mfu 0.78%\n",
            "iter 100: loss 3.1516, time 331.61ms, mfu 0.78%\n",
            "iter 110: loss 3.0573, time 332.35ms, mfu 0.78%\n",
            "iter 120: loss 3.0091, time 334.64ms, mfu 0.78%\n",
            "iter 130: loss 2.9933, time 333.13ms, mfu 0.78%\n",
            "iter 140: loss 2.9215, time 327.66ms, mfu 0.78%\n",
            "iter 150: loss 2.8241, time 329.24ms, mfu 0.78%\n",
            "iter 160: loss 2.8441, time 326.84ms, mfu 0.78%\n",
            "iter 170: loss 2.8462, time 335.31ms, mfu 0.78%\n",
            "iter 180: loss 2.8004, time 327.93ms, mfu 0.78%\n",
            "iter 190: loss 2.8319, time 331.43ms, mfu 0.78%\n",
            "step 200: train loss 2.6858, val loss 2.6943\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 200: loss 2.7566, time 1775.91ms, mfu 0.72%\n",
            "iter 210: loss 2.7959, time 328.76ms, mfu 0.73%\n",
            "iter 220: loss 2.7104, time 326.58ms, mfu 0.73%\n",
            "iter 230: loss 2.7103, time 334.98ms, mfu 0.74%\n",
            "iter 240: loss 2.7288, time 334.60ms, mfu 0.74%\n",
            "iter 250: loss 2.6088, time 334.76ms, mfu 0.74%\n",
            "iter 260: loss 2.6672, time 334.15ms, mfu 0.75%\n",
            "iter 270: loss 2.5593, time 333.42ms, mfu 0.75%\n",
            "iter 280: loss 2.5997, time 332.19ms, mfu 0.75%\n",
            "iter 290: loss 2.5790, time 335.37ms, mfu 0.76%\n",
            "iter 300: loss 2.6470, time 328.17ms, mfu 0.76%\n",
            "iter 310: loss 2.5504, time 338.29ms, mfu 0.76%\n",
            "iter 320: loss 2.5299, time 336.91ms, mfu 0.76%\n",
            "iter 330: loss 2.4607, time 333.66ms, mfu 0.76%\n",
            "iter 340: loss 2.4506, time 333.91ms, mfu 0.76%\n",
            "iter 350: loss 2.4983, time 328.76ms, mfu 0.77%\n",
            "iter 360: loss 2.5082, time 327.05ms, mfu 0.77%\n",
            "iter 370: loss 2.4020, time 328.03ms, mfu 0.77%\n",
            "iter 380: loss 2.4859, time 333.28ms, mfu 0.77%\n",
            "iter 390: loss 2.4005, time 326.83ms, mfu 0.77%\n",
            "step 400: train loss 2.3829, val loss 2.3900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 400: loss 2.4064, time 1788.11ms, mfu 0.71%\n",
            "iter 410: loss 2.4550, time 330.21ms, mfu 0.72%\n",
            "iter 420: loss 2.4256, time 327.13ms, mfu 0.73%\n",
            "iter 430: loss 2.4152, time 324.79ms, mfu 0.73%\n",
            "iter 440: loss 2.3216, time 333.11ms, mfu 0.74%\n",
            "iter 450: loss 2.4192, time 329.77ms, mfu 0.74%\n",
            "iter 460: loss 2.3992, time 325.05ms, mfu 0.75%\n",
            "iter 470: loss 2.3835, time 328.78ms, mfu 0.75%\n",
            "iter 480: loss 2.2425, time 330.43ms, mfu 0.76%\n",
            "iter 490: loss 2.2764, time 343.79ms, mfu 0.76%\n",
            "iter 500: loss 2.3621, time 331.43ms, mfu 0.76%\n",
            "iter 510: loss 2.3225, time 330.44ms, mfu 0.76%\n",
            "iter 520: loss 2.1634, time 329.50ms, mfu 0.76%\n",
            "iter 530: loss 2.2345, time 329.56ms, mfu 0.77%\n",
            "iter 540: loss 2.2840, time 326.15ms, mfu 0.77%\n",
            "iter 550: loss 2.2918, time 324.03ms, mfu 0.77%\n",
            "iter 560: loss 2.3251, time 333.98ms, mfu 0.77%\n",
            "iter 570: loss 2.2381, time 336.38ms, mfu 0.77%\n",
            "iter 580: loss 2.1426, time 332.89ms, mfu 0.77%\n",
            "iter 590: loss 2.1770, time 335.00ms, mfu 0.77%\n",
            "step 600: train loss 2.1307, val loss 2.1626\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 600: loss 2.2942, time 1786.16ms, mfu 0.71%\n",
            "iter 610: loss 2.1845, time 336.22ms, mfu 0.72%\n",
            "iter 620: loss 2.2296, time 332.29ms, mfu 0.72%\n",
            "iter 630: loss 2.1813, time 376.16ms, mfu 0.72%\n",
            "iter 640: loss 2.2262, time 328.92ms, mfu 0.73%\n",
            "iter 650: loss 2.1863, time 331.13ms, mfu 0.73%\n",
            "iter 660: loss 2.1370, time 324.54ms, mfu 0.74%\n",
            "iter 670: loss 2.2148, time 327.78ms, mfu 0.74%\n",
            "iter 680: loss 2.0723, time 330.09ms, mfu 0.75%\n",
            "iter 690: loss 2.0935, time 326.68ms, mfu 0.75%\n",
            "iter 700: loss 2.0796, time 329.97ms, mfu 0.76%\n",
            "iter 710: loss 2.2140, time 331.26ms, mfu 0.76%\n",
            "iter 720: loss 2.1091, time 326.34ms, mfu 0.76%\n",
            "iter 730: loss 2.0848, time 328.01ms, mfu 0.77%\n",
            "iter 740: loss 2.1743, time 343.15ms, mfu 0.76%\n",
            "iter 750: loss 2.1163, time 325.03ms, mfu 0.77%\n",
            "iter 760: loss 2.0377, time 321.93ms, mfu 0.77%\n",
            "iter 770: loss 2.0608, time 324.43ms, mfu 0.77%\n",
            "iter 780: loss 2.0584, time 332.34ms, mfu 0.78%\n",
            "iter 790: loss 1.9995, time 326.09ms, mfu 0.78%\n",
            "step 800: train loss 1.9421, val loss 2.0161\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 800: loss 2.0287, time 1762.52ms, mfu 0.71%\n",
            "iter 810: loss 2.0934, time 339.13ms, mfu 0.72%\n",
            "iter 820: loss 2.0733, time 330.11ms, mfu 0.73%\n",
            "iter 830: loss 2.1231, time 330.59ms, mfu 0.73%\n",
            "iter 840: loss 2.0707, time 328.46ms, mfu 0.74%\n",
            "iter 850: loss 1.9247, time 332.46ms, mfu 0.74%\n",
            "iter 860: loss 2.0270, time 333.59ms, mfu 0.75%\n",
            "iter 870: loss 2.0116, time 332.42ms, mfu 0.75%\n",
            "iter 880: loss 1.8907, time 330.00ms, mfu 0.75%\n",
            "iter 890: loss 1.9846, time 327.35ms, mfu 0.76%\n",
            "iter 900: loss 1.9627, time 329.19ms, mfu 0.76%\n",
            "iter 910: loss 1.9590, time 327.14ms, mfu 0.76%\n",
            "iter 920: loss 1.9093, time 329.12ms, mfu 0.77%\n",
            "iter 930: loss 2.0333, time 326.31ms, mfu 0.77%\n",
            "iter 940: loss 1.9720, time 331.12ms, mfu 0.77%\n",
            "iter 950: loss 1.9349, time 342.29ms, mfu 0.77%\n",
            "iter 960: loss 1.8700, time 328.93ms, mfu 0.77%\n",
            "iter 970: loss 1.8770, time 327.61ms, mfu 0.77%\n",
            "iter 980: loss 1.9396, time 328.60ms, mfu 0.78%\n",
            "iter 990: loss 1.9667, time 337.11ms, mfu 0.77%\n",
            "step 1000: train loss 1.7654, val loss 1.9078\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1000: loss 1.9307, time 1788.24ms, mfu 0.71%\n",
            "iter 1010: loss 1.8512, time 329.18ms, mfu 0.72%\n",
            "iter 1020: loss 1.8333, time 327.56ms, mfu 0.73%\n",
            "iter 1030: loss 1.8856, time 332.99ms, mfu 0.73%\n",
            "iter 1040: loss 1.8618, time 328.21ms, mfu 0.74%\n",
            "iter 1050: loss 1.7886, time 329.89ms, mfu 0.74%\n",
            "iter 1060: loss 1.9513, time 335.52ms, mfu 0.75%\n",
            "iter 1070: loss 1.8428, time 334.86ms, mfu 0.75%\n",
            "iter 1080: loss 1.7668, time 327.87ms, mfu 0.75%\n",
            "iter 1090: loss 1.8130, time 324.10ms, mfu 0.76%\n",
            "iter 1100: loss 1.8274, time 332.01ms, mfu 0.76%\n",
            "iter 1110: loss 1.8926, time 328.63ms, mfu 0.76%\n",
            "iter 1120: loss 1.8647, time 326.00ms, mfu 0.77%\n",
            "iter 1130: loss 1.7834, time 328.05ms, mfu 0.77%\n",
            "iter 1140: loss 1.7813, time 329.48ms, mfu 0.77%\n",
            "iter 1150: loss 1.8063, time 328.84ms, mfu 0.77%\n",
            "iter 1160: loss 1.7422, time 323.83ms, mfu 0.78%\n",
            "iter 1170: loss 1.7323, time 334.99ms, mfu 0.78%\n",
            "iter 1180: loss 1.8274, time 327.84ms, mfu 0.78%\n",
            "iter 1190: loss 1.7218, time 324.42ms, mfu 0.78%\n",
            "step 1200: train loss 1.6389, val loss 1.8167\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1200: loss 1.6867, time 1792.36ms, mfu 0.72%\n",
            "iter 1210: loss 1.7805, time 329.78ms, mfu 0.72%\n",
            "iter 1220: loss 1.7842, time 329.38ms, mfu 0.73%\n",
            "iter 1230: loss 1.7676, time 329.92ms, mfu 0.74%\n",
            "iter 1240: loss 1.7657, time 340.00ms, mfu 0.74%\n",
            "iter 1250: loss 1.6540, time 331.56ms, mfu 0.74%\n",
            "iter 1260: loss 1.7733, time 327.60ms, mfu 0.75%\n",
            "iter 1270: loss 1.7007, time 332.95ms, mfu 0.75%\n",
            "iter 1280: loss 1.6105, time 333.07ms, mfu 0.75%\n",
            "iter 1290: loss 1.6705, time 331.84ms, mfu 0.76%\n",
            "iter 1300: loss 1.6642, time 330.62ms, mfu 0.76%\n",
            "iter 1310: loss 1.7572, time 331.21ms, mfu 0.76%\n",
            "iter 1320: loss 1.6385, time 324.40ms, mfu 0.77%\n",
            "iter 1330: loss 1.5835, time 324.97ms, mfu 0.77%\n",
            "iter 1340: loss 1.5761, time 327.36ms, mfu 0.77%\n",
            "iter 1350: loss 1.6781, time 337.28ms, mfu 0.77%\n",
            "iter 1360: loss 1.6896, time 338.39ms, mfu 0.77%\n",
            "iter 1370: loss 1.5861, time 330.02ms, mfu 0.77%\n",
            "iter 1380: loss 1.6714, time 341.00ms, mfu 0.77%\n",
            "iter 1390: loss 1.6894, time 332.36ms, mfu 0.77%\n",
            "step 1400: train loss 1.5546, val loss 1.7320\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1400: loss 1.6899, time 1782.97ms, mfu 0.71%\n",
            "iter 1410: loss 1.5938, time 326.38ms, mfu 0.72%\n",
            "iter 1420: loss 1.7358, time 334.71ms, mfu 0.72%\n",
            "iter 1430: loss 1.6361, time 328.69ms, mfu 0.73%\n",
            "iter 1440: loss 1.6164, time 330.92ms, mfu 0.74%\n",
            "iter 1450: loss 1.6530, time 330.53ms, mfu 0.74%\n",
            "iter 1460: loss 1.5689, time 331.94ms, mfu 0.74%\n",
            "iter 1470: loss 1.6968, time 331.99ms, mfu 0.75%\n",
            "iter 1480: loss 1.6245, time 330.67ms, mfu 0.75%\n",
            "iter 1490: loss 1.5978, time 340.66ms, mfu 0.75%\n",
            "iter 1500: loss 1.6619, time 333.08ms, mfu 0.76%\n",
            "iter 1510: loss 1.6507, time 327.47ms, mfu 0.76%\n",
            "iter 1520: loss 1.5805, time 328.55ms, mfu 0.76%\n",
            "iter 1530: loss 1.5593, time 331.59ms, mfu 0.76%\n",
            "iter 1540: loss 1.6410, time 329.73ms, mfu 0.77%\n",
            "iter 1550: loss 1.5967, time 331.68ms, mfu 0.77%\n",
            "iter 1560: loss 1.5534, time 336.25ms, mfu 0.77%\n",
            "iter 1570: loss 1.6019, time 335.94ms, mfu 0.77%\n",
            "iter 1580: loss 1.5788, time 328.31ms, mfu 0.77%\n",
            "iter 1590: loss 1.5943, time 330.99ms, mfu 0.77%\n",
            "step 1600: train loss 1.4833, val loss 1.6758\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1600: loss 1.6418, time 1787.49ms, mfu 0.71%\n",
            "iter 1610: loss 1.5433, time 328.30ms, mfu 0.72%\n",
            "iter 1620: loss 1.6941, time 323.46ms, mfu 0.73%\n",
            "iter 1630: loss 1.5379, time 335.66ms, mfu 0.73%\n",
            "iter 1640: loss 1.5487, time 325.23ms, mfu 0.74%\n",
            "iter 1650: loss 1.6499, time 328.74ms, mfu 0.74%\n",
            "iter 1660: loss 1.5226, time 330.61ms, mfu 0.75%\n",
            "iter 1670: loss 1.5949, time 329.55ms, mfu 0.75%\n",
            "iter 1680: loss 1.5914, time 328.36ms, mfu 0.76%\n",
            "iter 1690: loss 1.6140, time 328.81ms, mfu 0.76%\n",
            "iter 1700: loss 1.6600, time 332.78ms, mfu 0.76%\n",
            "iter 1710: loss 1.5680, time 326.93ms, mfu 0.76%\n",
            "iter 1720: loss 1.5795, time 322.75ms, mfu 0.77%\n",
            "iter 1730: loss 1.6397, time 325.17ms, mfu 0.77%\n",
            "iter 1740: loss 1.4783, time 332.11ms, mfu 0.77%\n",
            "iter 1750: loss 1.5638, time 330.65ms, mfu 0.77%\n",
            "iter 1760: loss 1.5873, time 328.85ms, mfu 0.78%\n",
            "iter 1770: loss 1.4477, time 329.42ms, mfu 0.78%\n",
            "iter 1780: loss 1.5415, time 329.19ms, mfu 0.78%\n",
            "iter 1790: loss 1.5922, time 331.17ms, mfu 0.78%\n",
            "step 1800: train loss 1.4247, val loss 1.6134\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1800: loss 1.4337, time 1789.69ms, mfu 0.71%\n",
            "iter 1810: loss 1.5606, time 335.78ms, mfu 0.72%\n",
            "iter 1820: loss 1.5165, time 329.90ms, mfu 0.73%\n",
            "iter 1830: loss 1.6092, time 328.47ms, mfu 0.73%\n",
            "iter 1840: loss 1.5311, time 328.92ms, mfu 0.74%\n",
            "iter 1850: loss 1.4973, time 330.62ms, mfu 0.74%\n",
            "iter 1860: loss 1.4748, time 326.27ms, mfu 0.75%\n",
            "iter 1870: loss 1.5211, time 325.19ms, mfu 0.75%\n",
            "iter 1880: loss 1.5106, time 337.30ms, mfu 0.76%\n",
            "iter 1890: loss 1.5462, time 331.59ms, mfu 0.76%\n",
            "iter 1900: loss 1.4661, time 330.91ms, mfu 0.76%\n",
            "iter 1910: loss 1.4998, time 338.59ms, mfu 0.76%\n",
            "iter 1920: loss 1.5741, time 333.29ms, mfu 0.76%\n",
            "iter 1930: loss 1.5002, time 329.00ms, mfu 0.77%\n",
            "iter 1940: loss 1.5236, time 329.59ms, mfu 0.77%\n",
            "iter 1950: loss 1.4908, time 338.21ms, mfu 0.77%\n",
            "iter 1960: loss 1.5615, time 338.89ms, mfu 0.77%\n",
            "iter 1970: loss 1.4530, time 338.00ms, mfu 0.77%\n",
            "iter 1980: loss 1.5236, time 334.00ms, mfu 0.77%\n",
            "iter 1990: loss 1.4195, time 342.79ms, mfu 0.77%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 17/32: b64_L4_H8_E128_BS8_MI1000_D10_s17 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS8_MI1000_D10_s17.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D10_s17\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 17\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1699, val loss 4.1654\n",
            "iter 0: loss 4.1824, time 1911.05ms, mfu -100.00%\n",
            "iter 10: loss 4.1605, time 333.94ms, mfu 0.10%\n",
            "iter 20: loss 4.1255, time 322.04ms, mfu 0.10%\n",
            "iter 30: loss 4.0581, time 322.51ms, mfu 0.10%\n",
            "iter 40: loss 4.0092, time 322.80ms, mfu 0.10%\n",
            "iter 50: loss 3.9070, time 325.59ms, mfu 0.10%\n",
            "iter 60: loss 3.8066, time 325.05ms, mfu 0.10%\n",
            "iter 70: loss 3.7784, time 323.59ms, mfu 0.10%\n",
            "iter 80: loss 3.7141, time 322.59ms, mfu 0.10%\n",
            "iter 90: loss 3.6923, time 330.76ms, mfu 0.10%\n",
            "iter 100: loss 3.6684, time 322.44ms, mfu 0.10%\n",
            "iter 110: loss 3.5508, time 323.18ms, mfu 0.10%\n",
            "iter 120: loss 3.5703, time 319.01ms, mfu 0.10%\n",
            "iter 130: loss 3.5038, time 320.29ms, mfu 0.10%\n",
            "iter 140: loss 3.4906, time 316.73ms, mfu 0.10%\n",
            "iter 150: loss 3.5015, time 318.82ms, mfu 0.10%\n",
            "iter 160: loss 3.4419, time 324.97ms, mfu 0.10%\n",
            "iter 170: loss 3.3934, time 320.48ms, mfu 0.10%\n",
            "iter 180: loss 3.3507, time 317.61ms, mfu 0.10%\n",
            "iter 190: loss 3.3321, time 316.88ms, mfu 0.11%\n",
            "step 200: train loss 3.2488, val loss 3.2542\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 200: loss 3.3137, time 1596.40ms, mfu 0.10%\n",
            "iter 210: loss 3.2380, time 317.51ms, mfu 0.10%\n",
            "iter 220: loss 3.2696, time 318.98ms, mfu 0.10%\n",
            "iter 230: loss 3.2018, time 321.52ms, mfu 0.10%\n",
            "iter 240: loss 3.2057, time 319.99ms, mfu 0.10%\n",
            "iter 250: loss 3.1395, time 322.38ms, mfu 0.10%\n",
            "iter 260: loss 3.1902, time 325.66ms, mfu 0.10%\n",
            "iter 270: loss 3.1295, time 316.07ms, mfu 0.10%\n",
            "iter 280: loss 3.0655, time 326.32ms, mfu 0.10%\n",
            "iter 290: loss 3.0082, time 317.92ms, mfu 0.10%\n",
            "iter 300: loss 3.0664, time 314.53ms, mfu 0.10%\n",
            "iter 310: loss 3.0207, time 317.55ms, mfu 0.10%\n",
            "iter 320: loss 3.0151, time 320.01ms, mfu 0.10%\n",
            "iter 330: loss 2.9590, time 314.52ms, mfu 0.10%\n",
            "iter 340: loss 2.9054, time 315.62ms, mfu 0.10%\n",
            "iter 350: loss 2.9307, time 322.83ms, mfu 0.10%\n",
            "iter 360: loss 2.9218, time 315.02ms, mfu 0.10%\n",
            "iter 370: loss 2.9370, time 319.16ms, mfu 0.10%\n",
            "iter 380: loss 2.8909, time 318.34ms, mfu 0.11%\n",
            "iter 390: loss 2.7711, time 327.13ms, mfu 0.10%\n",
            "step 400: train loss 2.7651, val loss 2.7746\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 400: loss 2.7912, time 1553.43ms, mfu 0.10%\n",
            "iter 410: loss 2.8483, time 319.87ms, mfu 0.10%\n",
            "iter 420: loss 2.6866, time 321.72ms, mfu 0.10%\n",
            "iter 430: loss 2.7748, time 321.30ms, mfu 0.10%\n",
            "iter 440: loss 2.7563, time 316.88ms, mfu 0.10%\n",
            "iter 450: loss 2.7361, time 318.44ms, mfu 0.10%\n",
            "iter 460: loss 2.7468, time 317.31ms, mfu 0.10%\n",
            "iter 470: loss 2.6437, time 318.98ms, mfu 0.10%\n",
            "iter 480: loss 2.6369, time 321.88ms, mfu 0.10%\n",
            "iter 490: loss 2.7019, time 316.74ms, mfu 0.10%\n",
            "iter 500: loss 2.5412, time 332.89ms, mfu 0.10%\n",
            "iter 510: loss 2.7105, time 321.62ms, mfu 0.10%\n",
            "iter 520: loss 2.5363, time 323.89ms, mfu 0.10%\n",
            "iter 530: loss 2.5868, time 322.80ms, mfu 0.10%\n",
            "iter 540: loss 2.5106, time 325.60ms, mfu 0.10%\n",
            "iter 550: loss 2.6681, time 319.70ms, mfu 0.10%\n",
            "iter 560: loss 2.5476, time 320.97ms, mfu 0.10%\n",
            "iter 570: loss 2.6046, time 330.81ms, mfu 0.10%\n",
            "iter 580: loss 2.5277, time 322.18ms, mfu 0.10%\n",
            "iter 590: loss 2.5470, time 314.72ms, mfu 0.10%\n",
            "step 600: train loss 2.4731, val loss 2.4710\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 600: loss 2.4900, time 1569.27ms, mfu 0.10%\n",
            "iter 610: loss 2.4559, time 336.31ms, mfu 0.10%\n",
            "iter 620: loss 2.5213, time 321.48ms, mfu 0.10%\n",
            "iter 630: loss 2.4336, time 321.11ms, mfu 0.10%\n",
            "iter 640: loss 2.5431, time 318.93ms, mfu 0.10%\n",
            "iter 650: loss 2.4705, time 318.03ms, mfu 0.10%\n",
            "iter 660: loss 2.4117, time 319.84ms, mfu 0.10%\n",
            "iter 670: loss 2.5031, time 316.52ms, mfu 0.10%\n",
            "iter 680: loss 2.4878, time 321.40ms, mfu 0.10%\n",
            "iter 690: loss 2.3874, time 318.19ms, mfu 0.10%\n",
            "iter 700: loss 2.3665, time 317.73ms, mfu 0.10%\n",
            "iter 710: loss 2.3629, time 316.55ms, mfu 0.10%\n",
            "iter 720: loss 2.4420, time 328.87ms, mfu 0.10%\n",
            "iter 730: loss 2.3685, time 315.70ms, mfu 0.10%\n",
            "iter 740: loss 2.4101, time 317.22ms, mfu 0.10%\n",
            "iter 750: loss 2.3774, time 318.56ms, mfu 0.10%\n",
            "iter 760: loss 2.2968, time 323.54ms, mfu 0.10%\n",
            "iter 770: loss 2.2612, time 317.30ms, mfu 0.10%\n",
            "iter 780: loss 2.3043, time 316.38ms, mfu 0.10%\n",
            "iter 790: loss 2.4478, time 320.73ms, mfu 0.10%\n",
            "step 800: train loss 2.2983, val loss 2.2981\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 800: loss 2.4011, time 1595.82ms, mfu 0.10%\n",
            "iter 810: loss 2.3126, time 313.08ms, mfu 0.10%\n",
            "iter 820: loss 2.3665, time 314.24ms, mfu 0.10%\n",
            "iter 830: loss 2.3700, time 319.14ms, mfu 0.10%\n",
            "iter 840: loss 2.2468, time 320.51ms, mfu 0.10%\n",
            "iter 850: loss 2.2714, time 317.05ms, mfu 0.10%\n",
            "iter 860: loss 2.2612, time 318.37ms, mfu 0.10%\n",
            "iter 870: loss 2.2699, time 318.35ms, mfu 0.10%\n",
            "iter 880: loss 2.2487, time 321.49ms, mfu 0.10%\n",
            "iter 890: loss 2.2640, time 319.66ms, mfu 0.10%\n",
            "iter 900: loss 2.2882, time 318.34ms, mfu 0.10%\n",
            "iter 910: loss 2.3068, time 328.42ms, mfu 0.10%\n",
            "iter 920: loss 2.2355, time 322.41ms, mfu 0.10%\n",
            "iter 930: loss 2.2383, time 326.04ms, mfu 0.10%\n",
            "iter 940: loss 2.1963, time 333.62ms, mfu 0.10%\n",
            "iter 950: loss 2.2900, time 330.25ms, mfu 0.10%\n",
            "iter 960: loss 2.2186, time 345.57ms, mfu 0.10%\n",
            "iter 970: loss 2.3189, time 335.66ms, mfu 0.10%\n",
            "iter 980: loss 2.2262, time 320.49ms, mfu 0.10%\n",
            "iter 990: loss 2.1613, time 333.28ms, mfu 0.10%\n",
            "step 1000: train loss 2.1446, val loss 2.1646\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 1000: loss 2.2170, time 1609.83ms, mfu 0.09%\n",
            "\n",
            "=== Experiment 18/32: b64_L4_H8_E128_BS8_MI1000_D20_s18 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS8_MI1000_D20_s18.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D20_s18\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 18\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1699, val loss 4.1654\n",
            "iter 0: loss 4.1799, time 1935.27ms, mfu -100.00%\n",
            "iter 10: loss 4.1610, time 326.86ms, mfu 0.10%\n",
            "iter 20: loss 4.1329, time 329.41ms, mfu 0.10%\n",
            "iter 30: loss 4.0710, time 335.43ms, mfu 0.10%\n",
            "iter 40: loss 4.0337, time 330.32ms, mfu 0.10%\n",
            "iter 50: loss 3.9370, time 328.69ms, mfu 0.10%\n",
            "iter 60: loss 3.8449, time 326.26ms, mfu 0.10%\n",
            "iter 70: loss 3.8059, time 326.32ms, mfu 0.10%\n",
            "iter 80: loss 3.7368, time 332.66ms, mfu 0.10%\n",
            "iter 90: loss 3.7141, time 320.61ms, mfu 0.10%\n",
            "iter 100: loss 3.6889, time 320.68ms, mfu 0.10%\n",
            "iter 110: loss 3.5779, time 341.84ms, mfu 0.10%\n",
            "iter 120: loss 3.6121, time 324.55ms, mfu 0.10%\n",
            "iter 130: loss 3.5445, time 328.64ms, mfu 0.10%\n",
            "iter 140: loss 3.5304, time 319.39ms, mfu 0.10%\n",
            "iter 150: loss 3.5367, time 324.35ms, mfu 0.10%\n",
            "iter 160: loss 3.4878, time 327.31ms, mfu 0.10%\n",
            "iter 170: loss 3.4432, time 334.67ms, mfu 0.10%\n",
            "iter 180: loss 3.3858, time 330.02ms, mfu 0.10%\n",
            "iter 190: loss 3.3763, time 334.19ms, mfu 0.10%\n",
            "step 200: train loss 3.2670, val loss 3.2730\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 200: loss 3.3505, time 1589.11ms, mfu 0.10%\n",
            "iter 210: loss 3.2638, time 323.52ms, mfu 0.10%\n",
            "iter 220: loss 3.3070, time 326.61ms, mfu 0.10%\n",
            "iter 230: loss 3.2427, time 333.50ms, mfu 0.10%\n",
            "iter 240: loss 3.2336, time 322.62ms, mfu 0.10%\n",
            "iter 250: loss 3.1841, time 340.06ms, mfu 0.10%\n",
            "iter 260: loss 3.2338, time 325.15ms, mfu 0.10%\n",
            "iter 270: loss 3.1678, time 326.72ms, mfu 0.10%\n",
            "iter 280: loss 3.1122, time 325.68ms, mfu 0.10%\n",
            "iter 290: loss 3.0356, time 328.17ms, mfu 0.10%\n",
            "iter 300: loss 3.0928, time 325.34ms, mfu 0.10%\n",
            "iter 310: loss 3.0530, time 327.88ms, mfu 0.10%\n",
            "iter 320: loss 3.0552, time 324.33ms, mfu 0.10%\n",
            "iter 330: loss 2.9781, time 324.90ms, mfu 0.10%\n",
            "iter 340: loss 2.9297, time 324.04ms, mfu 0.10%\n",
            "iter 350: loss 2.9701, time 326.09ms, mfu 0.10%\n",
            "iter 360: loss 2.9537, time 334.29ms, mfu 0.10%\n",
            "iter 370: loss 2.9705, time 327.40ms, mfu 0.10%\n",
            "iter 380: loss 2.9256, time 328.31ms, mfu 0.10%\n",
            "iter 390: loss 2.8049, time 325.20ms, mfu 0.10%\n",
            "step 400: train loss 2.7851, val loss 2.7929\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 400: loss 2.8271, time 1617.12ms, mfu 0.09%\n",
            "iter 410: loss 2.8839, time 320.67ms, mfu 0.10%\n",
            "iter 420: loss 2.7152, time 322.62ms, mfu 0.10%\n",
            "iter 430: loss 2.7936, time 346.83ms, mfu 0.10%\n",
            "iter 440: loss 2.7864, time 323.97ms, mfu 0.10%\n",
            "iter 450: loss 2.7673, time 322.63ms, mfu 0.10%\n",
            "iter 460: loss 2.7756, time 323.65ms, mfu 0.10%\n",
            "iter 470: loss 2.6827, time 330.54ms, mfu 0.10%\n",
            "iter 480: loss 2.6745, time 324.13ms, mfu 0.10%\n",
            "iter 490: loss 2.7325, time 328.99ms, mfu 0.10%\n",
            "iter 500: loss 2.5853, time 320.08ms, mfu 0.10%\n",
            "iter 510: loss 2.7292, time 327.14ms, mfu 0.10%\n",
            "iter 520: loss 2.5645, time 320.72ms, mfu 0.10%\n",
            "iter 530: loss 2.6120, time 324.12ms, mfu 0.10%\n",
            "iter 540: loss 2.5463, time 320.24ms, mfu 0.10%\n",
            "iter 550: loss 2.7009, time 324.38ms, mfu 0.10%\n",
            "iter 560: loss 2.5563, time 324.52ms, mfu 0.10%\n",
            "iter 570: loss 2.6263, time 327.83ms, mfu 0.10%\n",
            "iter 580: loss 2.5789, time 337.82ms, mfu 0.10%\n",
            "iter 590: loss 2.5876, time 320.67ms, mfu 0.10%\n",
            "step 600: train loss 2.5080, val loss 2.5028\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 600: loss 2.5421, time 1604.78ms, mfu 0.09%\n",
            "iter 610: loss 2.4879, time 323.66ms, mfu 0.10%\n",
            "iter 620: loss 2.5851, time 318.95ms, mfu 0.10%\n",
            "iter 630: loss 2.4783, time 335.78ms, mfu 0.10%\n",
            "iter 640: loss 2.5702, time 322.98ms, mfu 0.10%\n",
            "iter 650: loss 2.5059, time 320.74ms, mfu 0.10%\n",
            "iter 660: loss 2.4587, time 322.08ms, mfu 0.10%\n",
            "iter 670: loss 2.5286, time 323.04ms, mfu 0.10%\n",
            "iter 680: loss 2.5319, time 325.86ms, mfu 0.10%\n",
            "iter 690: loss 2.4293, time 324.29ms, mfu 0.10%\n",
            "iter 700: loss 2.4287, time 323.34ms, mfu 0.10%\n",
            "iter 710: loss 2.4020, time 330.51ms, mfu 0.10%\n",
            "iter 720: loss 2.4799, time 324.43ms, mfu 0.10%\n",
            "iter 730: loss 2.4038, time 330.88ms, mfu 0.10%\n",
            "iter 740: loss 2.4515, time 323.30ms, mfu 0.10%\n",
            "iter 750: loss 2.4247, time 322.06ms, mfu 0.10%\n",
            "iter 760: loss 2.3505, time 331.41ms, mfu 0.10%\n",
            "iter 770: loss 2.3194, time 320.82ms, mfu 0.10%\n",
            "iter 780: loss 2.3756, time 324.37ms, mfu 0.10%\n",
            "iter 790: loss 2.4981, time 325.71ms, mfu 0.10%\n",
            "step 800: train loss 2.3366, val loss 2.3400\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 800: loss 2.4234, time 1618.73ms, mfu 0.09%\n",
            "iter 810: loss 2.3519, time 324.20ms, mfu 0.10%\n",
            "iter 820: loss 2.3946, time 322.76ms, mfu 0.10%\n",
            "iter 830: loss 2.4094, time 335.09ms, mfu 0.10%\n",
            "iter 840: loss 2.3259, time 334.07ms, mfu 0.10%\n",
            "iter 850: loss 2.3215, time 324.57ms, mfu 0.10%\n",
            "iter 860: loss 2.3014, time 326.82ms, mfu 0.10%\n",
            "iter 870: loss 2.3233, time 331.44ms, mfu 0.10%\n",
            "iter 880: loss 2.3234, time 322.53ms, mfu 0.10%\n",
            "iter 890: loss 2.3118, time 326.11ms, mfu 0.10%\n",
            "iter 900: loss 2.3707, time 335.35ms, mfu 0.10%\n",
            "iter 910: loss 2.3720, time 355.00ms, mfu 0.10%\n",
            "iter 920: loss 2.2997, time 327.69ms, mfu 0.10%\n",
            "iter 930: loss 2.2919, time 323.07ms, mfu 0.10%\n",
            "iter 940: loss 2.2529, time 322.79ms, mfu 0.10%\n",
            "iter 950: loss 2.3699, time 327.49ms, mfu 0.10%\n",
            "iter 960: loss 2.2900, time 321.11ms, mfu 0.10%\n",
            "iter 970: loss 2.4280, time 320.11ms, mfu 0.10%\n",
            "iter 980: loss 2.2771, time 322.95ms, mfu 0.10%\n",
            "iter 990: loss 2.2541, time 320.83ms, mfu 0.10%\n",
            "step 1000: train loss 2.2126, val loss 2.2270\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 1000: loss 2.2936, time 1585.13ms, mfu 0.09%\n",
            "\n",
            "=== Experiment 19/32: b64_L4_H8_E128_BS8_MI2000_D10_s19 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS8_MI2000_D10_s19.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 19\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1699, val loss 4.1654\n",
            "iter 0: loss 4.1824, time 1930.51ms, mfu -100.00%\n",
            "iter 10: loss 4.1605, time 323.28ms, mfu 0.10%\n",
            "iter 20: loss 4.1255, time 326.50ms, mfu 0.10%\n",
            "iter 30: loss 4.0581, time 327.20ms, mfu 0.10%\n",
            "iter 40: loss 4.0092, time 325.42ms, mfu 0.10%\n",
            "iter 50: loss 3.9070, time 329.58ms, mfu 0.10%\n",
            "iter 60: loss 3.8066, time 319.39ms, mfu 0.10%\n",
            "iter 70: loss 3.7784, time 336.24ms, mfu 0.10%\n",
            "iter 80: loss 3.7141, time 323.34ms, mfu 0.10%\n",
            "iter 90: loss 3.6923, time 322.62ms, mfu 0.10%\n",
            "iter 100: loss 3.6684, time 324.80ms, mfu 0.10%\n",
            "iter 110: loss 3.5508, time 337.62ms, mfu 0.10%\n",
            "iter 120: loss 3.5703, time 320.07ms, mfu 0.10%\n",
            "iter 130: loss 3.5038, time 324.93ms, mfu 0.10%\n",
            "iter 140: loss 3.4906, time 319.66ms, mfu 0.10%\n",
            "iter 150: loss 3.5015, time 323.04ms, mfu 0.10%\n",
            "iter 160: loss 3.4419, time 324.73ms, mfu 0.10%\n",
            "iter 170: loss 3.3934, time 321.72ms, mfu 0.10%\n",
            "iter 180: loss 3.3507, time 324.24ms, mfu 0.10%\n",
            "iter 190: loss 3.3321, time 317.24ms, mfu 0.10%\n",
            "step 200: train loss 3.2488, val loss 3.2542\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 200: loss 3.3137, time 1582.08ms, mfu 0.10%\n",
            "iter 210: loss 3.2380, time 315.41ms, mfu 0.10%\n",
            "iter 220: loss 3.2696, time 325.08ms, mfu 0.10%\n",
            "iter 230: loss 3.2018, time 329.84ms, mfu 0.10%\n",
            "iter 240: loss 3.2057, time 319.65ms, mfu 0.10%\n",
            "iter 250: loss 3.1395, time 320.59ms, mfu 0.10%\n",
            "iter 260: loss 3.1902, time 330.02ms, mfu 0.10%\n",
            "iter 270: loss 3.1295, time 322.39ms, mfu 0.10%\n",
            "iter 280: loss 3.0655, time 320.57ms, mfu 0.10%\n",
            "iter 290: loss 3.0082, time 320.75ms, mfu 0.10%\n",
            "iter 300: loss 3.0664, time 318.25ms, mfu 0.10%\n",
            "iter 310: loss 3.0207, time 319.27ms, mfu 0.10%\n",
            "iter 320: loss 3.0151, time 324.21ms, mfu 0.10%\n",
            "iter 330: loss 2.9590, time 324.09ms, mfu 0.10%\n",
            "iter 340: loss 2.9054, time 323.38ms, mfu 0.10%\n",
            "iter 350: loss 2.9307, time 322.01ms, mfu 0.10%\n",
            "iter 360: loss 2.9218, time 317.03ms, mfu 0.10%\n",
            "iter 370: loss 2.9370, time 319.65ms, mfu 0.10%\n",
            "iter 380: loss 2.8909, time 316.49ms, mfu 0.10%\n",
            "iter 390: loss 2.7711, time 321.72ms, mfu 0.10%\n",
            "step 400: train loss 2.7651, val loss 2.7746\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 400: loss 2.7912, time 1599.25ms, mfu 0.10%\n",
            "iter 410: loss 2.8483, time 328.73ms, mfu 0.10%\n",
            "iter 420: loss 2.6866, time 317.23ms, mfu 0.10%\n",
            "iter 430: loss 2.7748, time 322.12ms, mfu 0.10%\n",
            "iter 440: loss 2.7563, time 322.04ms, mfu 0.10%\n",
            "iter 450: loss 2.7361, time 316.62ms, mfu 0.10%\n",
            "iter 460: loss 2.7468, time 315.81ms, mfu 0.10%\n",
            "iter 470: loss 2.6437, time 318.64ms, mfu 0.10%\n",
            "iter 480: loss 2.6369, time 326.57ms, mfu 0.10%\n",
            "iter 490: loss 2.7019, time 324.41ms, mfu 0.10%\n",
            "iter 500: loss 2.5412, time 322.08ms, mfu 0.10%\n",
            "iter 510: loss 2.7105, time 316.65ms, mfu 0.10%\n",
            "iter 520: loss 2.5363, time 330.51ms, mfu 0.10%\n",
            "iter 530: loss 2.5868, time 320.76ms, mfu 0.10%\n",
            "iter 540: loss 2.5106, time 319.75ms, mfu 0.10%\n",
            "iter 550: loss 2.6681, time 317.93ms, mfu 0.10%\n",
            "iter 560: loss 2.5476, time 319.11ms, mfu 0.10%\n",
            "iter 570: loss 2.6046, time 324.69ms, mfu 0.10%\n",
            "iter 580: loss 2.5277, time 318.41ms, mfu 0.10%\n",
            "iter 590: loss 2.5470, time 320.61ms, mfu 0.10%\n",
            "step 600: train loss 2.4731, val loss 2.4710\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 600: loss 2.4900, time 1614.19ms, mfu 0.10%\n",
            "iter 610: loss 2.4559, time 323.33ms, mfu 0.10%\n",
            "iter 620: loss 2.5213, time 325.55ms, mfu 0.10%\n",
            "iter 630: loss 2.4336, time 321.38ms, mfu 0.10%\n",
            "iter 640: loss 2.5431, time 321.39ms, mfu 0.10%\n",
            "iter 650: loss 2.4705, time 328.14ms, mfu 0.10%\n",
            "iter 660: loss 2.4117, time 325.20ms, mfu 0.10%\n",
            "iter 670: loss 2.5031, time 321.64ms, mfu 0.10%\n",
            "iter 680: loss 2.4878, time 327.96ms, mfu 0.10%\n",
            "iter 690: loss 2.3874, time 327.73ms, mfu 0.10%\n",
            "iter 700: loss 2.3665, time 338.14ms, mfu 0.10%\n",
            "iter 710: loss 2.3629, time 319.46ms, mfu 0.10%\n",
            "iter 720: loss 2.4420, time 354.61ms, mfu 0.10%\n",
            "iter 730: loss 2.3685, time 329.69ms, mfu 0.10%\n",
            "iter 740: loss 2.4101, time 363.18ms, mfu 0.10%\n",
            "iter 750: loss 2.3774, time 342.08ms, mfu 0.10%\n",
            "iter 760: loss 2.2968, time 322.47ms, mfu 0.10%\n",
            "iter 770: loss 2.2612, time 320.43ms, mfu 0.10%\n",
            "iter 780: loss 2.3043, time 351.53ms, mfu 0.10%\n",
            "iter 790: loss 2.4478, time 345.02ms, mfu 0.10%\n",
            "step 800: train loss 2.2983, val loss 2.2981\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 800: loss 2.4011, time 1607.68ms, mfu 0.09%\n",
            "iter 810: loss 2.3126, time 328.88ms, mfu 0.09%\n",
            "iter 820: loss 2.3665, time 322.98ms, mfu 0.09%\n",
            "iter 830: loss 2.3700, time 345.00ms, mfu 0.10%\n",
            "iter 840: loss 2.2468, time 330.14ms, mfu 0.10%\n",
            "iter 850: loss 2.2714, time 321.24ms, mfu 0.10%\n",
            "iter 860: loss 2.2612, time 319.96ms, mfu 0.10%\n",
            "iter 870: loss 2.2699, time 318.40ms, mfu 0.10%\n",
            "iter 880: loss 2.2487, time 334.01ms, mfu 0.10%\n",
            "iter 890: loss 2.2640, time 323.40ms, mfu 0.10%\n",
            "iter 900: loss 2.2882, time 319.87ms, mfu 0.10%\n",
            "iter 910: loss 2.3068, time 318.56ms, mfu 0.10%\n",
            "iter 920: loss 2.2355, time 339.47ms, mfu 0.10%\n",
            "iter 930: loss 2.2383, time 320.46ms, mfu 0.10%\n",
            "iter 940: loss 2.1963, time 320.63ms, mfu 0.10%\n",
            "iter 950: loss 2.2900, time 319.90ms, mfu 0.10%\n",
            "iter 960: loss 2.2186, time 324.60ms, mfu 0.10%\n",
            "iter 970: loss 2.3189, time 320.77ms, mfu 0.10%\n",
            "iter 980: loss 2.2262, time 322.06ms, mfu 0.10%\n",
            "iter 990: loss 2.1613, time 329.79ms, mfu 0.10%\n",
            "step 1000: train loss 2.1446, val loss 2.1646\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1000: loss 2.2170, time 1577.48ms, mfu 0.09%\n",
            "iter 1010: loss 2.3157, time 317.77ms, mfu 0.10%\n",
            "iter 1020: loss 2.1547, time 319.01ms, mfu 0.10%\n",
            "iter 1030: loss 2.0866, time 326.58ms, mfu 0.10%\n",
            "iter 1040: loss 2.1824, time 319.73ms, mfu 0.10%\n",
            "iter 1050: loss 2.1881, time 321.52ms, mfu 0.10%\n",
            "iter 1060: loss 2.2839, time 319.14ms, mfu 0.10%\n",
            "iter 1070: loss 2.3211, time 321.10ms, mfu 0.10%\n",
            "iter 1080: loss 2.1700, time 319.73ms, mfu 0.10%\n",
            "iter 1090: loss 2.1502, time 317.49ms, mfu 0.10%\n",
            "iter 1100: loss 2.1430, time 334.91ms, mfu 0.10%\n",
            "iter 1110: loss 2.0804, time 316.78ms, mfu 0.10%\n",
            "iter 1120: loss 2.0880, time 317.20ms, mfu 0.10%\n",
            "iter 1130: loss 2.1114, time 319.19ms, mfu 0.10%\n",
            "iter 1140: loss 2.2696, time 331.96ms, mfu 0.10%\n",
            "iter 1150: loss 2.0936, time 320.45ms, mfu 0.10%\n",
            "iter 1160: loss 2.2149, time 319.23ms, mfu 0.10%\n",
            "iter 1170: loss 2.0819, time 317.74ms, mfu 0.10%\n",
            "iter 1180: loss 2.0991, time 324.08ms, mfu 0.10%\n",
            "iter 1190: loss 2.0205, time 318.77ms, mfu 0.10%\n",
            "step 1200: train loss 1.9958, val loss 2.0505\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1200: loss 2.0832, time 1610.43ms, mfu 0.10%\n",
            "iter 1210: loss 2.0896, time 324.00ms, mfu 0.10%\n",
            "iter 1220: loss 2.0055, time 321.72ms, mfu 0.10%\n",
            "iter 1230: loss 2.0525, time 340.38ms, mfu 0.10%\n",
            "iter 1240: loss 2.0478, time 324.34ms, mfu 0.10%\n",
            "iter 1250: loss 2.0994, time 321.89ms, mfu 0.10%\n",
            "iter 1260: loss 1.9189, time 316.94ms, mfu 0.10%\n",
            "iter 1270: loss 1.9359, time 321.66ms, mfu 0.10%\n",
            "iter 1280: loss 2.0362, time 318.76ms, mfu 0.10%\n",
            "iter 1290: loss 2.1383, time 327.31ms, mfu 0.10%\n",
            "iter 1300: loss 2.0452, time 320.30ms, mfu 0.10%\n",
            "iter 1310: loss 2.0085, time 322.15ms, mfu 0.10%\n",
            "iter 1320: loss 1.9695, time 319.52ms, mfu 0.10%\n",
            "iter 1330: loss 2.1166, time 321.10ms, mfu 0.10%\n",
            "iter 1340: loss 1.9785, time 319.71ms, mfu 0.10%\n",
            "iter 1350: loss 2.0608, time 321.44ms, mfu 0.10%\n",
            "iter 1360: loss 2.1273, time 326.39ms, mfu 0.10%\n",
            "iter 1370: loss 2.0311, time 319.50ms, mfu 0.10%\n",
            "iter 1380: loss 1.9764, time 319.26ms, mfu 0.10%\n",
            "iter 1390: loss 2.0540, time 324.61ms, mfu 0.10%\n",
            "step 1400: train loss 1.8965, val loss 1.9856\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1400: loss 1.8755, time 1616.03ms, mfu 0.10%\n",
            "iter 1410: loss 1.9203, time 321.37ms, mfu 0.10%\n",
            "iter 1420: loss 2.0908, time 321.53ms, mfu 0.10%\n",
            "iter 1430: loss 1.9366, time 335.76ms, mfu 0.10%\n",
            "iter 1440: loss 1.9077, time 322.35ms, mfu 0.10%\n",
            "iter 1450: loss 1.9323, time 320.96ms, mfu 0.10%\n",
            "iter 1460: loss 1.9717, time 327.48ms, mfu 0.10%\n",
            "iter 1470: loss 1.9456, time 325.91ms, mfu 0.10%\n",
            "iter 1480: loss 2.0045, time 317.31ms, mfu 0.10%\n",
            "iter 1490: loss 1.9564, time 319.36ms, mfu 0.10%\n",
            "iter 1500: loss 1.8613, time 317.42ms, mfu 0.10%\n",
            "iter 1510: loss 1.9073, time 323.74ms, mfu 0.10%\n",
            "iter 1520: loss 1.9395, time 324.03ms, mfu 0.10%\n",
            "iter 1530: loss 1.8428, time 324.87ms, mfu 0.10%\n",
            "iter 1540: loss 1.8839, time 321.03ms, mfu 0.10%\n",
            "iter 1550: loss 1.9612, time 321.94ms, mfu 0.10%\n",
            "iter 1560: loss 2.0161, time 332.37ms, mfu 0.10%\n",
            "iter 1570: loss 1.9849, time 329.08ms, mfu 0.10%\n",
            "iter 1580: loss 1.9150, time 333.15ms, mfu 0.10%\n",
            "iter 1590: loss 1.9281, time 348.21ms, mfu 0.10%\n",
            "step 1600: train loss 1.7920, val loss 1.9149\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1600: loss 1.8862, time 1726.79ms, mfu 0.09%\n",
            "iter 1610: loss 1.8333, time 367.71ms, mfu 0.09%\n",
            "iter 1620: loss 1.8751, time 360.29ms, mfu 0.09%\n",
            "iter 1630: loss 1.9075, time 361.99ms, mfu 0.09%\n",
            "iter 1640: loss 1.8283, time 358.12ms, mfu 0.09%\n",
            "iter 1650: loss 1.7614, time 371.87ms, mfu 0.09%\n",
            "iter 1660: loss 1.8368, time 366.44ms, mfu 0.09%\n",
            "iter 1670: loss 1.8513, time 370.13ms, mfu 0.09%\n",
            "iter 1680: loss 1.7488, time 372.26ms, mfu 0.09%\n",
            "iter 1690: loss 1.7110, time 361.42ms, mfu 0.09%\n",
            "iter 1700: loss 1.9015, time 347.26ms, mfu 0.09%\n",
            "iter 1710: loss 1.8739, time 360.90ms, mfu 0.09%\n",
            "iter 1720: loss 1.7490, time 357.06ms, mfu 0.09%\n",
            "iter 1730: loss 1.8499, time 367.20ms, mfu 0.09%\n",
            "iter 1740: loss 1.8689, time 359.83ms, mfu 0.09%\n",
            "iter 1750: loss 1.8159, time 371.88ms, mfu 0.09%\n",
            "iter 1760: loss 1.7222, time 359.00ms, mfu 0.09%\n",
            "iter 1770: loss 1.8137, time 362.16ms, mfu 0.09%\n",
            "iter 1780: loss 1.8952, time 364.80ms, mfu 0.09%\n",
            "iter 1790: loss 1.8845, time 366.97ms, mfu 0.09%\n",
            "step 1800: train loss 1.7064, val loss 1.8641\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1800: loss 1.6900, time 1740.13ms, mfu 0.09%\n",
            "iter 1810: loss 1.8723, time 366.35ms, mfu 0.09%\n",
            "iter 1820: loss 1.7211, time 361.26ms, mfu 0.09%\n",
            "iter 1830: loss 1.6743, time 360.82ms, mfu 0.09%\n",
            "iter 1840: loss 1.7511, time 359.62ms, mfu 0.09%\n",
            "iter 1850: loss 1.7963, time 356.70ms, mfu 0.09%\n",
            "iter 1860: loss 1.7260, time 361.05ms, mfu 0.09%\n",
            "iter 1870: loss 1.7526, time 329.52ms, mfu 0.09%\n",
            "iter 1880: loss 1.7860, time 352.70ms, mfu 0.09%\n",
            "iter 1890: loss 1.7282, time 341.49ms, mfu 0.09%\n",
            "iter 1900: loss 1.7430, time 339.29ms, mfu 0.09%\n",
            "iter 1910: loss 1.7864, time 329.60ms, mfu 0.09%\n",
            "iter 1920: loss 1.7443, time 329.24ms, mfu 0.10%\n",
            "iter 1930: loss 1.8628, time 338.88ms, mfu 0.10%\n",
            "iter 1940: loss 1.7748, time 341.53ms, mfu 0.10%\n",
            "iter 1950: loss 1.6951, time 338.29ms, mfu 0.10%\n",
            "iter 1960: loss 1.7246, time 327.21ms, mfu 0.10%\n",
            "iter 1970: loss 1.8864, time 337.77ms, mfu 0.10%\n",
            "iter 1980: loss 1.6544, time 329.34ms, mfu 0.10%\n",
            "iter 1990: loss 1.8001, time 365.36ms, mfu 0.10%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 20/32: b64_L4_H8_E128_BS8_MI2000_D20_s20 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS8_MI2000_D20_s20.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 20\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1699, val loss 4.1654\n",
            "iter 0: loss 4.1799, time 2058.95ms, mfu -100.00%\n",
            "iter 10: loss 4.1610, time 362.05ms, mfu 0.09%\n",
            "iter 20: loss 4.1329, time 362.47ms, mfu 0.09%\n",
            "iter 30: loss 4.0710, time 367.11ms, mfu 0.09%\n",
            "iter 40: loss 4.0337, time 363.71ms, mfu 0.09%\n",
            "iter 50: loss 3.9370, time 361.06ms, mfu 0.09%\n",
            "iter 60: loss 3.8449, time 356.60ms, mfu 0.09%\n",
            "iter 70: loss 3.8059, time 356.18ms, mfu 0.09%\n",
            "iter 80: loss 3.7368, time 337.47ms, mfu 0.09%\n",
            "iter 90: loss 3.7141, time 334.64ms, mfu 0.10%\n",
            "iter 100: loss 3.6889, time 333.50ms, mfu 0.10%\n",
            "iter 110: loss 3.5779, time 337.81ms, mfu 0.10%\n",
            "iter 120: loss 3.6121, time 326.86ms, mfu 0.10%\n",
            "iter 130: loss 3.5445, time 320.24ms, mfu 0.10%\n",
            "iter 140: loss 3.5304, time 327.99ms, mfu 0.10%\n",
            "iter 150: loss 3.5367, time 345.33ms, mfu 0.10%\n",
            "iter 160: loss 3.4878, time 329.98ms, mfu 0.10%\n",
            "iter 170: loss 3.4432, time 320.50ms, mfu 0.10%\n",
            "iter 180: loss 3.3858, time 330.05ms, mfu 0.10%\n",
            "iter 190: loss 3.3763, time 320.28ms, mfu 0.10%\n",
            "step 200: train loss 3.2670, val loss 3.2730\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 200: loss 3.3505, time 1577.01ms, mfu 0.09%\n",
            "iter 210: loss 3.2638, time 328.99ms, mfu 0.09%\n",
            "iter 220: loss 3.3070, time 328.93ms, mfu 0.09%\n",
            "iter 230: loss 3.2427, time 358.07ms, mfu 0.09%\n",
            "iter 240: loss 3.2336, time 327.67ms, mfu 0.10%\n",
            "iter 250: loss 3.1841, time 324.73ms, mfu 0.10%\n",
            "iter 260: loss 3.2338, time 342.51ms, mfu 0.10%\n",
            "iter 270: loss 3.1678, time 320.87ms, mfu 0.10%\n",
            "iter 280: loss 3.1122, time 356.09ms, mfu 0.10%\n",
            "iter 290: loss 3.0356, time 338.20ms, mfu 0.10%\n",
            "iter 300: loss 3.0928, time 329.23ms, mfu 0.10%\n",
            "iter 310: loss 3.0530, time 324.61ms, mfu 0.10%\n",
            "iter 320: loss 3.0552, time 321.68ms, mfu 0.10%\n",
            "iter 330: loss 2.9781, time 353.19ms, mfu 0.10%\n",
            "iter 340: loss 2.9297, time 316.82ms, mfu 0.10%\n",
            "iter 350: loss 2.9701, time 331.34ms, mfu 0.10%\n",
            "iter 360: loss 2.9537, time 320.18ms, mfu 0.10%\n",
            "iter 370: loss 2.9705, time 323.60ms, mfu 0.10%\n",
            "iter 380: loss 2.9256, time 315.78ms, mfu 0.10%\n",
            "iter 390: loss 2.8049, time 314.54ms, mfu 0.10%\n",
            "step 400: train loss 2.7851, val loss 2.7929\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 400: loss 2.8271, time 1602.10ms, mfu 0.09%\n",
            "iter 410: loss 2.8839, time 320.23ms, mfu 0.10%\n",
            "iter 420: loss 2.7152, time 318.03ms, mfu 0.10%\n",
            "iter 430: loss 2.7936, time 316.72ms, mfu 0.10%\n",
            "iter 440: loss 2.7864, time 326.93ms, mfu 0.10%\n",
            "iter 450: loss 2.7673, time 320.40ms, mfu 0.10%\n",
            "iter 460: loss 2.7756, time 320.62ms, mfu 0.10%\n",
            "iter 470: loss 2.6827, time 350.30ms, mfu 0.10%\n",
            "iter 480: loss 2.6745, time 338.74ms, mfu 0.10%\n",
            "iter 490: loss 2.7325, time 335.51ms, mfu 0.10%\n",
            "iter 500: loss 2.5853, time 320.66ms, mfu 0.10%\n",
            "iter 510: loss 2.7292, time 317.57ms, mfu 0.10%\n",
            "iter 520: loss 2.5645, time 333.96ms, mfu 0.10%\n",
            "iter 530: loss 2.6120, time 328.46ms, mfu 0.10%\n",
            "iter 540: loss 2.5463, time 328.63ms, mfu 0.10%\n",
            "iter 550: loss 2.7009, time 337.95ms, mfu 0.10%\n",
            "iter 560: loss 2.5563, time 329.85ms, mfu 0.10%\n",
            "iter 570: loss 2.6263, time 326.98ms, mfu 0.10%\n",
            "iter 580: loss 2.5789, time 337.89ms, mfu 0.10%\n",
            "iter 590: loss 2.5876, time 331.40ms, mfu 0.10%\n",
            "step 600: train loss 2.5080, val loss 2.5028\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 600: loss 2.5421, time 1597.33ms, mfu 0.09%\n",
            "iter 610: loss 2.4879, time 331.12ms, mfu 0.09%\n",
            "iter 620: loss 2.5851, time 331.59ms, mfu 0.10%\n",
            "iter 630: loss 2.4783, time 326.02ms, mfu 0.10%\n",
            "iter 640: loss 2.5702, time 324.82ms, mfu 0.10%\n",
            "iter 650: loss 2.5059, time 336.34ms, mfu 0.10%\n",
            "iter 660: loss 2.4587, time 332.45ms, mfu 0.10%\n",
            "iter 670: loss 2.5286, time 329.16ms, mfu 0.10%\n",
            "iter 680: loss 2.5319, time 327.71ms, mfu 0.10%\n",
            "iter 690: loss 2.4293, time 336.65ms, mfu 0.10%\n",
            "iter 700: loss 2.4287, time 328.21ms, mfu 0.10%\n",
            "iter 710: loss 2.4020, time 329.80ms, mfu 0.10%\n",
            "iter 720: loss 2.4799, time 333.64ms, mfu 0.10%\n",
            "iter 730: loss 2.4038, time 330.07ms, mfu 0.10%\n",
            "iter 740: loss 2.4515, time 327.55ms, mfu 0.10%\n",
            "iter 750: loss 2.4247, time 329.17ms, mfu 0.10%\n",
            "iter 760: loss 2.3505, time 334.48ms, mfu 0.10%\n",
            "iter 770: loss 2.3194, time 325.64ms, mfu 0.10%\n",
            "iter 780: loss 2.3756, time 332.17ms, mfu 0.10%\n",
            "iter 790: loss 2.4981, time 326.53ms, mfu 0.10%\n",
            "step 800: train loss 2.3366, val loss 2.3400\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 800: loss 2.4234, time 1645.61ms, mfu 0.09%\n",
            "iter 810: loss 2.3519, time 331.19ms, mfu 0.09%\n",
            "iter 820: loss 2.3946, time 331.15ms, mfu 0.10%\n",
            "iter 830: loss 2.4094, time 345.87ms, mfu 0.10%\n",
            "iter 840: loss 2.3259, time 330.04ms, mfu 0.10%\n",
            "iter 850: loss 2.3215, time 332.12ms, mfu 0.10%\n",
            "iter 860: loss 2.3014, time 328.63ms, mfu 0.10%\n",
            "iter 870: loss 2.3233, time 343.74ms, mfu 0.10%\n",
            "iter 880: loss 2.3234, time 335.17ms, mfu 0.10%\n",
            "iter 890: loss 2.3118, time 326.45ms, mfu 0.10%\n",
            "iter 900: loss 2.3707, time 324.79ms, mfu 0.10%\n",
            "iter 910: loss 2.3720, time 329.39ms, mfu 0.10%\n",
            "iter 920: loss 2.2997, time 332.53ms, mfu 0.10%\n",
            "iter 930: loss 2.2919, time 328.73ms, mfu 0.10%\n",
            "iter 940: loss 2.2529, time 342.62ms, mfu 0.10%\n",
            "iter 950: loss 2.3699, time 330.93ms, mfu 0.10%\n",
            "iter 960: loss 2.2900, time 332.61ms, mfu 0.10%\n",
            "iter 970: loss 2.4280, time 330.04ms, mfu 0.10%\n",
            "iter 980: loss 2.2771, time 349.04ms, mfu 0.10%\n",
            "iter 990: loss 2.2541, time 330.25ms, mfu 0.10%\n",
            "step 1000: train loss 2.2126, val loss 2.2270\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1000: loss 2.2936, time 1605.86ms, mfu 0.09%\n",
            "iter 1010: loss 2.4089, time 341.48ms, mfu 0.09%\n",
            "iter 1020: loss 2.2582, time 333.49ms, mfu 0.09%\n",
            "iter 1030: loss 2.1673, time 331.33ms, mfu 0.09%\n",
            "iter 1040: loss 2.2260, time 328.87ms, mfu 0.10%\n",
            "iter 1050: loss 2.2702, time 335.56ms, mfu 0.10%\n",
            "iter 1060: loss 2.3685, time 328.14ms, mfu 0.10%\n",
            "iter 1070: loss 2.3845, time 328.17ms, mfu 0.10%\n",
            "iter 1080: loss 2.2731, time 333.59ms, mfu 0.10%\n",
            "iter 1090: loss 2.2481, time 324.89ms, mfu 0.10%\n",
            "iter 1100: loss 2.2092, time 324.70ms, mfu 0.10%\n",
            "iter 1110: loss 2.1898, time 331.84ms, mfu 0.10%\n",
            "iter 1120: loss 2.1587, time 335.26ms, mfu 0.10%\n",
            "iter 1130: loss 2.2215, time 336.53ms, mfu 0.10%\n",
            "iter 1140: loss 2.3390, time 334.97ms, mfu 0.10%\n",
            "iter 1150: loss 2.1842, time 328.17ms, mfu 0.10%\n",
            "iter 1160: loss 2.3059, time 331.27ms, mfu 0.10%\n",
            "iter 1170: loss 2.1644, time 332.03ms, mfu 0.10%\n",
            "iter 1180: loss 2.1815, time 332.11ms, mfu 0.10%\n",
            "iter 1190: loss 2.1234, time 335.38ms, mfu 0.10%\n",
            "step 1200: train loss 2.0889, val loss 2.1276\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1200: loss 2.1919, time 1581.22ms, mfu 0.09%\n",
            "iter 1210: loss 2.1803, time 334.36ms, mfu 0.09%\n",
            "iter 1220: loss 2.1375, time 328.89ms, mfu 0.09%\n",
            "iter 1230: loss 2.1575, time 341.20ms, mfu 0.10%\n",
            "iter 1240: loss 2.1532, time 337.04ms, mfu 0.10%\n",
            "iter 1250: loss 2.1927, time 327.63ms, mfu 0.10%\n",
            "iter 1260: loss 2.0950, time 333.49ms, mfu 0.10%\n",
            "iter 1270: loss 2.0522, time 332.22ms, mfu 0.10%\n",
            "iter 1280: loss 2.1538, time 331.37ms, mfu 0.10%\n",
            "iter 1290: loss 2.2646, time 333.57ms, mfu 0.10%\n",
            "iter 1300: loss 2.2271, time 348.04ms, mfu 0.10%\n",
            "iter 1310: loss 2.0915, time 329.64ms, mfu 0.10%\n",
            "iter 1320: loss 2.0896, time 330.61ms, mfu 0.10%\n",
            "iter 1330: loss 2.2334, time 333.83ms, mfu 0.10%\n",
            "iter 1340: loss 2.0758, time 334.24ms, mfu 0.10%\n",
            "iter 1350: loss 2.1902, time 327.87ms, mfu 0.10%\n",
            "iter 1360: loss 2.2182, time 333.55ms, mfu 0.10%\n",
            "iter 1370: loss 2.1189, time 336.08ms, mfu 0.10%\n",
            "iter 1380: loss 2.0652, time 332.66ms, mfu 0.10%\n",
            "iter 1390: loss 2.1529, time 327.97ms, mfu 0.10%\n",
            "step 1400: train loss 1.9920, val loss 2.0500\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1400: loss 2.0251, time 1618.63ms, mfu 0.09%\n",
            "iter 1410: loss 2.0609, time 333.11ms, mfu 0.09%\n",
            "iter 1420: loss 2.2154, time 331.72ms, mfu 0.09%\n",
            "iter 1430: loss 2.0469, time 329.06ms, mfu 0.10%\n",
            "iter 1440: loss 2.0652, time 330.71ms, mfu 0.10%\n",
            "iter 1450: loss 2.0542, time 326.81ms, mfu 0.10%\n",
            "iter 1460: loss 2.0790, time 328.75ms, mfu 0.10%\n",
            "iter 1470: loss 2.0307, time 332.29ms, mfu 0.10%\n",
            "iter 1480: loss 2.1623, time 328.01ms, mfu 0.10%\n",
            "iter 1490: loss 2.0840, time 329.02ms, mfu 0.10%\n",
            "iter 1500: loss 1.9772, time 331.61ms, mfu 0.10%\n",
            "iter 1510: loss 2.0089, time 340.94ms, mfu 0.10%\n",
            "iter 1520: loss 2.1218, time 337.49ms, mfu 0.10%\n",
            "iter 1530: loss 2.0160, time 331.81ms, mfu 0.10%\n",
            "iter 1540: loss 2.0172, time 333.95ms, mfu 0.10%\n",
            "iter 1550: loss 2.1269, time 334.74ms, mfu 0.10%\n",
            "iter 1560: loss 2.0902, time 334.83ms, mfu 0.10%\n",
            "iter 1570: loss 2.0530, time 335.46ms, mfu 0.10%\n",
            "iter 1580: loss 2.0420, time 332.18ms, mfu 0.10%\n",
            "iter 1590: loss 2.0296, time 328.30ms, mfu 0.10%\n",
            "step 1600: train loss 1.9058, val loss 1.9853\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1600: loss 2.0163, time 1600.43ms, mfu 0.09%\n",
            "iter 1610: loss 1.9643, time 337.68ms, mfu 0.09%\n",
            "iter 1620: loss 2.0194, time 343.08ms, mfu 0.09%\n",
            "iter 1630: loss 1.9954, time 335.96ms, mfu 0.09%\n",
            "iter 1640: loss 2.0048, time 326.18ms, mfu 0.10%\n",
            "iter 1650: loss 1.9044, time 331.58ms, mfu 0.10%\n",
            "iter 1660: loss 1.9866, time 330.65ms, mfu 0.10%\n",
            "iter 1670: loss 1.9998, time 328.02ms, mfu 0.10%\n",
            "iter 1680: loss 1.8800, time 331.28ms, mfu 0.10%\n",
            "iter 1690: loss 1.8576, time 331.78ms, mfu 0.10%\n",
            "iter 1700: loss 2.0311, time 335.66ms, mfu 0.10%\n",
            "iter 1710: loss 2.0181, time 347.76ms, mfu 0.10%\n",
            "iter 1720: loss 1.8930, time 327.81ms, mfu 0.10%\n",
            "iter 1730: loss 2.0204, time 350.45ms, mfu 0.10%\n",
            "iter 1740: loss 2.0007, time 331.67ms, mfu 0.10%\n",
            "iter 1750: loss 1.9488, time 330.47ms, mfu 0.10%\n",
            "iter 1760: loss 1.8799, time 327.23ms, mfu 0.10%\n",
            "iter 1770: loss 1.9261, time 330.10ms, mfu 0.10%\n",
            "iter 1780: loss 2.0556, time 337.78ms, mfu 0.10%\n",
            "iter 1790: loss 1.9661, time 336.84ms, mfu 0.10%\n",
            "step 1800: train loss 1.8166, val loss 1.9284\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1800: loss 1.8410, time 1622.92ms, mfu 0.09%\n",
            "iter 1810: loss 1.9816, time 328.22ms, mfu 0.09%\n",
            "iter 1820: loss 1.8519, time 330.12ms, mfu 0.09%\n",
            "iter 1830: loss 1.7686, time 341.49ms, mfu 0.09%\n",
            "iter 1840: loss 1.8837, time 330.25ms, mfu 0.10%\n",
            "iter 1850: loss 1.9009, time 322.06ms, mfu 0.10%\n",
            "iter 1860: loss 1.8623, time 328.84ms, mfu 0.10%\n",
            "iter 1870: loss 1.8787, time 337.92ms, mfu 0.10%\n",
            "iter 1880: loss 1.8942, time 330.73ms, mfu 0.10%\n",
            "iter 1890: loss 1.8556, time 327.36ms, mfu 0.10%\n",
            "iter 1900: loss 1.9003, time 329.49ms, mfu 0.10%\n",
            "iter 1910: loss 1.8955, time 353.30ms, mfu 0.10%\n",
            "iter 1920: loss 1.8856, time 329.81ms, mfu 0.10%\n",
            "iter 1930: loss 2.0240, time 331.94ms, mfu 0.10%\n",
            "iter 1940: loss 1.8807, time 343.06ms, mfu 0.10%\n",
            "iter 1950: loss 1.8254, time 335.77ms, mfu 0.10%\n",
            "iter 1960: loss 1.8554, time 329.01ms, mfu 0.10%\n",
            "iter 1970: loss 1.9783, time 329.81ms, mfu 0.10%\n",
            "iter 1980: loss 1.8499, time 334.98ms, mfu 0.10%\n",
            "iter 1990: loss 1.9280, time 330.16ms, mfu 0.10%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 21/32: b64_L4_H8_E128_BS16_MI1000_D10_s21 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS16_MI1000_D10_s21.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D10_s21\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 21\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1702, val loss 4.1669\n",
            "iter 0: loss 4.1778, time 2088.10ms, mfu -100.00%\n",
            "iter 10: loss 4.1631, time 353.92ms, mfu 0.19%\n",
            "iter 20: loss 4.1145, time 347.07ms, mfu 0.19%\n",
            "iter 30: loss 4.0852, time 352.66ms, mfu 0.19%\n",
            "iter 40: loss 4.0073, time 349.62ms, mfu 0.19%\n",
            "iter 50: loss 3.9121, time 344.94ms, mfu 0.19%\n",
            "iter 60: loss 3.8469, time 348.77ms, mfu 0.19%\n",
            "iter 70: loss 3.7525, time 345.98ms, mfu 0.19%\n",
            "iter 80: loss 3.6984, time 348.49ms, mfu 0.19%\n",
            "iter 90: loss 3.6959, time 345.13ms, mfu 0.19%\n",
            "iter 100: loss 3.6510, time 341.90ms, mfu 0.19%\n",
            "iter 110: loss 3.6234, time 350.56ms, mfu 0.19%\n",
            "iter 120: loss 3.5859, time 342.92ms, mfu 0.19%\n",
            "iter 130: loss 3.5060, time 345.57ms, mfu 0.19%\n",
            "iter 140: loss 3.4716, time 349.65ms, mfu 0.19%\n",
            "iter 150: loss 3.4711, time 348.96ms, mfu 0.19%\n",
            "iter 160: loss 3.3923, time 345.95ms, mfu 0.19%\n",
            "iter 170: loss 3.3491, time 347.26ms, mfu 0.19%\n",
            "iter 180: loss 3.3690, time 341.28ms, mfu 0.20%\n",
            "iter 190: loss 3.3508, time 346.34ms, mfu 0.20%\n",
            "step 200: train loss 3.2414, val loss 3.2477\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 200: loss 3.2623, time 1745.31ms, mfu 0.18%\n",
            "iter 210: loss 3.2473, time 340.38ms, mfu 0.18%\n",
            "iter 220: loss 3.2005, time 346.58ms, mfu 0.18%\n",
            "iter 230: loss 3.2067, time 344.44ms, mfu 0.18%\n",
            "iter 240: loss 3.1749, time 353.81ms, mfu 0.19%\n",
            "iter 250: loss 3.1290, time 342.09ms, mfu 0.19%\n",
            "iter 260: loss 3.1049, time 344.49ms, mfu 0.19%\n",
            "iter 270: loss 3.1495, time 345.13ms, mfu 0.19%\n",
            "iter 280: loss 3.0373, time 345.31ms, mfu 0.19%\n",
            "iter 290: loss 2.9985, time 346.76ms, mfu 0.19%\n",
            "iter 300: loss 3.0398, time 350.22ms, mfu 0.19%\n",
            "iter 310: loss 3.0059, time 351.77ms, mfu 0.19%\n",
            "iter 320: loss 2.9742, time 345.01ms, mfu 0.19%\n",
            "iter 330: loss 2.9065, time 349.80ms, mfu 0.19%\n",
            "iter 340: loss 2.9805, time 346.60ms, mfu 0.19%\n",
            "iter 350: loss 2.8311, time 348.75ms, mfu 0.19%\n",
            "iter 360: loss 2.8516, time 349.93ms, mfu 0.19%\n",
            "iter 370: loss 2.8562, time 351.87ms, mfu 0.19%\n",
            "iter 380: loss 2.8236, time 347.63ms, mfu 0.19%\n",
            "iter 390: loss 2.8485, time 336.36ms, mfu 0.19%\n",
            "step 400: train loss 2.7498, val loss 2.7615\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 400: loss 2.7653, time 1746.62ms, mfu 0.18%\n",
            "iter 410: loss 2.7712, time 345.77ms, mfu 0.18%\n",
            "iter 420: loss 2.7699, time 344.42ms, mfu 0.18%\n",
            "iter 430: loss 2.7044, time 346.13ms, mfu 0.18%\n",
            "iter 440: loss 2.6899, time 336.87ms, mfu 0.18%\n",
            "iter 450: loss 2.7176, time 342.91ms, mfu 0.19%\n",
            "iter 460: loss 2.6343, time 346.91ms, mfu 0.19%\n",
            "iter 470: loss 2.6252, time 336.91ms, mfu 0.19%\n",
            "iter 480: loss 2.6770, time 347.98ms, mfu 0.19%\n",
            "iter 490: loss 2.6870, time 344.18ms, mfu 0.19%\n",
            "iter 500: loss 2.6056, time 343.18ms, mfu 0.19%\n",
            "iter 510: loss 2.6044, time 338.57ms, mfu 0.19%\n",
            "iter 520: loss 2.5607, time 341.69ms, mfu 0.19%\n",
            "iter 530: loss 2.5920, time 342.10ms, mfu 0.19%\n",
            "iter 540: loss 2.5614, time 350.28ms, mfu 0.19%\n",
            "iter 550: loss 2.5907, time 351.11ms, mfu 0.19%\n",
            "iter 560: loss 2.4746, time 348.44ms, mfu 0.19%\n",
            "iter 570: loss 2.4606, time 349.44ms, mfu 0.19%\n",
            "iter 580: loss 2.4811, time 340.06ms, mfu 0.19%\n",
            "iter 590: loss 2.4632, time 348.08ms, mfu 0.19%\n",
            "step 600: train loss 2.4367, val loss 2.4480\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 600: loss 2.4772, time 1744.54ms, mfu 0.18%\n",
            "iter 610: loss 2.4637, time 348.07ms, mfu 0.18%\n",
            "iter 620: loss 2.4974, time 350.00ms, mfu 0.18%\n",
            "iter 630: loss 2.4916, time 350.04ms, mfu 0.18%\n",
            "iter 640: loss 2.4477, time 349.14ms, mfu 0.18%\n",
            "iter 650: loss 2.4893, time 350.74ms, mfu 0.18%\n",
            "iter 660: loss 2.5095, time 342.31ms, mfu 0.19%\n",
            "iter 670: loss 2.3313, time 343.22ms, mfu 0.19%\n",
            "iter 680: loss 2.4315, time 341.75ms, mfu 0.19%\n",
            "iter 690: loss 2.3816, time 341.60ms, mfu 0.19%\n",
            "iter 700: loss 2.3342, time 341.60ms, mfu 0.19%\n",
            "iter 710: loss 2.3711, time 349.20ms, mfu 0.19%\n",
            "iter 720: loss 2.3646, time 353.80ms, mfu 0.19%\n",
            "iter 730: loss 2.3435, time 348.48ms, mfu 0.19%\n",
            "iter 740: loss 2.3067, time 345.08ms, mfu 0.19%\n",
            "iter 750: loss 2.3230, time 351.68ms, mfu 0.19%\n",
            "iter 760: loss 2.2921, time 343.36ms, mfu 0.19%\n",
            "iter 770: loss 2.3354, time 346.39ms, mfu 0.19%\n",
            "iter 780: loss 2.3496, time 344.86ms, mfu 0.19%\n",
            "iter 790: loss 2.3514, time 351.98ms, mfu 0.19%\n",
            "step 800: train loss 2.2428, val loss 2.2546\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 800: loss 2.2716, time 1755.87ms, mfu 0.18%\n",
            "iter 810: loss 2.2703, time 342.97ms, mfu 0.18%\n",
            "iter 820: loss 2.3316, time 347.23ms, mfu 0.18%\n",
            "iter 830: loss 2.3049, time 342.03ms, mfu 0.18%\n",
            "iter 840: loss 2.3203, time 342.46ms, mfu 0.18%\n",
            "iter 850: loss 2.2278, time 348.42ms, mfu 0.19%\n",
            "iter 860: loss 2.2409, time 346.31ms, mfu 0.19%\n",
            "iter 870: loss 2.2361, time 347.78ms, mfu 0.19%\n",
            "iter 880: loss 2.1778, time 347.91ms, mfu 0.19%\n",
            "iter 890: loss 2.2975, time 355.51ms, mfu 0.19%\n",
            "iter 900: loss 2.1698, time 340.77ms, mfu 0.19%\n",
            "iter 910: loss 2.1661, time 344.31ms, mfu 0.19%\n",
            "iter 920: loss 2.1723, time 344.14ms, mfu 0.19%\n",
            "iter 930: loss 2.2655, time 347.54ms, mfu 0.19%\n",
            "iter 940: loss 2.1279, time 347.54ms, mfu 0.19%\n",
            "iter 950: loss 2.1852, time 353.38ms, mfu 0.19%\n",
            "iter 960: loss 2.1536, time 348.92ms, mfu 0.19%\n",
            "iter 970: loss 2.2071, time 350.38ms, mfu 0.19%\n",
            "iter 980: loss 2.2259, time 354.24ms, mfu 0.19%\n",
            "iter 990: loss 2.1147, time 348.69ms, mfu 0.19%\n",
            "step 1000: train loss 2.0687, val loss 2.1010\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 1000: loss 2.0601, time 1734.66ms, mfu 0.18%\n",
            "\n",
            "=== Experiment 22/32: b64_L4_H8_E128_BS16_MI1000_D20_s22 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS16_MI1000_D20_s22.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D20_s22\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 22\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1702, val loss 4.1669\n",
            "iter 0: loss 4.1761, time 2085.46ms, mfu -100.00%\n",
            "iter 10: loss 4.1629, time 353.02ms, mfu 0.19%\n",
            "iter 20: loss 4.1212, time 352.58ms, mfu 0.19%\n",
            "iter 30: loss 4.0959, time 344.88ms, mfu 0.19%\n",
            "iter 40: loss 4.0292, time 340.70ms, mfu 0.19%\n",
            "iter 50: loss 3.9453, time 345.48ms, mfu 0.19%\n",
            "iter 60: loss 3.8773, time 344.36ms, mfu 0.19%\n",
            "iter 70: loss 3.7791, time 336.89ms, mfu 0.19%\n",
            "iter 80: loss 3.7260, time 352.31ms, mfu 0.19%\n",
            "iter 90: loss 3.7184, time 352.71ms, mfu 0.19%\n",
            "iter 100: loss 3.6724, time 354.28ms, mfu 0.19%\n",
            "iter 110: loss 3.6561, time 353.15ms, mfu 0.19%\n",
            "iter 120: loss 3.6210, time 347.12ms, mfu 0.19%\n",
            "iter 130: loss 3.5509, time 349.14ms, mfu 0.19%\n",
            "iter 140: loss 3.5186, time 349.57ms, mfu 0.19%\n",
            "iter 150: loss 3.5038, time 356.82ms, mfu 0.19%\n",
            "iter 160: loss 3.4369, time 349.34ms, mfu 0.19%\n",
            "iter 170: loss 3.3932, time 352.94ms, mfu 0.19%\n",
            "iter 180: loss 3.4096, time 356.53ms, mfu 0.19%\n",
            "iter 190: loss 3.3906, time 344.14ms, mfu 0.19%\n",
            "step 200: train loss 3.2582, val loss 3.2650\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 200: loss 3.3050, time 1733.97ms, mfu 0.18%\n",
            "iter 210: loss 3.2838, time 347.83ms, mfu 0.18%\n",
            "iter 220: loss 3.2417, time 341.38ms, mfu 0.18%\n",
            "iter 230: loss 3.2294, time 348.79ms, mfu 0.18%\n",
            "iter 240: loss 3.2060, time 342.76ms, mfu 0.18%\n",
            "iter 250: loss 3.1645, time 350.71ms, mfu 0.19%\n",
            "iter 260: loss 3.1369, time 347.98ms, mfu 0.19%\n",
            "iter 270: loss 3.1851, time 354.81ms, mfu 0.19%\n",
            "iter 280: loss 3.0676, time 346.50ms, mfu 0.19%\n",
            "iter 290: loss 3.0346, time 354.05ms, mfu 0.19%\n",
            "iter 300: loss 3.0665, time 348.15ms, mfu 0.19%\n",
            "iter 310: loss 3.0375, time 342.02ms, mfu 0.19%\n",
            "iter 320: loss 3.0098, time 358.46ms, mfu 0.19%\n",
            "iter 330: loss 2.9450, time 350.23ms, mfu 0.19%\n",
            "iter 340: loss 3.0132, time 349.31ms, mfu 0.19%\n",
            "iter 350: loss 2.8650, time 349.22ms, mfu 0.19%\n",
            "iter 360: loss 2.8785, time 341.65ms, mfu 0.19%\n",
            "iter 370: loss 2.8906, time 338.29ms, mfu 0.19%\n",
            "iter 380: loss 2.8631, time 341.59ms, mfu 0.19%\n",
            "iter 390: loss 2.8798, time 355.41ms, mfu 0.19%\n",
            "step 400: train loss 2.7711, val loss 2.7815\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 400: loss 2.7901, time 1759.92ms, mfu 0.18%\n",
            "iter 410: loss 2.8037, time 345.87ms, mfu 0.18%\n",
            "iter 420: loss 2.8099, time 352.28ms, mfu 0.18%\n",
            "iter 430: loss 2.7418, time 351.93ms, mfu 0.18%\n",
            "iter 440: loss 2.7239, time 345.84ms, mfu 0.18%\n",
            "iter 450: loss 2.7545, time 351.79ms, mfu 0.18%\n",
            "iter 460: loss 2.6682, time 354.36ms, mfu 0.19%\n",
            "iter 470: loss 2.6561, time 352.63ms, mfu 0.19%\n",
            "iter 480: loss 2.7048, time 339.39ms, mfu 0.19%\n",
            "iter 490: loss 2.7202, time 344.13ms, mfu 0.19%\n",
            "iter 500: loss 2.6260, time 338.70ms, mfu 0.19%\n",
            "iter 510: loss 2.6403, time 344.43ms, mfu 0.19%\n",
            "iter 520: loss 2.5986, time 345.52ms, mfu 0.19%\n",
            "iter 530: loss 2.6251, time 351.92ms, mfu 0.19%\n",
            "iter 540: loss 2.6045, time 343.76ms, mfu 0.19%\n",
            "iter 550: loss 2.6054, time 347.82ms, mfu 0.19%\n",
            "iter 560: loss 2.5113, time 349.86ms, mfu 0.19%\n",
            "iter 570: loss 2.5066, time 343.70ms, mfu 0.19%\n",
            "iter 580: loss 2.4997, time 344.04ms, mfu 0.19%\n",
            "iter 590: loss 2.5021, time 344.04ms, mfu 0.19%\n",
            "step 600: train loss 2.4719, val loss 2.4782\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 600: loss 2.5119, time 1769.00ms, mfu 0.18%\n",
            "iter 610: loss 2.5173, time 350.07ms, mfu 0.18%\n",
            "iter 620: loss 2.5353, time 347.68ms, mfu 0.18%\n",
            "iter 630: loss 2.5380, time 350.58ms, mfu 0.18%\n",
            "iter 640: loss 2.5064, time 339.56ms, mfu 0.18%\n",
            "iter 650: loss 2.5317, time 342.09ms, mfu 0.19%\n",
            "iter 660: loss 2.5573, time 354.15ms, mfu 0.19%\n",
            "iter 670: loss 2.3809, time 348.54ms, mfu 0.19%\n",
            "iter 680: loss 2.4920, time 348.96ms, mfu 0.19%\n",
            "iter 690: loss 2.4346, time 349.74ms, mfu 0.19%\n",
            "iter 700: loss 2.3728, time 346.58ms, mfu 0.19%\n",
            "iter 710: loss 2.4183, time 339.56ms, mfu 0.19%\n",
            "iter 720: loss 2.4069, time 352.28ms, mfu 0.19%\n",
            "iter 730: loss 2.3751, time 347.90ms, mfu 0.19%\n",
            "iter 740: loss 2.3684, time 348.58ms, mfu 0.19%\n",
            "iter 750: loss 2.3798, time 350.08ms, mfu 0.19%\n",
            "iter 760: loss 2.3492, time 351.98ms, mfu 0.19%\n",
            "iter 770: loss 2.4144, time 350.99ms, mfu 0.19%\n",
            "iter 780: loss 2.4091, time 351.96ms, mfu 0.19%\n",
            "iter 790: loss 2.4089, time 340.84ms, mfu 0.19%\n",
            "step 800: train loss 2.2976, val loss 2.3042\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 800: loss 2.3271, time 1758.18ms, mfu 0.18%\n",
            "iter 810: loss 2.3249, time 348.49ms, mfu 0.18%\n",
            "iter 820: loss 2.4100, time 340.18ms, mfu 0.18%\n",
            "iter 830: loss 2.3753, time 344.47ms, mfu 0.18%\n",
            "iter 840: loss 2.3908, time 338.17ms, mfu 0.18%\n",
            "iter 850: loss 2.3118, time 351.48ms, mfu 0.19%\n",
            "iter 860: loss 2.3121, time 343.10ms, mfu 0.19%\n",
            "iter 870: loss 2.3212, time 342.07ms, mfu 0.19%\n",
            "iter 880: loss 2.2410, time 345.30ms, mfu 0.19%\n",
            "iter 890: loss 2.3512, time 340.11ms, mfu 0.19%\n",
            "iter 900: loss 2.2607, time 347.48ms, mfu 0.19%\n",
            "iter 910: loss 2.2521, time 346.90ms, mfu 0.19%\n",
            "iter 920: loss 2.2615, time 348.04ms, mfu 0.19%\n",
            "iter 930: loss 2.3445, time 342.67ms, mfu 0.19%\n",
            "iter 940: loss 2.2325, time 365.71ms, mfu 0.19%\n",
            "iter 950: loss 2.2988, time 349.42ms, mfu 0.19%\n",
            "iter 960: loss 2.2366, time 344.31ms, mfu 0.19%\n",
            "iter 970: loss 2.3094, time 352.44ms, mfu 0.19%\n",
            "iter 980: loss 2.3378, time 348.06ms, mfu 0.19%\n",
            "iter 990: loss 2.2363, time 343.05ms, mfu 0.19%\n",
            "step 1000: train loss 2.1587, val loss 2.1749\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 1000: loss 2.1612, time 1762.73ms, mfu 0.18%\n",
            "\n",
            "=== Experiment 23/32: b64_L4_H8_E128_BS16_MI2000_D10_s23 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS16_MI2000_D10_s23.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 23\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1702, val loss 4.1669\n",
            "iter 0: loss 4.1778, time 2075.29ms, mfu -100.00%\n",
            "iter 10: loss 4.1631, time 345.36ms, mfu 0.20%\n",
            "iter 20: loss 4.1145, time 351.18ms, mfu 0.20%\n",
            "iter 30: loss 4.0852, time 350.47ms, mfu 0.20%\n",
            "iter 40: loss 4.0073, time 348.97ms, mfu 0.20%\n",
            "iter 50: loss 3.9121, time 345.20ms, mfu 0.20%\n",
            "iter 60: loss 3.8469, time 347.46ms, mfu 0.20%\n",
            "iter 70: loss 3.7525, time 347.67ms, mfu 0.20%\n",
            "iter 80: loss 3.6984, time 342.25ms, mfu 0.20%\n",
            "iter 90: loss 3.6959, time 358.38ms, mfu 0.20%\n",
            "iter 100: loss 3.6510, time 341.56ms, mfu 0.20%\n",
            "iter 110: loss 3.6234, time 342.26ms, mfu 0.20%\n",
            "iter 120: loss 3.5859, time 342.85ms, mfu 0.20%\n",
            "iter 130: loss 3.5060, time 347.41ms, mfu 0.20%\n",
            "iter 140: loss 3.4716, time 341.11ms, mfu 0.20%\n",
            "iter 150: loss 3.4711, time 346.94ms, mfu 0.20%\n",
            "iter 160: loss 3.3923, time 345.38ms, mfu 0.20%\n",
            "iter 170: loss 3.3491, time 350.47ms, mfu 0.20%\n",
            "iter 180: loss 3.3690, time 343.59ms, mfu 0.20%\n",
            "iter 190: loss 3.3508, time 332.24ms, mfu 0.20%\n",
            "step 200: train loss 3.2414, val loss 3.2477\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 200: loss 3.2623, time 1711.68ms, mfu 0.18%\n",
            "iter 210: loss 3.2473, time 339.00ms, mfu 0.18%\n",
            "iter 220: loss 3.2005, time 348.87ms, mfu 0.18%\n",
            "iter 230: loss 3.2067, time 350.21ms, mfu 0.19%\n",
            "iter 240: loss 3.1749, time 348.87ms, mfu 0.19%\n",
            "iter 250: loss 3.1290, time 344.97ms, mfu 0.19%\n",
            "iter 260: loss 3.1049, time 362.52ms, mfu 0.19%\n",
            "iter 270: loss 3.1495, time 338.81ms, mfu 0.19%\n",
            "iter 280: loss 3.0373, time 350.10ms, mfu 0.19%\n",
            "iter 290: loss 2.9985, time 350.85ms, mfu 0.19%\n",
            "iter 300: loss 3.0398, time 358.34ms, mfu 0.19%\n",
            "iter 310: loss 3.0059, time 343.83ms, mfu 0.19%\n",
            "iter 320: loss 2.9742, time 340.69ms, mfu 0.19%\n",
            "iter 330: loss 2.9065, time 356.39ms, mfu 0.19%\n",
            "iter 340: loss 2.9805, time 341.29ms, mfu 0.19%\n",
            "iter 350: loss 2.8311, time 345.53ms, mfu 0.19%\n",
            "iter 360: loss 2.8516, time 342.85ms, mfu 0.19%\n",
            "iter 370: loss 2.8562, time 375.58ms, mfu 0.19%\n",
            "iter 380: loss 2.8236, time 344.23ms, mfu 0.19%\n",
            "iter 390: loss 2.8485, time 346.84ms, mfu 0.19%\n",
            "step 400: train loss 2.7498, val loss 2.7615\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 400: loss 2.7653, time 1791.09ms, mfu 0.18%\n",
            "iter 410: loss 2.7712, time 340.37ms, mfu 0.18%\n",
            "iter 420: loss 2.7699, time 342.61ms, mfu 0.18%\n",
            "iter 430: loss 2.7044, time 343.81ms, mfu 0.18%\n",
            "iter 440: loss 2.6899, time 351.57ms, mfu 0.18%\n",
            "iter 450: loss 2.7176, time 351.46ms, mfu 0.18%\n",
            "iter 460: loss 2.6343, time 345.03ms, mfu 0.19%\n",
            "iter 470: loss 2.6252, time 349.20ms, mfu 0.19%\n",
            "iter 480: loss 2.6770, time 344.54ms, mfu 0.19%\n",
            "iter 490: loss 2.6870, time 346.10ms, mfu 0.19%\n",
            "iter 500: loss 2.6056, time 353.39ms, mfu 0.19%\n",
            "iter 510: loss 2.6044, time 349.74ms, mfu 0.19%\n",
            "iter 520: loss 2.5607, time 349.22ms, mfu 0.19%\n",
            "iter 530: loss 2.5920, time 348.14ms, mfu 0.19%\n",
            "iter 540: loss 2.5614, time 372.11ms, mfu 0.19%\n",
            "iter 550: loss 2.5907, time 342.69ms, mfu 0.19%\n",
            "iter 560: loss 2.4746, time 344.02ms, mfu 0.19%\n",
            "iter 570: loss 2.4606, time 342.79ms, mfu 0.19%\n",
            "iter 580: loss 2.4811, time 343.04ms, mfu 0.19%\n",
            "iter 590: loss 2.4632, time 346.48ms, mfu 0.19%\n",
            "step 600: train loss 2.4367, val loss 2.4480\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 600: loss 2.4772, time 1731.06ms, mfu 0.18%\n",
            "iter 610: loss 2.4637, time 351.46ms, mfu 0.18%\n",
            "iter 620: loss 2.4974, time 352.73ms, mfu 0.18%\n",
            "iter 630: loss 2.4916, time 346.49ms, mfu 0.18%\n",
            "iter 640: loss 2.4477, time 352.99ms, mfu 0.18%\n",
            "iter 650: loss 2.4893, time 343.16ms, mfu 0.18%\n",
            "iter 660: loss 2.5095, time 348.91ms, mfu 0.19%\n",
            "iter 670: loss 2.3313, time 345.88ms, mfu 0.19%\n",
            "iter 680: loss 2.4315, time 345.50ms, mfu 0.19%\n",
            "iter 690: loss 2.3816, time 348.97ms, mfu 0.19%\n",
            "iter 700: loss 2.3342, time 352.02ms, mfu 0.19%\n",
            "iter 710: loss 2.3711, time 359.63ms, mfu 0.19%\n",
            "iter 720: loss 2.3646, time 345.92ms, mfu 0.19%\n",
            "iter 730: loss 2.3435, time 348.40ms, mfu 0.19%\n",
            "iter 740: loss 2.3067, time 352.47ms, mfu 0.19%\n",
            "iter 750: loss 2.3230, time 346.15ms, mfu 0.19%\n",
            "iter 760: loss 2.2921, time 346.17ms, mfu 0.19%\n",
            "iter 770: loss 2.3354, time 350.11ms, mfu 0.19%\n",
            "iter 780: loss 2.3496, time 356.96ms, mfu 0.19%\n",
            "iter 790: loss 2.3514, time 347.92ms, mfu 0.19%\n",
            "step 800: train loss 2.2428, val loss 2.2546\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 800: loss 2.2716, time 1734.95ms, mfu 0.18%\n",
            "iter 810: loss 2.2703, time 345.93ms, mfu 0.18%\n",
            "iter 820: loss 2.3316, time 346.32ms, mfu 0.18%\n",
            "iter 830: loss 2.3049, time 346.83ms, mfu 0.18%\n",
            "iter 840: loss 2.3203, time 351.28ms, mfu 0.18%\n",
            "iter 850: loss 2.2278, time 345.12ms, mfu 0.18%\n",
            "iter 860: loss 2.2409, time 343.42ms, mfu 0.19%\n",
            "iter 870: loss 2.2361, time 344.98ms, mfu 0.19%\n",
            "iter 880: loss 2.1778, time 354.96ms, mfu 0.19%\n",
            "iter 890: loss 2.2975, time 329.00ms, mfu 0.19%\n",
            "iter 900: loss 2.1698, time 344.56ms, mfu 0.19%\n",
            "iter 910: loss 2.1661, time 355.58ms, mfu 0.19%\n",
            "iter 920: loss 2.1723, time 348.79ms, mfu 0.19%\n",
            "iter 930: loss 2.2655, time 343.30ms, mfu 0.19%\n",
            "iter 940: loss 2.1279, time 345.52ms, mfu 0.19%\n",
            "iter 950: loss 2.1852, time 351.07ms, mfu 0.19%\n",
            "iter 960: loss 2.1536, time 352.35ms, mfu 0.19%\n",
            "iter 970: loss 2.2071, time 344.48ms, mfu 0.19%\n",
            "iter 980: loss 2.2259, time 331.57ms, mfu 0.19%\n",
            "iter 990: loss 2.1147, time 348.96ms, mfu 0.19%\n",
            "step 1000: train loss 2.0687, val loss 2.1010\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1000: loss 2.0601, time 1732.69ms, mfu 0.18%\n",
            "iter 1010: loss 2.1839, time 341.66ms, mfu 0.18%\n",
            "iter 1020: loss 2.1669, time 383.86ms, mfu 0.18%\n",
            "iter 1030: loss 2.0936, time 339.06ms, mfu 0.18%\n",
            "iter 1040: loss 2.1475, time 341.02ms, mfu 0.18%\n",
            "iter 1050: loss 2.1484, time 360.97ms, mfu 0.18%\n",
            "iter 1060: loss 2.0717, time 341.13ms, mfu 0.19%\n",
            "iter 1070: loss 2.1122, time 343.41ms, mfu 0.19%\n",
            "iter 1080: loss 2.1294, time 361.16ms, mfu 0.19%\n",
            "iter 1090: loss 2.0928, time 358.67ms, mfu 0.19%\n",
            "iter 1100: loss 2.1570, time 343.01ms, mfu 0.19%\n",
            "iter 1110: loss 2.0923, time 345.62ms, mfu 0.19%\n",
            "iter 1120: loss 2.1228, time 357.78ms, mfu 0.19%\n",
            "iter 1130: loss 2.0611, time 343.71ms, mfu 0.19%\n",
            "iter 1140: loss 2.0991, time 346.48ms, mfu 0.19%\n",
            "iter 1150: loss 2.0806, time 344.88ms, mfu 0.19%\n",
            "iter 1160: loss 1.9987, time 359.54ms, mfu 0.19%\n",
            "iter 1170: loss 1.9873, time 343.59ms, mfu 0.19%\n",
            "iter 1180: loss 2.0305, time 347.53ms, mfu 0.19%\n",
            "iter 1190: loss 1.9580, time 345.55ms, mfu 0.19%\n",
            "step 1200: train loss 1.9196, val loss 1.9946\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1200: loss 2.0171, time 1730.83ms, mfu 0.18%\n",
            "iter 1210: loss 1.9597, time 348.29ms, mfu 0.18%\n",
            "iter 1220: loss 2.1588, time 342.16ms, mfu 0.18%\n",
            "iter 1230: loss 2.0709, time 339.40ms, mfu 0.18%\n",
            "iter 1240: loss 1.9962, time 341.82ms, mfu 0.18%\n",
            "iter 1250: loss 1.9865, time 343.50ms, mfu 0.19%\n",
            "iter 1260: loss 2.0106, time 351.30ms, mfu 0.19%\n",
            "iter 1270: loss 1.9956, time 348.42ms, mfu 0.19%\n",
            "iter 1280: loss 1.9683, time 345.83ms, mfu 0.19%\n",
            "iter 1290: loss 1.9871, time 339.36ms, mfu 0.19%\n",
            "iter 1300: loss 1.9790, time 350.70ms, mfu 0.19%\n",
            "iter 1310: loss 1.9446, time 342.21ms, mfu 0.19%\n",
            "iter 1320: loss 1.9481, time 343.02ms, mfu 0.19%\n",
            "iter 1330: loss 1.8740, time 363.84ms, mfu 0.19%\n",
            "iter 1340: loss 1.9483, time 340.40ms, mfu 0.19%\n",
            "iter 1350: loss 1.9328, time 347.71ms, mfu 0.19%\n",
            "iter 1360: loss 1.9602, time 348.33ms, mfu 0.19%\n",
            "iter 1370: loss 1.8942, time 349.86ms, mfu 0.19%\n",
            "iter 1380: loss 1.7950, time 351.06ms, mfu 0.19%\n",
            "iter 1390: loss 1.8733, time 353.60ms, mfu 0.19%\n",
            "step 1400: train loss 1.7977, val loss 1.9216\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1400: loss 1.8778, time 1771.99ms, mfu 0.18%\n",
            "iter 1410: loss 1.8698, time 346.75ms, mfu 0.18%\n",
            "iter 1420: loss 1.9038, time 348.26ms, mfu 0.18%\n",
            "iter 1430: loss 1.8518, time 351.58ms, mfu 0.18%\n",
            "iter 1440: loss 1.8498, time 347.58ms, mfu 0.18%\n",
            "iter 1450: loss 1.8204, time 339.88ms, mfu 0.18%\n",
            "iter 1460: loss 1.9415, time 351.21ms, mfu 0.19%\n",
            "iter 1470: loss 1.8728, time 343.98ms, mfu 0.19%\n",
            "iter 1480: loss 1.9305, time 347.35ms, mfu 0.19%\n",
            "iter 1490: loss 1.9311, time 348.05ms, mfu 0.19%\n",
            "iter 1500: loss 1.8657, time 352.79ms, mfu 0.19%\n",
            "iter 1510: loss 1.7806, time 346.60ms, mfu 0.19%\n",
            "iter 1520: loss 1.8817, time 347.70ms, mfu 0.19%\n",
            "iter 1530: loss 1.9689, time 351.55ms, mfu 0.19%\n",
            "iter 1540: loss 1.8013, time 349.17ms, mfu 0.19%\n",
            "iter 1550: loss 1.8333, time 349.75ms, mfu 0.19%\n",
            "iter 1560: loss 1.7645, time 346.05ms, mfu 0.19%\n",
            "iter 1570: loss 1.8030, time 360.12ms, mfu 0.19%\n",
            "iter 1580: loss 1.8780, time 345.02ms, mfu 0.19%\n",
            "iter 1590: loss 1.7876, time 352.14ms, mfu 0.19%\n",
            "step 1600: train loss 1.7066, val loss 1.8568\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1600: loss 1.7519, time 1765.37ms, mfu 0.18%\n",
            "iter 1610: loss 1.9056, time 342.20ms, mfu 0.18%\n",
            "iter 1620: loss 1.7962, time 348.35ms, mfu 0.18%\n",
            "iter 1630: loss 1.8267, time 350.93ms, mfu 0.18%\n",
            "iter 1640: loss 1.8135, time 353.89ms, mfu 0.18%\n",
            "iter 1650: loss 1.7931, time 346.40ms, mfu 0.18%\n",
            "iter 1660: loss 1.7191, time 343.07ms, mfu 0.19%\n",
            "iter 1670: loss 1.7762, time 350.92ms, mfu 0.19%\n",
            "iter 1680: loss 1.6398, time 354.62ms, mfu 0.19%\n",
            "iter 1690: loss 1.7665, time 354.43ms, mfu 0.19%\n",
            "iter 1700: loss 1.7531, time 352.86ms, mfu 0.19%\n",
            "iter 1710: loss 1.7249, time 338.58ms, mfu 0.19%\n",
            "iter 1720: loss 1.8114, time 339.13ms, mfu 0.19%\n",
            "iter 1730: loss 1.7630, time 345.56ms, mfu 0.19%\n",
            "iter 1740: loss 1.7350, time 363.69ms, mfu 0.19%\n",
            "iter 1750: loss 1.7403, time 344.05ms, mfu 0.19%\n",
            "iter 1760: loss 1.8078, time 354.15ms, mfu 0.19%\n",
            "iter 1770: loss 1.6953, time 347.58ms, mfu 0.19%\n",
            "iter 1780: loss 1.7785, time 347.83ms, mfu 0.19%\n",
            "iter 1790: loss 1.6489, time 346.49ms, mfu 0.19%\n",
            "step 1800: train loss 1.6310, val loss 1.8067\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1800: loss 1.7646, time 1736.81ms, mfu 0.18%\n",
            "iter 1810: loss 1.7486, time 354.14ms, mfu 0.18%\n",
            "iter 1820: loss 1.8234, time 343.08ms, mfu 0.18%\n",
            "iter 1830: loss 1.7665, time 347.30ms, mfu 0.18%\n",
            "iter 1840: loss 1.6358, time 352.87ms, mfu 0.18%\n",
            "iter 1850: loss 1.6483, time 349.00ms, mfu 0.18%\n",
            "iter 1860: loss 1.7051, time 345.06ms, mfu 0.19%\n",
            "iter 1870: loss 1.6601, time 349.84ms, mfu 0.19%\n",
            "iter 1880: loss 1.6997, time 352.72ms, mfu 0.19%\n",
            "iter 1890: loss 1.6353, time 351.18ms, mfu 0.19%\n",
            "iter 1900: loss 1.7052, time 353.61ms, mfu 0.19%\n",
            "iter 1910: loss 1.7863, time 351.37ms, mfu 0.19%\n",
            "iter 1920: loss 1.6513, time 348.09ms, mfu 0.19%\n",
            "iter 1930: loss 1.7229, time 337.37ms, mfu 0.19%\n",
            "iter 1940: loss 1.7045, time 343.65ms, mfu 0.19%\n",
            "iter 1950: loss 1.7240, time 362.59ms, mfu 0.19%\n",
            "iter 1960: loss 1.7548, time 347.15ms, mfu 0.19%\n",
            "iter 1970: loss 1.7841, time 350.35ms, mfu 0.19%\n",
            "iter 1980: loss 1.6482, time 354.53ms, mfu 0.19%\n",
            "iter 1990: loss 1.6993, time 344.81ms, mfu 0.19%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 24/32: b64_L4_H8_E128_BS16_MI2000_D20_s24 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E128_BS16_MI2000_D20_s24.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 24\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 0.80M\n",
            "num decayed parameter tensors: 18, with 802,944 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,152 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1702, val loss 4.1669\n",
            "iter 0: loss 4.1761, time 2085.91ms, mfu -100.00%\n",
            "iter 10: loss 4.1629, time 339.55ms, mfu 0.20%\n",
            "iter 20: loss 4.1212, time 344.79ms, mfu 0.20%\n",
            "iter 30: loss 4.0959, time 351.82ms, mfu 0.20%\n",
            "iter 40: loss 4.0292, time 383.73ms, mfu 0.20%\n",
            "iter 50: loss 3.9453, time 343.41ms, mfu 0.20%\n",
            "iter 60: loss 3.8773, time 343.24ms, mfu 0.20%\n",
            "iter 70: loss 3.7791, time 354.46ms, mfu 0.20%\n",
            "iter 80: loss 3.7260, time 338.74ms, mfu 0.20%\n",
            "iter 90: loss 3.7184, time 344.12ms, mfu 0.20%\n",
            "iter 100: loss 3.6724, time 343.69ms, mfu 0.20%\n",
            "iter 110: loss 3.6561, time 355.76ms, mfu 0.20%\n",
            "iter 120: loss 3.6210, time 349.75ms, mfu 0.20%\n",
            "iter 130: loss 3.5509, time 345.32ms, mfu 0.20%\n",
            "iter 140: loss 3.5186, time 348.25ms, mfu 0.20%\n",
            "iter 150: loss 3.5038, time 351.59ms, mfu 0.20%\n",
            "iter 160: loss 3.4369, time 343.52ms, mfu 0.20%\n",
            "iter 170: loss 3.3932, time 346.62ms, mfu 0.20%\n",
            "iter 180: loss 3.4096, time 366.09ms, mfu 0.19%\n",
            "iter 190: loss 3.3906, time 345.14ms, mfu 0.19%\n",
            "step 200: train loss 3.2582, val loss 3.2650\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 200: loss 3.3050, time 1722.89ms, mfu 0.18%\n",
            "iter 210: loss 3.2838, time 345.70ms, mfu 0.18%\n",
            "iter 220: loss 3.2417, time 348.19ms, mfu 0.18%\n",
            "iter 230: loss 3.2294, time 345.72ms, mfu 0.18%\n",
            "iter 240: loss 3.2060, time 343.22ms, mfu 0.19%\n",
            "iter 250: loss 3.1645, time 345.60ms, mfu 0.19%\n",
            "iter 260: loss 3.1369, time 345.04ms, mfu 0.19%\n",
            "iter 270: loss 3.1851, time 344.20ms, mfu 0.19%\n",
            "iter 280: loss 3.0676, time 345.41ms, mfu 0.19%\n",
            "iter 290: loss 3.0346, time 340.95ms, mfu 0.19%\n",
            "iter 300: loss 3.0665, time 341.08ms, mfu 0.19%\n",
            "iter 310: loss 3.0375, time 341.46ms, mfu 0.19%\n",
            "iter 320: loss 3.0098, time 346.02ms, mfu 0.19%\n",
            "iter 330: loss 2.9450, time 344.50ms, mfu 0.19%\n",
            "iter 340: loss 3.0132, time 343.29ms, mfu 0.19%\n",
            "iter 350: loss 2.8650, time 352.38ms, mfu 0.19%\n",
            "iter 360: loss 2.8785, time 343.04ms, mfu 0.19%\n",
            "iter 370: loss 2.8906, time 345.52ms, mfu 0.19%\n",
            "iter 380: loss 2.8631, time 344.65ms, mfu 0.19%\n",
            "iter 390: loss 2.8798, time 345.65ms, mfu 0.19%\n",
            "step 400: train loss 2.7711, val loss 2.7815\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 400: loss 2.7901, time 1731.58ms, mfu 0.18%\n",
            "iter 410: loss 2.8037, time 346.78ms, mfu 0.18%\n",
            "iter 420: loss 2.8099, time 356.94ms, mfu 0.18%\n",
            "iter 430: loss 2.7418, time 338.41ms, mfu 0.18%\n",
            "iter 440: loss 2.7239, time 340.50ms, mfu 0.18%\n",
            "iter 450: loss 2.7545, time 352.86ms, mfu 0.19%\n",
            "iter 460: loss 2.6682, time 338.11ms, mfu 0.19%\n",
            "iter 470: loss 2.6561, time 344.68ms, mfu 0.19%\n",
            "iter 480: loss 2.7048, time 346.40ms, mfu 0.19%\n",
            "iter 490: loss 2.7202, time 351.97ms, mfu 0.19%\n",
            "iter 500: loss 2.6260, time 346.28ms, mfu 0.19%\n",
            "iter 510: loss 2.6403, time 345.47ms, mfu 0.19%\n",
            "iter 520: loss 2.5986, time 342.60ms, mfu 0.19%\n",
            "iter 530: loss 2.6251, time 344.39ms, mfu 0.19%\n",
            "iter 540: loss 2.6045, time 346.83ms, mfu 0.19%\n",
            "iter 550: loss 2.6054, time 353.43ms, mfu 0.19%\n",
            "iter 560: loss 2.5113, time 354.05ms, mfu 0.19%\n",
            "iter 570: loss 2.5066, time 346.82ms, mfu 0.19%\n",
            "iter 580: loss 2.4997, time 343.19ms, mfu 0.19%\n",
            "iter 590: loss 2.5021, time 340.61ms, mfu 0.19%\n",
            "step 600: train loss 2.4719, val loss 2.4782\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 600: loss 2.5119, time 1742.68ms, mfu 0.18%\n",
            "iter 610: loss 2.5173, time 345.71ms, mfu 0.18%\n",
            "iter 620: loss 2.5353, time 342.14ms, mfu 0.18%\n",
            "iter 630: loss 2.5380, time 345.01ms, mfu 0.18%\n",
            "iter 640: loss 2.5064, time 351.82ms, mfu 0.18%\n",
            "iter 650: loss 2.5317, time 344.48ms, mfu 0.19%\n",
            "iter 660: loss 2.5573, time 362.80ms, mfu 0.19%\n",
            "iter 670: loss 2.3809, time 345.96ms, mfu 0.19%\n",
            "iter 680: loss 2.4920, time 336.34ms, mfu 0.19%\n",
            "iter 690: loss 2.4346, time 346.81ms, mfu 0.19%\n",
            "iter 700: loss 2.3728, time 348.27ms, mfu 0.19%\n",
            "iter 710: loss 2.4183, time 347.12ms, mfu 0.19%\n",
            "iter 720: loss 2.4069, time 348.61ms, mfu 0.19%\n",
            "iter 730: loss 2.3751, time 355.17ms, mfu 0.19%\n",
            "iter 740: loss 2.3684, time 347.15ms, mfu 0.19%\n",
            "iter 750: loss 2.3798, time 345.47ms, mfu 0.19%\n",
            "iter 760: loss 2.3492, time 346.24ms, mfu 0.19%\n",
            "iter 770: loss 2.4144, time 351.00ms, mfu 0.19%\n",
            "iter 780: loss 2.4091, time 340.75ms, mfu 0.19%\n",
            "iter 790: loss 2.4089, time 348.38ms, mfu 0.19%\n",
            "step 800: train loss 2.2976, val loss 2.3042\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 800: loss 2.3271, time 1778.81ms, mfu 0.18%\n",
            "iter 810: loss 2.3249, time 340.76ms, mfu 0.18%\n",
            "iter 820: loss 2.4100, time 348.00ms, mfu 0.18%\n",
            "iter 830: loss 2.3753, time 357.11ms, mfu 0.18%\n",
            "iter 840: loss 2.3908, time 347.37ms, mfu 0.18%\n",
            "iter 850: loss 2.3118, time 344.27ms, mfu 0.18%\n",
            "iter 860: loss 2.3121, time 347.57ms, mfu 0.19%\n",
            "iter 870: loss 2.3212, time 362.31ms, mfu 0.19%\n",
            "iter 880: loss 2.2410, time 343.97ms, mfu 0.19%\n",
            "iter 890: loss 2.3512, time 347.86ms, mfu 0.19%\n",
            "iter 900: loss 2.2607, time 348.24ms, mfu 0.19%\n",
            "iter 910: loss 2.2521, time 344.98ms, mfu 0.19%\n",
            "iter 920: loss 2.2615, time 345.46ms, mfu 0.19%\n",
            "iter 930: loss 2.3445, time 342.64ms, mfu 0.19%\n",
            "iter 940: loss 2.2325, time 349.11ms, mfu 0.19%\n",
            "iter 950: loss 2.2988, time 344.21ms, mfu 0.19%\n",
            "iter 960: loss 2.2366, time 350.37ms, mfu 0.19%\n",
            "iter 970: loss 2.3094, time 345.71ms, mfu 0.19%\n",
            "iter 980: loss 2.3378, time 343.56ms, mfu 0.19%\n",
            "iter 990: loss 2.2363, time 347.77ms, mfu 0.19%\n",
            "step 1000: train loss 2.1587, val loss 2.1749\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1000: loss 2.1612, time 1708.17ms, mfu 0.18%\n",
            "iter 1010: loss 2.3128, time 349.13ms, mfu 0.18%\n",
            "iter 1020: loss 2.2449, time 345.16ms, mfu 0.18%\n",
            "iter 1030: loss 2.1987, time 348.42ms, mfu 0.18%\n",
            "iter 1040: loss 2.2296, time 350.31ms, mfu 0.18%\n",
            "iter 1050: loss 2.2538, time 345.01ms, mfu 0.18%\n",
            "iter 1060: loss 2.1767, time 343.54ms, mfu 0.19%\n",
            "iter 1070: loss 2.2109, time 349.93ms, mfu 0.19%\n",
            "iter 1080: loss 2.2203, time 347.44ms, mfu 0.19%\n",
            "iter 1090: loss 2.2068, time 345.29ms, mfu 0.19%\n",
            "iter 1100: loss 2.2782, time 340.09ms, mfu 0.19%\n",
            "iter 1110: loss 2.1896, time 355.23ms, mfu 0.19%\n",
            "iter 1120: loss 2.2176, time 337.76ms, mfu 0.19%\n",
            "iter 1130: loss 2.1534, time 349.09ms, mfu 0.19%\n",
            "iter 1140: loss 2.1862, time 348.14ms, mfu 0.19%\n",
            "iter 1150: loss 2.1791, time 345.25ms, mfu 0.19%\n",
            "iter 1160: loss 2.1420, time 340.87ms, mfu 0.19%\n",
            "iter 1170: loss 2.0931, time 350.85ms, mfu 0.19%\n",
            "iter 1180: loss 2.1219, time 353.21ms, mfu 0.19%\n",
            "iter 1190: loss 2.0885, time 344.94ms, mfu 0.19%\n",
            "step 1200: train loss 2.0162, val loss 2.0674\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1200: loss 2.1301, time 1721.72ms, mfu 0.18%\n",
            "iter 1210: loss 2.1021, time 354.77ms, mfu 0.18%\n",
            "iter 1220: loss 2.2697, time 345.54ms, mfu 0.18%\n",
            "iter 1230: loss 2.1834, time 352.94ms, mfu 0.18%\n",
            "iter 1240: loss 2.1114, time 349.60ms, mfu 0.18%\n",
            "iter 1250: loss 2.0945, time 352.35ms, mfu 0.18%\n",
            "iter 1260: loss 2.1073, time 349.87ms, mfu 0.19%\n",
            "iter 1270: loss 2.0958, time 349.16ms, mfu 0.19%\n",
            "iter 1280: loss 2.0854, time 344.94ms, mfu 0.19%\n",
            "iter 1290: loss 2.0899, time 344.05ms, mfu 0.19%\n",
            "iter 1300: loss 2.1139, time 343.58ms, mfu 0.19%\n",
            "iter 1310: loss 2.0554, time 346.77ms, mfu 0.19%\n",
            "iter 1320: loss 2.0775, time 354.26ms, mfu 0.19%\n",
            "iter 1330: loss 1.9905, time 344.42ms, mfu 0.19%\n",
            "iter 1340: loss 2.0464, time 345.06ms, mfu 0.19%\n",
            "iter 1350: loss 2.0691, time 358.33ms, mfu 0.19%\n",
            "iter 1360: loss 2.0731, time 341.26ms, mfu 0.19%\n",
            "iter 1370: loss 2.0236, time 342.06ms, mfu 0.19%\n",
            "iter 1380: loss 1.9266, time 344.60ms, mfu 0.19%\n",
            "iter 1390: loss 1.9882, time 342.86ms, mfu 0.19%\n",
            "step 1400: train loss 1.9084, val loss 1.9942\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1400: loss 2.0067, time 1732.45ms, mfu 0.18%\n",
            "iter 1410: loss 2.0034, time 347.61ms, mfu 0.18%\n",
            "iter 1420: loss 2.0301, time 344.15ms, mfu 0.18%\n",
            "iter 1430: loss 2.0257, time 340.64ms, mfu 0.18%\n",
            "iter 1440: loss 1.9473, time 341.98ms, mfu 0.18%\n",
            "iter 1450: loss 1.9531, time 353.07ms, mfu 0.19%\n",
            "iter 1460: loss 2.0400, time 352.31ms, mfu 0.19%\n",
            "iter 1470: loss 2.0105, time 331.46ms, mfu 0.19%\n",
            "iter 1480: loss 2.0488, time 342.97ms, mfu 0.19%\n",
            "iter 1490: loss 2.0479, time 365.16ms, mfu 0.19%\n",
            "iter 1500: loss 1.9881, time 347.09ms, mfu 0.19%\n",
            "iter 1510: loss 1.9205, time 345.99ms, mfu 0.19%\n",
            "iter 1520: loss 2.0207, time 350.81ms, mfu 0.19%\n",
            "iter 1530: loss 2.0671, time 346.01ms, mfu 0.19%\n",
            "iter 1540: loss 1.9406, time 351.14ms, mfu 0.19%\n",
            "iter 1550: loss 1.9687, time 345.09ms, mfu 0.19%\n",
            "iter 1560: loss 1.9089, time 353.07ms, mfu 0.19%\n",
            "iter 1570: loss 1.9146, time 354.10ms, mfu 0.19%\n",
            "iter 1580: loss 1.9862, time 341.54ms, mfu 0.19%\n",
            "iter 1590: loss 1.9436, time 349.69ms, mfu 0.19%\n",
            "step 1600: train loss 1.8235, val loss 1.9308\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1600: loss 1.8836, time 1726.64ms, mfu 0.18%\n",
            "iter 1610: loss 2.0311, time 349.66ms, mfu 0.18%\n",
            "iter 1620: loss 1.9047, time 352.20ms, mfu 0.18%\n",
            "iter 1630: loss 1.9810, time 349.69ms, mfu 0.18%\n",
            "iter 1640: loss 1.9574, time 342.96ms, mfu 0.18%\n",
            "iter 1650: loss 1.9274, time 343.08ms, mfu 0.18%\n",
            "iter 1660: loss 1.8633, time 349.72ms, mfu 0.19%\n",
            "iter 1670: loss 1.8758, time 342.95ms, mfu 0.19%\n",
            "iter 1680: loss 1.8111, time 352.21ms, mfu 0.19%\n",
            "iter 1690: loss 1.9049, time 357.62ms, mfu 0.19%\n",
            "iter 1700: loss 1.8490, time 333.23ms, mfu 0.19%\n",
            "iter 1710: loss 1.8333, time 346.13ms, mfu 0.19%\n",
            "iter 1720: loss 1.9476, time 334.87ms, mfu 0.19%\n",
            "iter 1730: loss 1.8758, time 333.88ms, mfu 0.19%\n",
            "iter 1740: loss 1.8699, time 330.29ms, mfu 0.19%\n",
            "iter 1750: loss 1.8919, time 355.55ms, mfu 0.19%\n",
            "iter 1760: loss 1.9510, time 354.52ms, mfu 0.19%\n",
            "iter 1770: loss 1.8211, time 352.45ms, mfu 0.19%\n",
            "iter 1780: loss 1.9305, time 359.51ms, mfu 0.19%\n",
            "iter 1790: loss 1.7874, time 354.69ms, mfu 0.19%\n",
            "step 1800: train loss 1.7377, val loss 1.8862\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1800: loss 1.9018, time 1760.80ms, mfu 0.18%\n",
            "iter 1810: loss 1.8955, time 350.52ms, mfu 0.18%\n",
            "iter 1820: loss 1.9521, time 353.37ms, mfu 0.18%\n",
            "iter 1830: loss 1.8956, time 353.89ms, mfu 0.18%\n",
            "iter 1840: loss 1.7737, time 354.28ms, mfu 0.18%\n",
            "iter 1850: loss 1.7795, time 352.36ms, mfu 0.18%\n",
            "iter 1860: loss 1.8354, time 355.37ms, mfu 0.18%\n",
            "iter 1870: loss 1.7755, time 363.58ms, mfu 0.18%\n",
            "iter 1880: loss 1.8281, time 363.64ms, mfu 0.18%\n",
            "iter 1890: loss 1.7761, time 333.92ms, mfu 0.19%\n",
            "iter 1900: loss 1.8407, time 348.86ms, mfu 0.19%\n",
            "iter 1910: loss 1.8957, time 333.65ms, mfu 0.19%\n",
            "iter 1920: loss 1.7827, time 330.00ms, mfu 0.19%\n",
            "iter 1930: loss 1.8452, time 334.34ms, mfu 0.19%\n",
            "iter 1940: loss 1.8057, time 335.24ms, mfu 0.19%\n",
            "iter 1950: loss 1.8524, time 327.29ms, mfu 0.19%\n",
            "iter 1960: loss 1.8720, time 329.11ms, mfu 0.20%\n",
            "iter 1970: loss 1.9288, time 333.67ms, mfu 0.20%\n",
            "iter 1980: loss 1.7847, time 329.10ms, mfu 0.20%\n",
            "iter 1990: loss 1.8231, time 327.15ms, mfu 0.20%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 25/32: b64_L4_H8_E256_BS8_MI1000_D10_s25 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS8_MI1000_D10_s25.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D10_s25\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 25\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2848, val loss 4.2795\n",
            "iter 0: loss 4.3122, time 1925.30ms, mfu -100.00%\n",
            "iter 10: loss 4.2481, time 319.57ms, mfu 0.41%\n",
            "iter 20: loss 4.0887, time 339.59ms, mfu 0.40%\n",
            "iter 30: loss 3.8727, time 341.46ms, mfu 0.40%\n",
            "iter 40: loss 3.6803, time 338.90ms, mfu 0.40%\n",
            "iter 50: loss 3.6134, time 332.93ms, mfu 0.40%\n",
            "iter 60: loss 3.5067, time 333.96ms, mfu 0.40%\n",
            "iter 70: loss 3.4168, time 340.19ms, mfu 0.40%\n",
            "iter 80: loss 3.4438, time 330.83ms, mfu 0.40%\n",
            "iter 90: loss 3.2155, time 332.32ms, mfu 0.40%\n",
            "iter 100: loss 3.1046, time 338.15ms, mfu 0.39%\n",
            "iter 110: loss 2.9983, time 329.65ms, mfu 0.39%\n",
            "iter 120: loss 3.0277, time 333.75ms, mfu 0.39%\n",
            "iter 130: loss 2.9600, time 332.49ms, mfu 0.39%\n",
            "iter 140: loss 2.8320, time 322.16ms, mfu 0.39%\n",
            "iter 150: loss 2.8181, time 331.17ms, mfu 0.39%\n",
            "iter 160: loss 2.7788, time 330.31ms, mfu 0.39%\n",
            "iter 170: loss 2.7932, time 330.41ms, mfu 0.39%\n",
            "iter 180: loss 2.8757, time 333.62ms, mfu 0.39%\n",
            "iter 190: loss 2.7402, time 331.23ms, mfu 0.39%\n",
            "step 200: train loss 2.6761, val loss 2.6900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 200: loss 2.7685, time 1672.70ms, mfu 0.36%\n",
            "iter 210: loss 2.6867, time 337.06ms, mfu 0.36%\n",
            "iter 220: loss 2.5660, time 343.17ms, mfu 0.37%\n",
            "iter 230: loss 2.6656, time 347.03ms, mfu 0.37%\n",
            "iter 240: loss 2.6717, time 332.40ms, mfu 0.37%\n",
            "iter 250: loss 2.6136, time 336.54ms, mfu 0.37%\n",
            "iter 260: loss 2.6673, time 325.90ms, mfu 0.37%\n",
            "iter 270: loss 2.4549, time 330.29ms, mfu 0.38%\n",
            "iter 280: loss 2.5746, time 351.62ms, mfu 0.37%\n",
            "iter 290: loss 2.6328, time 329.39ms, mfu 0.38%\n",
            "iter 300: loss 2.5208, time 327.27ms, mfu 0.38%\n",
            "iter 310: loss 2.4852, time 338.40ms, mfu 0.38%\n",
            "iter 320: loss 2.5762, time 331.59ms, mfu 0.38%\n",
            "iter 330: loss 2.4378, time 335.77ms, mfu 0.38%\n",
            "iter 340: loss 2.5175, time 330.85ms, mfu 0.38%\n",
            "iter 350: loss 2.4423, time 326.64ms, mfu 0.38%\n",
            "iter 360: loss 2.3510, time 329.52ms, mfu 0.38%\n",
            "iter 370: loss 2.4120, time 333.58ms, mfu 0.39%\n",
            "iter 380: loss 2.3579, time 333.02ms, mfu 0.39%\n",
            "iter 390: loss 2.4793, time 337.48ms, mfu 0.39%\n",
            "step 400: train loss 2.3722, val loss 2.3899\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 400: loss 2.4128, time 1683.65ms, mfu 0.35%\n",
            "iter 410: loss 2.3159, time 324.01ms, mfu 0.36%\n",
            "iter 420: loss 2.4490, time 328.76ms, mfu 0.36%\n",
            "iter 430: loss 2.3183, time 335.65ms, mfu 0.37%\n",
            "iter 440: loss 2.4214, time 326.21ms, mfu 0.37%\n",
            "iter 450: loss 2.4800, time 331.36ms, mfu 0.37%\n",
            "iter 460: loss 2.3520, time 339.89ms, mfu 0.37%\n",
            "iter 470: loss 2.3782, time 327.99ms, mfu 0.37%\n",
            "iter 480: loss 2.3493, time 335.63ms, mfu 0.38%\n",
            "iter 490: loss 2.3283, time 331.59ms, mfu 0.38%\n",
            "iter 500: loss 2.3494, time 330.13ms, mfu 0.38%\n",
            "iter 510: loss 2.2906, time 323.54ms, mfu 0.38%\n",
            "iter 520: loss 2.2903, time 331.58ms, mfu 0.38%\n",
            "iter 530: loss 2.3435, time 324.44ms, mfu 0.38%\n",
            "iter 540: loss 2.2785, time 329.00ms, mfu 0.38%\n",
            "iter 550: loss 2.1872, time 323.60ms, mfu 0.39%\n",
            "iter 560: loss 2.3057, time 325.93ms, mfu 0.39%\n",
            "iter 570: loss 2.1446, time 337.37ms, mfu 0.39%\n",
            "iter 580: loss 2.2559, time 326.51ms, mfu 0.39%\n",
            "iter 590: loss 2.1999, time 325.18ms, mfu 0.39%\n",
            "step 600: train loss 2.1485, val loss 2.1707\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 600: loss 2.1867, time 1649.29ms, mfu 0.36%\n",
            "iter 610: loss 2.2663, time 325.40ms, mfu 0.36%\n",
            "iter 620: loss 2.2329, time 327.19ms, mfu 0.37%\n",
            "iter 630: loss 2.2947, time 325.54ms, mfu 0.37%\n",
            "iter 640: loss 2.1912, time 332.46ms, mfu 0.37%\n",
            "iter 650: loss 2.1846, time 330.73ms, mfu 0.37%\n",
            "iter 660: loss 2.1935, time 331.14ms, mfu 0.38%\n",
            "iter 670: loss 2.2017, time 327.17ms, mfu 0.38%\n",
            "iter 680: loss 2.1131, time 332.76ms, mfu 0.38%\n",
            "iter 690: loss 2.0694, time 325.02ms, mfu 0.38%\n",
            "iter 700: loss 2.1049, time 328.04ms, mfu 0.38%\n",
            "iter 710: loss 2.0061, time 324.04ms, mfu 0.38%\n",
            "iter 720: loss 2.0714, time 324.55ms, mfu 0.39%\n",
            "iter 730: loss 2.1111, time 326.98ms, mfu 0.39%\n",
            "iter 740: loss 2.0423, time 322.97ms, mfu 0.39%\n",
            "iter 750: loss 2.0163, time 334.12ms, mfu 0.39%\n",
            "iter 760: loss 2.0528, time 331.32ms, mfu 0.39%\n",
            "iter 770: loss 1.9813, time 329.45ms, mfu 0.39%\n",
            "iter 780: loss 1.9912, time 326.76ms, mfu 0.39%\n",
            "iter 790: loss 2.1688, time 325.36ms, mfu 0.39%\n",
            "step 800: train loss 1.9347, val loss 2.0004\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 800: loss 2.0911, time 1661.20ms, mfu 0.36%\n",
            "iter 810: loss 2.1212, time 324.21ms, mfu 0.36%\n",
            "iter 820: loss 1.9476, time 334.42ms, mfu 0.37%\n",
            "iter 830: loss 1.9421, time 333.43ms, mfu 0.37%\n",
            "iter 840: loss 1.9867, time 327.24ms, mfu 0.37%\n",
            "iter 850: loss 1.9484, time 324.26ms, mfu 0.37%\n",
            "iter 860: loss 1.9427, time 329.77ms, mfu 0.38%\n",
            "iter 870: loss 2.0822, time 322.15ms, mfu 0.38%\n",
            "iter 880: loss 1.9728, time 344.29ms, mfu 0.38%\n",
            "iter 890: loss 1.9399, time 321.19ms, mfu 0.38%\n",
            "iter 900: loss 1.9114, time 348.24ms, mfu 0.38%\n",
            "iter 910: loss 2.0003, time 324.55ms, mfu 0.38%\n",
            "iter 920: loss 1.8211, time 331.15ms, mfu 0.38%\n",
            "iter 930: loss 1.7743, time 330.46ms, mfu 0.38%\n",
            "iter 940: loss 2.0976, time 327.49ms, mfu 0.39%\n",
            "iter 950: loss 1.8633, time 331.43ms, mfu 0.39%\n",
            "iter 960: loss 1.9548, time 333.96ms, mfu 0.39%\n",
            "iter 970: loss 1.8722, time 326.70ms, mfu 0.39%\n",
            "iter 980: loss 1.9064, time 334.89ms, mfu 0.39%\n",
            "iter 990: loss 1.9457, time 328.19ms, mfu 0.39%\n",
            "step 1000: train loss 1.7594, val loss 1.8970\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 1000: loss 1.6944, time 1653.31ms, mfu 0.36%\n",
            "\n",
            "=== Experiment 26/32: b64_L4_H8_E256_BS8_MI1000_D20_s26 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS8_MI1000_D20_s26.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D20_s26\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 26\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2848, val loss 4.2795\n",
            "iter 0: loss 4.2829, time 1935.43ms, mfu -100.00%\n",
            "iter 10: loss 4.2476, time 325.11ms, mfu 0.40%\n",
            "iter 20: loss 4.1187, time 338.17ms, mfu 0.40%\n",
            "iter 30: loss 3.9243, time 324.53ms, mfu 0.40%\n",
            "iter 40: loss 3.7347, time 327.81ms, mfu 0.40%\n",
            "iter 50: loss 3.6495, time 325.19ms, mfu 0.40%\n",
            "iter 60: loss 3.5403, time 327.38ms, mfu 0.40%\n",
            "iter 70: loss 3.4489, time 336.80ms, mfu 0.40%\n",
            "iter 80: loss 3.5004, time 321.54ms, mfu 0.40%\n",
            "iter 90: loss 3.2912, time 324.51ms, mfu 0.40%\n",
            "iter 100: loss 3.1675, time 333.64ms, mfu 0.40%\n",
            "iter 110: loss 3.0813, time 326.63ms, mfu 0.40%\n",
            "iter 120: loss 3.1122, time 331.46ms, mfu 0.40%\n",
            "iter 130: loss 3.0190, time 335.98ms, mfu 0.40%\n",
            "iter 140: loss 2.9128, time 322.57ms, mfu 0.40%\n",
            "iter 150: loss 2.8811, time 328.63ms, mfu 0.40%\n",
            "iter 160: loss 2.8443, time 330.03ms, mfu 0.40%\n",
            "iter 170: loss 2.8306, time 326.93ms, mfu 0.40%\n",
            "iter 180: loss 2.9286, time 326.06ms, mfu 0.40%\n",
            "iter 190: loss 2.7934, time 327.41ms, mfu 0.40%\n",
            "step 200: train loss 2.6964, val loss 2.7065\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 200: loss 2.8279, time 1648.43ms, mfu 0.36%\n",
            "iter 210: loss 2.7141, time 326.95ms, mfu 0.37%\n",
            "iter 220: loss 2.6022, time 357.88ms, mfu 0.37%\n",
            "iter 230: loss 2.7079, time 327.48ms, mfu 0.37%\n",
            "iter 240: loss 2.7162, time 329.06ms, mfu 0.37%\n",
            "iter 250: loss 2.6474, time 331.62ms, mfu 0.37%\n",
            "iter 260: loss 2.7007, time 327.05ms, mfu 0.38%\n",
            "iter 270: loss 2.4991, time 326.08ms, mfu 0.38%\n",
            "iter 280: loss 2.6419, time 359.32ms, mfu 0.38%\n",
            "iter 290: loss 2.6664, time 328.14ms, mfu 0.38%\n",
            "iter 300: loss 2.5733, time 332.29ms, mfu 0.38%\n",
            "iter 310: loss 2.5365, time 327.08ms, mfu 0.38%\n",
            "iter 320: loss 2.6041, time 330.92ms, mfu 0.38%\n",
            "iter 330: loss 2.4941, time 333.41ms, mfu 0.38%\n",
            "iter 340: loss 2.5478, time 329.63ms, mfu 0.38%\n",
            "iter 350: loss 2.4853, time 345.95ms, mfu 0.38%\n",
            "iter 360: loss 2.3999, time 326.74ms, mfu 0.38%\n",
            "iter 370: loss 2.4624, time 331.26ms, mfu 0.39%\n",
            "iter 380: loss 2.4005, time 339.63ms, mfu 0.39%\n",
            "iter 390: loss 2.5178, time 342.60ms, mfu 0.38%\n",
            "step 400: train loss 2.4137, val loss 2.4303\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 400: loss 2.4710, time 1685.42ms, mfu 0.35%\n",
            "iter 410: loss 2.3711, time 334.68ms, mfu 0.36%\n",
            "iter 420: loss 2.5046, time 328.63ms, mfu 0.36%\n",
            "iter 430: loss 2.3739, time 354.19ms, mfu 0.36%\n",
            "iter 440: loss 2.4635, time 346.19ms, mfu 0.36%\n",
            "iter 450: loss 2.5352, time 325.12ms, mfu 0.37%\n",
            "iter 460: loss 2.3861, time 330.47ms, mfu 0.37%\n",
            "iter 470: loss 2.4271, time 349.05ms, mfu 0.37%\n",
            "iter 480: loss 2.4385, time 344.69ms, mfu 0.37%\n",
            "iter 490: loss 2.3610, time 333.73ms, mfu 0.37%\n",
            "iter 500: loss 2.4087, time 331.90ms, mfu 0.37%\n",
            "iter 510: loss 2.3724, time 329.36ms, mfu 0.38%\n",
            "iter 520: loss 2.3928, time 329.30ms, mfu 0.38%\n",
            "iter 530: loss 2.3998, time 338.99ms, mfu 0.38%\n",
            "iter 540: loss 2.3601, time 331.52ms, mfu 0.38%\n",
            "iter 550: loss 2.2585, time 328.00ms, mfu 0.38%\n",
            "iter 560: loss 2.3743, time 329.41ms, mfu 0.38%\n",
            "iter 570: loss 2.2174, time 333.44ms, mfu 0.38%\n",
            "iter 580: loss 2.3240, time 333.33ms, mfu 0.38%\n",
            "iter 590: loss 2.3282, time 339.53ms, mfu 0.38%\n",
            "step 600: train loss 2.2305, val loss 2.2396\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 600: loss 2.2919, time 1694.07ms, mfu 0.35%\n",
            "iter 610: loss 2.3207, time 332.92ms, mfu 0.36%\n",
            "iter 620: loss 2.3239, time 335.44ms, mfu 0.36%\n",
            "iter 630: loss 2.3551, time 354.39ms, mfu 0.36%\n",
            "iter 640: loss 2.2593, time 337.71ms, mfu 0.36%\n",
            "iter 650: loss 2.2795, time 335.11ms, mfu 0.37%\n",
            "iter 660: loss 2.2792, time 331.67ms, mfu 0.37%\n",
            "iter 670: loss 2.2866, time 348.53ms, mfu 0.37%\n",
            "iter 680: loss 2.1835, time 331.16ms, mfu 0.37%\n",
            "iter 690: loss 2.1702, time 337.93ms, mfu 0.37%\n",
            "iter 700: loss 2.1789, time 336.23ms, mfu 0.37%\n",
            "iter 710: loss 2.1086, time 325.48ms, mfu 0.38%\n",
            "iter 720: loss 2.1811, time 326.86ms, mfu 0.38%\n",
            "iter 730: loss 2.2000, time 330.49ms, mfu 0.38%\n",
            "iter 740: loss 2.1473, time 343.84ms, mfu 0.38%\n",
            "iter 750: loss 2.1277, time 328.06ms, mfu 0.38%\n",
            "iter 760: loss 2.1451, time 336.40ms, mfu 0.38%\n",
            "iter 770: loss 2.0656, time 335.19ms, mfu 0.38%\n",
            "iter 780: loss 2.1117, time 341.01ms, mfu 0.38%\n",
            "iter 790: loss 2.2514, time 332.59ms, mfu 0.38%\n",
            "step 800: train loss 2.0432, val loss 2.0863\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 800: loss 2.2425, time 1664.55ms, mfu 0.35%\n",
            "iter 810: loss 2.2188, time 343.78ms, mfu 0.35%\n",
            "iter 820: loss 2.0700, time 342.07ms, mfu 0.36%\n",
            "iter 830: loss 2.0617, time 401.38ms, mfu 0.35%\n",
            "iter 840: loss 2.1093, time 354.59ms, mfu 0.36%\n",
            "iter 850: loss 2.0765, time 330.33ms, mfu 0.36%\n",
            "iter 860: loss 2.0787, time 337.03ms, mfu 0.36%\n",
            "iter 870: loss 2.2045, time 326.28ms, mfu 0.37%\n",
            "iter 880: loss 2.0966, time 334.85ms, mfu 0.37%\n",
            "iter 890: loss 2.1065, time 335.60ms, mfu 0.37%\n",
            "iter 900: loss 2.0256, time 329.52ms, mfu 0.37%\n",
            "iter 910: loss 2.0882, time 333.86ms, mfu 0.37%\n",
            "iter 920: loss 1.9522, time 345.50ms, mfu 0.37%\n",
            "iter 930: loss 1.9178, time 337.89ms, mfu 0.37%\n",
            "iter 940: loss 2.2227, time 336.78ms, mfu 0.38%\n",
            "iter 950: loss 2.0270, time 324.66ms, mfu 0.38%\n",
            "iter 960: loss 2.1091, time 331.59ms, mfu 0.38%\n",
            "iter 970: loss 1.9678, time 330.45ms, mfu 0.38%\n",
            "iter 980: loss 2.0145, time 330.93ms, mfu 0.38%\n",
            "iter 990: loss 2.0934, time 327.68ms, mfu 0.38%\n",
            "step 1000: train loss 1.8798, val loss 1.9804\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 1000: loss 1.8830, time 1665.47ms, mfu 0.35%\n",
            "\n",
            "=== Experiment 27/32: b64_L4_H8_E256_BS8_MI2000_D10_s27 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS8_MI2000_D10_s27.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 27\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2848, val loss 4.2795\n",
            "iter 0: loss 4.3122, time 1945.03ms, mfu -100.00%\n",
            "iter 10: loss 4.2481, time 334.49ms, mfu 0.39%\n",
            "iter 20: loss 4.0887, time 331.90ms, mfu 0.39%\n",
            "iter 30: loss 3.8727, time 325.89ms, mfu 0.39%\n",
            "iter 40: loss 3.6803, time 336.25ms, mfu 0.39%\n",
            "iter 50: loss 3.6134, time 330.16ms, mfu 0.39%\n",
            "iter 60: loss 3.5067, time 334.56ms, mfu 0.39%\n",
            "iter 70: loss 3.4168, time 336.52ms, mfu 0.39%\n",
            "iter 80: loss 3.4438, time 349.78ms, mfu 0.39%\n",
            "iter 90: loss 3.2155, time 334.79ms, mfu 0.39%\n",
            "iter 100: loss 3.1046, time 327.31ms, mfu 0.39%\n",
            "iter 110: loss 2.9983, time 339.06ms, mfu 0.39%\n",
            "iter 120: loss 3.0277, time 334.68ms, mfu 0.39%\n",
            "iter 130: loss 2.9600, time 335.22ms, mfu 0.39%\n",
            "iter 140: loss 2.8320, time 340.17ms, mfu 0.39%\n",
            "iter 150: loss 2.8181, time 345.74ms, mfu 0.39%\n",
            "iter 160: loss 2.7788, time 336.93ms, mfu 0.39%\n",
            "iter 170: loss 2.7932, time 335.70ms, mfu 0.39%\n",
            "iter 180: loss 2.8757, time 338.43ms, mfu 0.39%\n",
            "iter 190: loss 2.7402, time 338.08ms, mfu 0.39%\n",
            "step 200: train loss 2.6761, val loss 2.6900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 200: loss 2.7685, time 1667.39ms, mfu 0.35%\n",
            "iter 210: loss 2.6867, time 337.31ms, mfu 0.36%\n",
            "iter 220: loss 2.5660, time 341.59ms, mfu 0.36%\n",
            "iter 230: loss 2.6656, time 327.75ms, mfu 0.36%\n",
            "iter 240: loss 2.6717, time 331.50ms, mfu 0.37%\n",
            "iter 250: loss 2.6136, time 337.75ms, mfu 0.37%\n",
            "iter 260: loss 2.6673, time 344.82ms, mfu 0.37%\n",
            "iter 270: loss 2.4549, time 337.86ms, mfu 0.37%\n",
            "iter 280: loss 2.5746, time 332.00ms, mfu 0.37%\n",
            "iter 290: loss 2.6328, time 336.61ms, mfu 0.37%\n",
            "iter 300: loss 2.5208, time 339.07ms, mfu 0.37%\n",
            "iter 310: loss 2.4852, time 330.16ms, mfu 0.38%\n",
            "iter 320: loss 2.5762, time 334.05ms, mfu 0.38%\n",
            "iter 330: loss 2.4378, time 330.14ms, mfu 0.38%\n",
            "iter 340: loss 2.5175, time 328.75ms, mfu 0.38%\n",
            "iter 350: loss 2.4423, time 338.19ms, mfu 0.38%\n",
            "iter 360: loss 2.3510, time 339.74ms, mfu 0.38%\n",
            "iter 370: loss 2.4120, time 329.59ms, mfu 0.38%\n",
            "iter 380: loss 2.3579, time 331.26ms, mfu 0.38%\n",
            "iter 390: loss 2.4793, time 330.36ms, mfu 0.38%\n",
            "step 400: train loss 2.3722, val loss 2.3899\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 400: loss 2.4128, time 1669.16ms, mfu 0.35%\n",
            "iter 410: loss 2.3159, time 331.47ms, mfu 0.36%\n",
            "iter 420: loss 2.4490, time 331.63ms, mfu 0.36%\n",
            "iter 430: loss 2.3183, time 344.93ms, mfu 0.36%\n",
            "iter 440: loss 2.4214, time 320.42ms, mfu 0.37%\n",
            "iter 450: loss 2.4800, time 331.38ms, mfu 0.37%\n",
            "iter 460: loss 2.3520, time 334.92ms, mfu 0.37%\n",
            "iter 470: loss 2.3782, time 344.64ms, mfu 0.37%\n",
            "iter 480: loss 2.3493, time 333.69ms, mfu 0.37%\n",
            "iter 490: loss 2.3283, time 332.31ms, mfu 0.38%\n",
            "iter 500: loss 2.3494, time 330.69ms, mfu 0.38%\n",
            "iter 510: loss 2.2906, time 330.22ms, mfu 0.38%\n",
            "iter 520: loss 2.2903, time 331.84ms, mfu 0.38%\n",
            "iter 530: loss 2.3435, time 333.22ms, mfu 0.38%\n",
            "iter 540: loss 2.2785, time 340.48ms, mfu 0.38%\n",
            "iter 550: loss 2.1872, time 334.71ms, mfu 0.38%\n",
            "iter 560: loss 2.3057, time 333.51ms, mfu 0.38%\n",
            "iter 570: loss 2.1446, time 331.83ms, mfu 0.38%\n",
            "iter 580: loss 2.2559, time 342.83ms, mfu 0.38%\n",
            "iter 590: loss 2.1999, time 331.78ms, mfu 0.38%\n",
            "step 600: train loss 2.1485, val loss 2.1707\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 600: loss 2.1867, time 1669.87ms, mfu 0.35%\n",
            "iter 610: loss 2.2663, time 335.25ms, mfu 0.36%\n",
            "iter 620: loss 2.2329, time 333.55ms, mfu 0.36%\n",
            "iter 630: loss 2.2947, time 340.10ms, mfu 0.36%\n",
            "iter 640: loss 2.1912, time 330.14ms, mfu 0.36%\n",
            "iter 650: loss 2.1846, time 330.18ms, mfu 0.37%\n",
            "iter 660: loss 2.1935, time 333.29ms, mfu 0.37%\n",
            "iter 670: loss 2.2017, time 327.61ms, mfu 0.37%\n",
            "iter 680: loss 2.1131, time 330.05ms, mfu 0.37%\n",
            "iter 690: loss 2.0694, time 328.91ms, mfu 0.38%\n",
            "iter 700: loss 2.1049, time 333.06ms, mfu 0.38%\n",
            "iter 710: loss 2.0061, time 336.09ms, mfu 0.38%\n",
            "iter 720: loss 2.0714, time 346.11ms, mfu 0.38%\n",
            "iter 730: loss 2.1111, time 336.96ms, mfu 0.38%\n",
            "iter 740: loss 2.0423, time 337.76ms, mfu 0.38%\n",
            "iter 750: loss 2.0163, time 330.51ms, mfu 0.38%\n",
            "iter 760: loss 2.0528, time 324.79ms, mfu 0.38%\n",
            "iter 770: loss 1.9813, time 334.71ms, mfu 0.38%\n",
            "iter 780: loss 1.9912, time 331.58ms, mfu 0.38%\n",
            "iter 790: loss 2.1688, time 337.16ms, mfu 0.38%\n",
            "step 800: train loss 1.9347, val loss 2.0004\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 800: loss 2.0911, time 1671.45ms, mfu 0.35%\n",
            "iter 810: loss 2.1212, time 325.30ms, mfu 0.36%\n",
            "iter 820: loss 1.9476, time 340.13ms, mfu 0.36%\n",
            "iter 830: loss 1.9421, time 333.60ms, mfu 0.36%\n",
            "iter 840: loss 1.9867, time 326.80ms, mfu 0.37%\n",
            "iter 850: loss 1.9484, time 330.99ms, mfu 0.37%\n",
            "iter 860: loss 1.9427, time 330.45ms, mfu 0.37%\n",
            "iter 870: loss 2.0822, time 334.30ms, mfu 0.37%\n",
            "iter 880: loss 1.9728, time 332.21ms, mfu 0.38%\n",
            "iter 890: loss 1.9399, time 331.20ms, mfu 0.38%\n",
            "iter 900: loss 1.9114, time 334.63ms, mfu 0.38%\n",
            "iter 910: loss 2.0003, time 332.90ms, mfu 0.38%\n",
            "iter 920: loss 1.8211, time 334.88ms, mfu 0.38%\n",
            "iter 930: loss 1.7743, time 339.75ms, mfu 0.38%\n",
            "iter 940: loss 2.0976, time 332.66ms, mfu 0.38%\n",
            "iter 950: loss 1.8633, time 336.80ms, mfu 0.38%\n",
            "iter 960: loss 1.9548, time 331.21ms, mfu 0.38%\n",
            "iter 970: loss 1.8722, time 336.36ms, mfu 0.38%\n",
            "iter 980: loss 1.9064, time 325.97ms, mfu 0.38%\n",
            "iter 990: loss 1.9457, time 327.22ms, mfu 0.39%\n",
            "step 1000: train loss 1.7594, val loss 1.8970\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1000: loss 1.6944, time 1691.12ms, mfu 0.35%\n",
            "iter 1010: loss 1.8117, time 321.55ms, mfu 0.36%\n",
            "iter 1020: loss 1.7283, time 323.91ms, mfu 0.36%\n",
            "iter 1030: loss 1.9764, time 334.69ms, mfu 0.37%\n",
            "iter 1040: loss 1.9236, time 351.06ms, mfu 0.37%\n",
            "iter 1050: loss 1.7240, time 332.30ms, mfu 0.37%\n",
            "iter 1060: loss 1.7784, time 331.93ms, mfu 0.37%\n",
            "iter 1070: loss 1.8348, time 332.55ms, mfu 0.37%\n",
            "iter 1080: loss 1.7667, time 341.43ms, mfu 0.37%\n",
            "iter 1090: loss 1.7602, time 334.69ms, mfu 0.38%\n",
            "iter 1100: loss 1.6817, time 331.34ms, mfu 0.38%\n",
            "iter 1110: loss 1.8347, time 331.64ms, mfu 0.38%\n",
            "iter 1120: loss 1.7404, time 332.55ms, mfu 0.38%\n",
            "iter 1130: loss 1.7536, time 327.93ms, mfu 0.38%\n",
            "iter 1140: loss 1.7086, time 335.73ms, mfu 0.38%\n",
            "iter 1150: loss 1.6452, time 328.64ms, mfu 0.38%\n",
            "iter 1160: loss 1.7054, time 336.62ms, mfu 0.38%\n",
            "iter 1170: loss 1.5989, time 335.99ms, mfu 0.38%\n",
            "iter 1180: loss 1.6150, time 337.73ms, mfu 0.38%\n",
            "iter 1190: loss 1.7353, time 327.68ms, mfu 0.38%\n",
            "step 1200: train loss 1.6189, val loss 1.7990\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1200: loss 1.6197, time 1671.04ms, mfu 0.35%\n",
            "iter 1210: loss 1.8033, time 325.69ms, mfu 0.36%\n",
            "iter 1220: loss 1.6952, time 324.69ms, mfu 0.36%\n",
            "iter 1230: loss 1.7869, time 351.64ms, mfu 0.36%\n",
            "iter 1240: loss 1.4902, time 330.19ms, mfu 0.37%\n",
            "iter 1250: loss 1.6512, time 328.12ms, mfu 0.37%\n",
            "iter 1260: loss 1.6853, time 329.99ms, mfu 0.37%\n",
            "iter 1270: loss 1.7407, time 334.84ms, mfu 0.37%\n",
            "iter 1280: loss 1.7002, time 332.18ms, mfu 0.38%\n",
            "iter 1290: loss 1.5801, time 341.64ms, mfu 0.38%\n",
            "iter 1300: loss 1.6771, time 332.34ms, mfu 0.38%\n",
            "iter 1310: loss 1.5658, time 333.40ms, mfu 0.38%\n",
            "iter 1320: loss 1.7004, time 339.93ms, mfu 0.38%\n",
            "iter 1330: loss 1.8443, time 330.62ms, mfu 0.38%\n",
            "iter 1340: loss 1.6707, time 328.67ms, mfu 0.38%\n",
            "iter 1350: loss 1.5907, time 335.74ms, mfu 0.38%\n",
            "iter 1360: loss 1.6093, time 343.78ms, mfu 0.38%\n",
            "iter 1370: loss 1.6498, time 333.16ms, mfu 0.38%\n",
            "iter 1380: loss 1.4988, time 317.03ms, mfu 0.39%\n",
            "iter 1390: loss 1.6780, time 333.28ms, mfu 0.39%\n",
            "step 1400: train loss 1.5486, val loss 1.7152\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1400: loss 1.5430, time 1693.80ms, mfu 0.35%\n",
            "iter 1410: loss 1.6096, time 334.58ms, mfu 0.36%\n",
            "iter 1420: loss 1.8041, time 321.10ms, mfu 0.36%\n",
            "iter 1430: loss 1.6636, time 342.89ms, mfu 0.36%\n",
            "iter 1440: loss 1.6342, time 326.83ms, mfu 0.37%\n",
            "iter 1450: loss 1.6018, time 329.23ms, mfu 0.37%\n",
            "iter 1460: loss 1.4767, time 329.37ms, mfu 0.37%\n",
            "iter 1470: loss 1.5741, time 324.32ms, mfu 0.38%\n",
            "iter 1480: loss 1.6992, time 330.98ms, mfu 0.38%\n",
            "iter 1490: loss 1.4544, time 332.51ms, mfu 0.38%\n",
            "iter 1500: loss 1.4665, time 346.45ms, mfu 0.38%\n",
            "iter 1510: loss 1.6093, time 331.53ms, mfu 0.38%\n",
            "iter 1520: loss 1.5754, time 338.69ms, mfu 0.38%\n",
            "iter 1530: loss 1.5791, time 332.00ms, mfu 0.38%\n",
            "iter 1540: loss 1.6324, time 332.90ms, mfu 0.38%\n",
            "iter 1550: loss 1.5040, time 337.09ms, mfu 0.38%\n",
            "iter 1560: loss 1.5287, time 323.24ms, mfu 0.38%\n",
            "iter 1570: loss 1.5855, time 333.24ms, mfu 0.38%\n",
            "iter 1580: loss 1.6439, time 333.11ms, mfu 0.39%\n",
            "iter 1590: loss 1.6839, time 329.76ms, mfu 0.39%\n",
            "step 1600: train loss 1.4880, val loss 1.6664\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1600: loss 1.6258, time 1659.13ms, mfu 0.36%\n",
            "iter 1610: loss 1.6813, time 344.35ms, mfu 0.36%\n",
            "iter 1620: loss 1.5854, time 342.30ms, mfu 0.36%\n",
            "iter 1630: loss 1.5166, time 340.29ms, mfu 0.36%\n",
            "iter 1640: loss 1.5283, time 334.72ms, mfu 0.36%\n",
            "iter 1650: loss 1.6142, time 333.04ms, mfu 0.37%\n",
            "iter 1660: loss 1.4286, time 329.52ms, mfu 0.37%\n",
            "iter 1670: loss 1.3799, time 336.91ms, mfu 0.37%\n",
            "iter 1680: loss 1.5146, time 340.98ms, mfu 0.37%\n",
            "iter 1690: loss 1.4276, time 334.98ms, mfu 0.37%\n",
            "iter 1700: loss 1.5428, time 334.38ms, mfu 0.38%\n",
            "iter 1710: loss 1.4804, time 335.58ms, mfu 0.38%\n",
            "iter 1720: loss 1.4225, time 330.70ms, mfu 0.38%\n",
            "iter 1730: loss 1.3955, time 336.90ms, mfu 0.38%\n",
            "iter 1740: loss 1.6096, time 334.94ms, mfu 0.38%\n",
            "iter 1750: loss 1.4658, time 341.63ms, mfu 0.38%\n",
            "iter 1760: loss 1.4870, time 333.90ms, mfu 0.38%\n",
            "iter 1770: loss 1.4690, time 329.77ms, mfu 0.38%\n",
            "iter 1780: loss 1.6583, time 335.15ms, mfu 0.38%\n",
            "iter 1790: loss 1.3379, time 354.73ms, mfu 0.38%\n",
            "step 1800: train loss 1.4282, val loss 1.6303\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1800: loss 1.3882, time 1655.16ms, mfu 0.35%\n",
            "iter 1810: loss 1.6662, time 330.49ms, mfu 0.35%\n",
            "iter 1820: loss 1.5548, time 349.00ms, mfu 0.36%\n",
            "iter 1830: loss 1.5712, time 331.99ms, mfu 0.36%\n",
            "iter 1840: loss 1.5064, time 361.46ms, mfu 0.36%\n",
            "iter 1850: loss 1.6472, time 323.81ms, mfu 0.36%\n",
            "iter 1860: loss 1.4866, time 340.92ms, mfu 0.37%\n",
            "iter 1870: loss 1.4684, time 329.86ms, mfu 0.37%\n",
            "iter 1880: loss 1.5818, time 327.50ms, mfu 0.37%\n",
            "iter 1890: loss 1.4131, time 333.27ms, mfu 0.37%\n",
            "iter 1900: loss 1.5122, time 326.27ms, mfu 0.38%\n",
            "iter 1910: loss 1.4339, time 325.75ms, mfu 0.38%\n",
            "iter 1920: loss 1.5322, time 328.45ms, mfu 0.38%\n",
            "iter 1930: loss 1.4972, time 332.69ms, mfu 0.38%\n",
            "iter 1940: loss 1.5220, time 331.67ms, mfu 0.38%\n",
            "iter 1950: loss 1.5769, time 328.95ms, mfu 0.38%\n",
            "iter 1960: loss 1.4347, time 324.04ms, mfu 0.38%\n",
            "iter 1970: loss 1.4377, time 336.83ms, mfu 0.38%\n",
            "iter 1980: loss 1.5148, time 325.53ms, mfu 0.39%\n",
            "iter 1990: loss 1.4385, time 328.81ms, mfu 0.39%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 28/32: b64_L4_H8_E256_BS8_MI2000_D20_s28 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS8_MI2000_D20_s28.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 28\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 20,480\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2848, val loss 4.2795\n",
            "iter 0: loss 4.2829, time 1909.57ms, mfu -100.00%\n",
            "iter 10: loss 4.2476, time 324.89ms, mfu 0.40%\n",
            "iter 20: loss 4.1187, time 325.28ms, mfu 0.40%\n",
            "iter 30: loss 3.9243, time 326.48ms, mfu 0.40%\n",
            "iter 40: loss 3.7347, time 326.89ms, mfu 0.40%\n",
            "iter 50: loss 3.6495, time 323.16ms, mfu 0.40%\n",
            "iter 60: loss 3.5403, time 331.53ms, mfu 0.40%\n",
            "iter 70: loss 3.4489, time 326.60ms, mfu 0.40%\n",
            "iter 80: loss 3.5004, time 327.33ms, mfu 0.40%\n",
            "iter 90: loss 3.2912, time 327.90ms, mfu 0.40%\n",
            "iter 100: loss 3.1675, time 329.79ms, mfu 0.40%\n",
            "iter 110: loss 3.0813, time 331.18ms, mfu 0.40%\n",
            "iter 120: loss 3.1122, time 327.97ms, mfu 0.40%\n",
            "iter 130: loss 3.0190, time 325.11ms, mfu 0.40%\n",
            "iter 140: loss 2.9128, time 334.44ms, mfu 0.40%\n",
            "iter 150: loss 2.8811, time 327.38ms, mfu 0.40%\n",
            "iter 160: loss 2.8443, time 328.96ms, mfu 0.40%\n",
            "iter 170: loss 2.8306, time 323.36ms, mfu 0.40%\n",
            "iter 180: loss 2.9286, time 321.97ms, mfu 0.40%\n",
            "iter 190: loss 2.7934, time 328.57ms, mfu 0.40%\n",
            "step 200: train loss 2.6964, val loss 2.7065\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 200: loss 2.8279, time 1643.55ms, mfu 0.37%\n",
            "iter 210: loss 2.7141, time 329.65ms, mfu 0.37%\n",
            "iter 220: loss 2.6022, time 330.26ms, mfu 0.37%\n",
            "iter 230: loss 2.7079, time 325.40ms, mfu 0.37%\n",
            "iter 240: loss 2.7162, time 324.58ms, mfu 0.38%\n",
            "iter 250: loss 2.6474, time 325.96ms, mfu 0.38%\n",
            "iter 260: loss 2.7007, time 325.28ms, mfu 0.38%\n",
            "iter 270: loss 2.4991, time 331.99ms, mfu 0.38%\n",
            "iter 280: loss 2.6419, time 325.87ms, mfu 0.38%\n",
            "iter 290: loss 2.6664, time 332.41ms, mfu 0.38%\n",
            "iter 300: loss 2.5733, time 328.63ms, mfu 0.38%\n",
            "iter 310: loss 2.5365, time 328.73ms, mfu 0.39%\n",
            "iter 320: loss 2.6041, time 330.74ms, mfu 0.39%\n",
            "iter 330: loss 2.4941, time 319.89ms, mfu 0.39%\n",
            "iter 340: loss 2.5478, time 322.92ms, mfu 0.39%\n",
            "iter 350: loss 2.4853, time 329.22ms, mfu 0.39%\n",
            "iter 360: loss 2.3999, time 325.82ms, mfu 0.39%\n",
            "iter 370: loss 2.4624, time 326.17ms, mfu 0.39%\n",
            "iter 380: loss 2.4005, time 330.53ms, mfu 0.39%\n",
            "iter 390: loss 2.5178, time 330.93ms, mfu 0.39%\n",
            "step 400: train loss 2.4137, val loss 2.4303\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 400: loss 2.4710, time 1645.45ms, mfu 0.36%\n",
            "iter 410: loss 2.3711, time 347.12ms, mfu 0.36%\n",
            "iter 420: loss 2.5046, time 331.08ms, mfu 0.36%\n",
            "iter 430: loss 2.3739, time 331.48ms, mfu 0.37%\n",
            "iter 440: loss 2.4635, time 327.47ms, mfu 0.37%\n",
            "iter 450: loss 2.5352, time 329.60ms, mfu 0.37%\n",
            "iter 460: loss 2.3861, time 332.37ms, mfu 0.37%\n",
            "iter 470: loss 2.4271, time 334.73ms, mfu 0.38%\n",
            "iter 480: loss 2.4385, time 328.91ms, mfu 0.38%\n",
            "iter 490: loss 2.3610, time 331.44ms, mfu 0.38%\n",
            "iter 500: loss 2.4087, time 331.17ms, mfu 0.38%\n",
            "iter 510: loss 2.3724, time 328.73ms, mfu 0.38%\n",
            "iter 520: loss 2.3928, time 332.85ms, mfu 0.38%\n",
            "iter 530: loss 2.3998, time 344.48ms, mfu 0.38%\n",
            "iter 540: loss 2.3601, time 321.51ms, mfu 0.38%\n",
            "iter 550: loss 2.2585, time 322.93ms, mfu 0.39%\n",
            "iter 560: loss 2.3743, time 333.69ms, mfu 0.39%\n",
            "iter 570: loss 2.2174, time 331.38ms, mfu 0.39%\n",
            "iter 580: loss 2.3240, time 323.24ms, mfu 0.39%\n",
            "iter 590: loss 2.3282, time 328.05ms, mfu 0.39%\n",
            "step 600: train loss 2.2305, val loss 2.2396\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 600: loss 2.2919, time 1682.63ms, mfu 0.36%\n",
            "iter 610: loss 2.3207, time 329.46ms, mfu 0.36%\n",
            "iter 620: loss 2.3239, time 321.67ms, mfu 0.37%\n",
            "iter 630: loss 2.3551, time 328.94ms, mfu 0.37%\n",
            "iter 640: loss 2.2593, time 331.69ms, mfu 0.37%\n",
            "iter 650: loss 2.2795, time 324.56ms, mfu 0.37%\n",
            "iter 660: loss 2.2792, time 331.05ms, mfu 0.38%\n",
            "iter 670: loss 2.2866, time 325.83ms, mfu 0.38%\n",
            "iter 680: loss 2.1835, time 325.69ms, mfu 0.38%\n",
            "iter 690: loss 2.1702, time 323.79ms, mfu 0.38%\n",
            "iter 700: loss 2.1789, time 325.33ms, mfu 0.38%\n",
            "iter 710: loss 2.1086, time 345.51ms, mfu 0.38%\n",
            "iter 720: loss 2.1811, time 336.14ms, mfu 0.38%\n",
            "iter 730: loss 2.2000, time 334.78ms, mfu 0.38%\n",
            "iter 740: loss 2.1473, time 334.62ms, mfu 0.38%\n",
            "iter 750: loss 2.1277, time 336.44ms, mfu 0.38%\n",
            "iter 760: loss 2.1451, time 333.74ms, mfu 0.38%\n",
            "iter 770: loss 2.0656, time 332.56ms, mfu 0.39%\n",
            "iter 780: loss 2.1117, time 331.20ms, mfu 0.39%\n",
            "iter 790: loss 2.2514, time 330.89ms, mfu 0.39%\n",
            "step 800: train loss 2.0432, val loss 2.0863\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 800: loss 2.2425, time 1669.20ms, mfu 0.36%\n",
            "iter 810: loss 2.2188, time 331.18ms, mfu 0.36%\n",
            "iter 820: loss 2.0700, time 353.17ms, mfu 0.36%\n",
            "iter 830: loss 2.0617, time 343.84ms, mfu 0.36%\n",
            "iter 840: loss 2.1093, time 332.05ms, mfu 0.36%\n",
            "iter 850: loss 2.0765, time 331.84ms, mfu 0.37%\n",
            "iter 860: loss 2.0787, time 335.99ms, mfu 0.37%\n",
            "iter 870: loss 2.2045, time 329.20ms, mfu 0.37%\n",
            "iter 880: loss 2.0966, time 337.71ms, mfu 0.37%\n",
            "iter 890: loss 2.1065, time 341.16ms, mfu 0.37%\n",
            "iter 900: loss 2.0256, time 337.87ms, mfu 0.37%\n",
            "iter 910: loss 2.0882, time 340.62ms, mfu 0.38%\n",
            "iter 920: loss 1.9522, time 323.32ms, mfu 0.38%\n",
            "iter 930: loss 1.9178, time 336.58ms, mfu 0.38%\n",
            "iter 940: loss 2.2227, time 327.44ms, mfu 0.38%\n",
            "iter 950: loss 2.0270, time 331.26ms, mfu 0.38%\n",
            "iter 960: loss 2.1091, time 323.84ms, mfu 0.38%\n",
            "iter 970: loss 1.9678, time 328.54ms, mfu 0.38%\n",
            "iter 980: loss 2.0145, time 325.98ms, mfu 0.39%\n",
            "iter 990: loss 2.0934, time 326.64ms, mfu 0.39%\n",
            "step 1000: train loss 1.8798, val loss 1.9804\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1000: loss 1.8830, time 1668.44ms, mfu 0.36%\n",
            "iter 1010: loss 1.9330, time 334.48ms, mfu 0.36%\n",
            "iter 1020: loss 1.9607, time 324.38ms, mfu 0.36%\n",
            "iter 1030: loss 2.0865, time 329.63ms, mfu 0.37%\n",
            "iter 1040: loss 2.0322, time 336.43ms, mfu 0.37%\n",
            "iter 1050: loss 1.8621, time 326.81ms, mfu 0.37%\n",
            "iter 1060: loss 1.9191, time 338.44ms, mfu 0.37%\n",
            "iter 1070: loss 1.9419, time 337.26ms, mfu 0.37%\n",
            "iter 1080: loss 1.8999, time 327.79ms, mfu 0.38%\n",
            "iter 1090: loss 1.8945, time 327.23ms, mfu 0.38%\n",
            "iter 1100: loss 1.8578, time 330.53ms, mfu 0.38%\n",
            "iter 1110: loss 2.0142, time 335.51ms, mfu 0.38%\n",
            "iter 1120: loss 1.9121, time 326.56ms, mfu 0.38%\n",
            "iter 1130: loss 1.9429, time 334.65ms, mfu 0.38%\n",
            "iter 1140: loss 1.8562, time 331.30ms, mfu 0.38%\n",
            "iter 1150: loss 1.7735, time 327.59ms, mfu 0.38%\n",
            "iter 1160: loss 1.8207, time 338.87ms, mfu 0.38%\n",
            "iter 1170: loss 1.7914, time 327.55ms, mfu 0.39%\n",
            "iter 1180: loss 1.7877, time 335.36ms, mfu 0.39%\n",
            "iter 1190: loss 1.8660, time 329.91ms, mfu 0.39%\n",
            "step 1200: train loss 1.7299, val loss 1.8941\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1200: loss 1.8221, time 1631.83ms, mfu 0.36%\n",
            "iter 1210: loss 1.9365, time 329.19ms, mfu 0.36%\n",
            "iter 1220: loss 1.8079, time 327.48ms, mfu 0.36%\n",
            "iter 1230: loss 1.8954, time 326.74ms, mfu 0.37%\n",
            "iter 1240: loss 1.6684, time 325.53ms, mfu 0.37%\n",
            "iter 1250: loss 1.7869, time 330.55ms, mfu 0.37%\n",
            "iter 1260: loss 1.8449, time 326.57ms, mfu 0.37%\n",
            "iter 1270: loss 1.8607, time 327.02ms, mfu 0.38%\n",
            "iter 1280: loss 1.8379, time 327.70ms, mfu 0.38%\n",
            "iter 1290: loss 1.7258, time 341.91ms, mfu 0.38%\n",
            "iter 1300: loss 1.8332, time 325.13ms, mfu 0.38%\n",
            "iter 1310: loss 1.6912, time 324.17ms, mfu 0.38%\n",
            "iter 1320: loss 1.8643, time 330.92ms, mfu 0.38%\n",
            "iter 1330: loss 1.9443, time 327.61ms, mfu 0.39%\n",
            "iter 1340: loss 1.7760, time 331.73ms, mfu 0.39%\n",
            "iter 1350: loss 1.7016, time 322.27ms, mfu 0.39%\n",
            "iter 1360: loss 1.7598, time 327.01ms, mfu 0.39%\n",
            "iter 1370: loss 1.8202, time 330.84ms, mfu 0.39%\n",
            "iter 1380: loss 1.6237, time 328.13ms, mfu 0.39%\n",
            "iter 1390: loss 1.8134, time 332.96ms, mfu 0.39%\n",
            "step 1400: train loss 1.6550, val loss 1.8086\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1400: loss 1.6365, time 1645.15ms, mfu 0.36%\n",
            "iter 1410: loss 1.7532, time 330.23ms, mfu 0.36%\n",
            "iter 1420: loss 1.9191, time 323.24ms, mfu 0.37%\n",
            "iter 1430: loss 1.7338, time 335.38ms, mfu 0.37%\n",
            "iter 1440: loss 1.7438, time 330.13ms, mfu 0.37%\n",
            "iter 1450: loss 1.6940, time 331.01ms, mfu 0.37%\n",
            "iter 1460: loss 1.5883, time 332.50ms, mfu 0.37%\n",
            "iter 1470: loss 1.6960, time 344.95ms, mfu 0.37%\n",
            "iter 1480: loss 1.8215, time 329.49ms, mfu 0.38%\n",
            "iter 1490: loss 1.5922, time 330.27ms, mfu 0.38%\n",
            "iter 1500: loss 1.5663, time 321.00ms, mfu 0.38%\n",
            "iter 1510: loss 1.7236, time 329.08ms, mfu 0.38%\n",
            "iter 1520: loss 1.6876, time 325.73ms, mfu 0.38%\n",
            "iter 1530: loss 1.6966, time 329.26ms, mfu 0.38%\n",
            "iter 1540: loss 1.8320, time 340.00ms, mfu 0.38%\n",
            "iter 1550: loss 1.6153, time 329.54ms, mfu 0.39%\n",
            "iter 1560: loss 1.6441, time 329.67ms, mfu 0.39%\n",
            "iter 1570: loss 1.6310, time 328.80ms, mfu 0.39%\n",
            "iter 1580: loss 1.7347, time 337.21ms, mfu 0.39%\n",
            "iter 1590: loss 1.7912, time 329.19ms, mfu 0.39%\n",
            "step 1600: train loss 1.5871, val loss 1.7602\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1600: loss 1.7450, time 1644.84ms, mfu 0.36%\n",
            "iter 1610: loss 1.7829, time 337.12ms, mfu 0.36%\n",
            "iter 1620: loss 1.7235, time 327.97ms, mfu 0.36%\n",
            "iter 1630: loss 1.6293, time 334.97ms, mfu 0.37%\n",
            "iter 1640: loss 1.6060, time 333.95ms, mfu 0.37%\n",
            "iter 1650: loss 1.7534, time 329.28ms, mfu 0.37%\n",
            "iter 1660: loss 1.5612, time 326.79ms, mfu 0.37%\n",
            "iter 1670: loss 1.4834, time 330.11ms, mfu 0.38%\n",
            "iter 1680: loss 1.5977, time 336.12ms, mfu 0.38%\n",
            "iter 1690: loss 1.5327, time 337.18ms, mfu 0.38%\n",
            "iter 1700: loss 1.6695, time 332.69ms, mfu 0.38%\n",
            "iter 1710: loss 1.5940, time 327.64ms, mfu 0.38%\n",
            "iter 1720: loss 1.5354, time 333.73ms, mfu 0.38%\n",
            "iter 1730: loss 1.5269, time 332.59ms, mfu 0.38%\n",
            "iter 1740: loss 1.7260, time 328.80ms, mfu 0.38%\n",
            "iter 1750: loss 1.6258, time 323.74ms, mfu 0.39%\n",
            "iter 1760: loss 1.5740, time 335.92ms, mfu 0.39%\n",
            "iter 1770: loss 1.6248, time 328.88ms, mfu 0.39%\n",
            "iter 1780: loss 1.7263, time 328.40ms, mfu 0.39%\n",
            "iter 1790: loss 1.4633, time 327.13ms, mfu 0.39%\n",
            "step 1800: train loss 1.5180, val loss 1.7155\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1800: loss 1.5352, time 1673.33ms, mfu 0.36%\n",
            "iter 1810: loss 1.7811, time 325.94ms, mfu 0.36%\n",
            "iter 1820: loss 1.6753, time 329.11ms, mfu 0.36%\n",
            "iter 1830: loss 1.6535, time 333.12ms, mfu 0.37%\n",
            "iter 1840: loss 1.6322, time 329.62ms, mfu 0.37%\n",
            "iter 1850: loss 1.7078, time 332.41ms, mfu 0.37%\n",
            "iter 1860: loss 1.5629, time 336.89ms, mfu 0.37%\n",
            "iter 1870: loss 1.5751, time 332.83ms, mfu 0.37%\n",
            "iter 1880: loss 1.6845, time 328.15ms, mfu 0.38%\n",
            "iter 1890: loss 1.5261, time 335.46ms, mfu 0.38%\n",
            "iter 1900: loss 1.6066, time 338.51ms, mfu 0.38%\n",
            "iter 1910: loss 1.5108, time 339.32ms, mfu 0.38%\n",
            "iter 1920: loss 1.6458, time 327.64ms, mfu 0.38%\n",
            "iter 1930: loss 1.6310, time 327.09ms, mfu 0.38%\n",
            "iter 1940: loss 1.6734, time 327.72ms, mfu 0.38%\n",
            "iter 1950: loss 1.6870, time 329.39ms, mfu 0.38%\n",
            "iter 1960: loss 1.5532, time 326.04ms, mfu 0.39%\n",
            "iter 1970: loss 1.5241, time 343.88ms, mfu 0.39%\n",
            "iter 1980: loss 1.5962, time 326.02ms, mfu 0.39%\n",
            "iter 1990: loss 1.4829, time 326.89ms, mfu 0.39%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 29/32: b64_L4_H8_E256_BS16_MI1000_D10_s29 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS16_MI1000_D10_s29.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D10_s29\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 29\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2845, val loss 4.2795\n",
            "iter 0: loss 4.2834, time 2060.16ms, mfu -100.00%\n",
            "iter 10: loss 4.2314, time 350.01ms, mfu 0.74%\n",
            "iter 20: loss 4.0859, time 346.45ms, mfu 0.74%\n",
            "iter 30: loss 3.9043, time 359.64ms, mfu 0.74%\n",
            "iter 40: loss 3.6865, time 350.63ms, mfu 0.74%\n",
            "iter 50: loss 3.5738, time 344.87ms, mfu 0.74%\n",
            "iter 60: loss 3.4752, time 358.30ms, mfu 0.74%\n",
            "iter 70: loss 3.3322, time 347.88ms, mfu 0.74%\n",
            "iter 80: loss 3.3368, time 348.37ms, mfu 0.74%\n",
            "iter 90: loss 3.2461, time 344.16ms, mfu 0.74%\n",
            "iter 100: loss 3.0821, time 371.22ms, mfu 0.74%\n",
            "iter 110: loss 2.9844, time 345.64ms, mfu 0.74%\n",
            "iter 120: loss 2.9331, time 344.95ms, mfu 0.74%\n",
            "iter 130: loss 2.9203, time 353.34ms, mfu 0.74%\n",
            "iter 140: loss 2.8739, time 354.02ms, mfu 0.74%\n",
            "iter 150: loss 2.7756, time 339.78ms, mfu 0.74%\n",
            "iter 160: loss 2.7848, time 352.34ms, mfu 0.74%\n",
            "iter 170: loss 2.7945, time 376.34ms, mfu 0.74%\n",
            "iter 180: loss 2.7542, time 344.18ms, mfu 0.74%\n",
            "iter 190: loss 2.7697, time 345.11ms, mfu 0.74%\n",
            "step 200: train loss 2.6653, val loss 2.6782\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 200: loss 2.7041, time 1869.99ms, mfu 0.68%\n",
            "iter 210: loss 2.7372, time 342.98ms, mfu 0.69%\n",
            "iter 220: loss 2.6678, time 350.15ms, mfu 0.69%\n",
            "iter 230: loss 2.6665, time 356.63ms, mfu 0.70%\n",
            "iter 240: loss 2.6701, time 342.90ms, mfu 0.70%\n",
            "iter 250: loss 2.5731, time 348.57ms, mfu 0.71%\n",
            "iter 260: loss 2.6245, time 344.62ms, mfu 0.71%\n",
            "iter 270: loss 2.5128, time 353.85ms, mfu 0.71%\n",
            "iter 280: loss 2.5431, time 340.69ms, mfu 0.72%\n",
            "iter 290: loss 2.5226, time 340.88ms, mfu 0.72%\n",
            "iter 300: loss 2.5947, time 353.38ms, mfu 0.72%\n",
            "iter 310: loss 2.5011, time 345.79ms, mfu 0.73%\n",
            "iter 320: loss 2.4693, time 349.11ms, mfu 0.73%\n",
            "iter 330: loss 2.4171, time 357.79ms, mfu 0.73%\n",
            "iter 340: loss 2.3858, time 353.82ms, mfu 0.73%\n",
            "iter 350: loss 2.4533, time 354.13ms, mfu 0.73%\n",
            "iter 360: loss 2.4459, time 353.01ms, mfu 0.73%\n",
            "iter 370: loss 2.3527, time 352.42ms, mfu 0.73%\n",
            "iter 380: loss 2.4303, time 348.92ms, mfu 0.73%\n",
            "iter 390: loss 2.3579, time 357.21ms, mfu 0.73%\n",
            "step 400: train loss 2.3375, val loss 2.3481\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 400: loss 2.3445, time 1811.56ms, mfu 0.67%\n",
            "iter 410: loss 2.4163, time 349.34ms, mfu 0.68%\n",
            "iter 420: loss 2.3920, time 349.39ms, mfu 0.69%\n",
            "iter 430: loss 2.3421, time 348.34ms, mfu 0.69%\n",
            "iter 440: loss 2.2446, time 351.84ms, mfu 0.70%\n",
            "iter 450: loss 2.3787, time 342.61ms, mfu 0.70%\n",
            "iter 460: loss 2.3381, time 342.61ms, mfu 0.71%\n",
            "iter 470: loss 2.3083, time 346.52ms, mfu 0.71%\n",
            "iter 480: loss 2.1966, time 345.63ms, mfu 0.72%\n",
            "iter 490: loss 2.1978, time 349.40ms, mfu 0.72%\n",
            "iter 500: loss 2.2917, time 349.09ms, mfu 0.72%\n",
            "iter 510: loss 2.2567, time 361.36ms, mfu 0.72%\n",
            "iter 520: loss 2.0851, time 341.32ms, mfu 0.72%\n",
            "iter 530: loss 2.1393, time 351.83ms, mfu 0.73%\n",
            "iter 540: loss 2.1832, time 358.99ms, mfu 0.73%\n",
            "iter 550: loss 2.2135, time 345.61ms, mfu 0.73%\n",
            "iter 560: loss 2.2668, time 347.53ms, mfu 0.73%\n",
            "iter 570: loss 2.1363, time 346.08ms, mfu 0.73%\n",
            "iter 580: loss 2.0409, time 351.64ms, mfu 0.73%\n",
            "iter 590: loss 2.1296, time 348.14ms, mfu 0.73%\n",
            "step 600: train loss 2.0625, val loss 2.1077\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 600: loss 2.1933, time 1802.63ms, mfu 0.68%\n",
            "iter 610: loss 2.1014, time 366.35ms, mfu 0.68%\n",
            "iter 620: loss 2.1366, time 346.89ms, mfu 0.69%\n",
            "iter 630: loss 2.0717, time 353.96ms, mfu 0.69%\n",
            "iter 640: loss 2.1634, time 354.00ms, mfu 0.69%\n",
            "iter 650: loss 2.0916, time 351.43ms, mfu 0.70%\n",
            "iter 660: loss 2.0416, time 350.19ms, mfu 0.70%\n",
            "iter 670: loss 2.1102, time 347.82ms, mfu 0.71%\n",
            "iter 680: loss 1.9839, time 352.44ms, mfu 0.71%\n",
            "iter 690: loss 2.0148, time 348.69ms, mfu 0.71%\n",
            "iter 700: loss 1.9786, time 344.51ms, mfu 0.72%\n",
            "iter 710: loss 2.1094, time 345.68ms, mfu 0.72%\n",
            "iter 720: loss 1.9580, time 341.10ms, mfu 0.73%\n",
            "iter 730: loss 1.9340, time 361.22ms, mfu 0.72%\n",
            "iter 740: loss 2.0800, time 345.52ms, mfu 0.73%\n",
            "iter 750: loss 2.0122, time 355.99ms, mfu 0.73%\n",
            "iter 760: loss 1.9105, time 343.80ms, mfu 0.73%\n",
            "iter 770: loss 1.9862, time 344.46ms, mfu 0.73%\n",
            "iter 780: loss 1.9541, time 346.49ms, mfu 0.73%\n",
            "iter 790: loss 1.8898, time 339.66ms, mfu 0.74%\n",
            "step 800: train loss 1.8444, val loss 1.9458\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 800: loss 1.9027, time 1816.66ms, mfu 0.68%\n",
            "iter 810: loss 1.9755, time 354.85ms, mfu 0.68%\n",
            "iter 820: loss 1.9675, time 333.87ms, mfu 0.69%\n",
            "iter 830: loss 1.9740, time 341.37ms, mfu 0.70%\n",
            "iter 840: loss 1.9334, time 349.78ms, mfu 0.70%\n",
            "iter 850: loss 1.8081, time 355.72ms, mfu 0.71%\n",
            "iter 860: loss 1.8591, time 345.02ms, mfu 0.71%\n",
            "iter 870: loss 1.9262, time 354.94ms, mfu 0.71%\n",
            "iter 880: loss 1.7477, time 364.35ms, mfu 0.71%\n",
            "iter 890: loss 1.8569, time 349.53ms, mfu 0.72%\n",
            "iter 900: loss 1.8284, time 343.62ms, mfu 0.72%\n",
            "iter 910: loss 1.8147, time 351.12ms, mfu 0.72%\n",
            "iter 920: loss 1.8171, time 354.36ms, mfu 0.72%\n",
            "iter 930: loss 1.9153, time 343.82ms, mfu 0.73%\n",
            "iter 940: loss 1.8477, time 343.74ms, mfu 0.73%\n",
            "iter 950: loss 1.8226, time 349.58ms, mfu 0.73%\n",
            "iter 960: loss 1.7164, time 344.72ms, mfu 0.73%\n",
            "iter 970: loss 1.8025, time 353.12ms, mfu 0.73%\n",
            "iter 980: loss 1.7914, time 347.39ms, mfu 0.73%\n",
            "iter 990: loss 1.8725, time 355.84ms, mfu 0.73%\n",
            "step 1000: train loss 1.6645, val loss 1.8232\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 1000: loss 1.7846, time 1796.40ms, mfu 0.67%\n",
            "\n",
            "=== Experiment 30/32: b64_L4_H8_E256_BS16_MI1000_D20_s30 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS16_MI1000_D20_s30.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D20_s30\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 30\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2845, val loss 4.2795\n",
            "iter 0: loss 4.2715, time 2088.29ms, mfu -100.00%\n",
            "iter 10: loss 4.2257, time 347.02ms, mfu 0.75%\n",
            "iter 20: loss 4.1068, time 349.48ms, mfu 0.75%\n",
            "iter 30: loss 3.9354, time 347.19ms, mfu 0.75%\n",
            "iter 40: loss 3.7395, time 345.73ms, mfu 0.75%\n",
            "iter 50: loss 3.6156, time 350.58ms, mfu 0.75%\n",
            "iter 60: loss 3.5143, time 340.37ms, mfu 0.75%\n",
            "iter 70: loss 3.3788, time 359.11ms, mfu 0.75%\n",
            "iter 80: loss 3.3988, time 339.23ms, mfu 0.75%\n",
            "iter 90: loss 3.3331, time 339.03ms, mfu 0.75%\n",
            "iter 100: loss 3.1542, time 342.37ms, mfu 0.75%\n",
            "iter 110: loss 3.0609, time 343.97ms, mfu 0.75%\n",
            "iter 120: loss 3.0154, time 338.12ms, mfu 0.75%\n",
            "iter 130: loss 2.9864, time 339.38ms, mfu 0.75%\n",
            "iter 140: loss 2.9340, time 348.41ms, mfu 0.75%\n",
            "iter 150: loss 2.8399, time 342.77ms, mfu 0.75%\n",
            "iter 160: loss 2.8458, time 343.61ms, mfu 0.75%\n",
            "iter 170: loss 2.8432, time 347.23ms, mfu 0.75%\n",
            "iter 180: loss 2.8044, time 358.06ms, mfu 0.75%\n",
            "iter 190: loss 2.8205, time 344.08ms, mfu 0.75%\n",
            "step 200: train loss 2.6865, val loss 2.6955\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 200: loss 2.7589, time 1804.52ms, mfu 0.69%\n",
            "iter 210: loss 2.7778, time 370.29ms, mfu 0.69%\n",
            "iter 220: loss 2.7130, time 339.62ms, mfu 0.70%\n",
            "iter 230: loss 2.7006, time 354.60ms, mfu 0.70%\n",
            "iter 240: loss 2.7093, time 356.85ms, mfu 0.70%\n",
            "iter 250: loss 2.6237, time 340.11ms, mfu 0.71%\n",
            "iter 260: loss 2.6650, time 338.75ms, mfu 0.72%\n",
            "iter 270: loss 2.5516, time 333.16ms, mfu 0.72%\n",
            "iter 280: loss 2.5899, time 355.46ms, mfu 0.72%\n",
            "iter 290: loss 2.5578, time 346.76ms, mfu 0.73%\n",
            "iter 300: loss 2.6300, time 337.60ms, mfu 0.73%\n",
            "iter 310: loss 2.5496, time 343.98ms, mfu 0.73%\n",
            "iter 320: loss 2.5322, time 338.10ms, mfu 0.74%\n",
            "iter 330: loss 2.4628, time 341.26ms, mfu 0.74%\n",
            "iter 340: loss 2.4410, time 343.76ms, mfu 0.74%\n",
            "iter 350: loss 2.5024, time 345.32ms, mfu 0.74%\n",
            "iter 360: loss 2.4959, time 345.57ms, mfu 0.74%\n",
            "iter 370: loss 2.4197, time 345.68ms, mfu 0.74%\n",
            "iter 380: loss 2.4781, time 347.42ms, mfu 0.74%\n",
            "iter 390: loss 2.4106, time 342.69ms, mfu 0.74%\n",
            "step 400: train loss 2.3870, val loss 2.3957\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 400: loss 2.4019, time 1800.10ms, mfu 0.68%\n",
            "iter 410: loss 2.4562, time 346.92ms, mfu 0.69%\n",
            "iter 420: loss 2.4440, time 347.56ms, mfu 0.70%\n",
            "iter 430: loss 2.3961, time 342.12ms, mfu 0.70%\n",
            "iter 440: loss 2.3084, time 350.09ms, mfu 0.71%\n",
            "iter 450: loss 2.4291, time 345.82ms, mfu 0.71%\n",
            "iter 460: loss 2.3799, time 335.21ms, mfu 0.72%\n",
            "iter 470: loss 2.3733, time 348.09ms, mfu 0.72%\n",
            "iter 480: loss 2.2559, time 346.55ms, mfu 0.72%\n",
            "iter 490: loss 2.2806, time 343.98ms, mfu 0.73%\n",
            "iter 500: loss 2.3715, time 345.22ms, mfu 0.73%\n",
            "iter 510: loss 2.3425, time 342.70ms, mfu 0.73%\n",
            "iter 520: loss 2.1668, time 357.76ms, mfu 0.73%\n",
            "iter 530: loss 2.2320, time 342.24ms, mfu 0.73%\n",
            "iter 540: loss 2.2896, time 337.12ms, mfu 0.74%\n",
            "iter 550: loss 2.3063, time 336.56ms, mfu 0.74%\n",
            "iter 560: loss 2.3321, time 341.24ms, mfu 0.74%\n",
            "iter 570: loss 2.2438, time 349.51ms, mfu 0.74%\n",
            "iter 580: loss 2.1371, time 348.85ms, mfu 0.74%\n",
            "iter 590: loss 2.2157, time 359.40ms, mfu 0.74%\n",
            "step 600: train loss 2.1477, val loss 2.1777\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 600: loss 2.2804, time 1811.42ms, mfu 0.68%\n",
            "iter 610: loss 2.2079, time 354.29ms, mfu 0.69%\n",
            "iter 620: loss 2.2219, time 353.41ms, mfu 0.69%\n",
            "iter 630: loss 2.1772, time 342.29ms, mfu 0.70%\n",
            "iter 640: loss 2.2526, time 345.89ms, mfu 0.70%\n",
            "iter 650: loss 2.1792, time 349.74ms, mfu 0.71%\n",
            "iter 660: loss 2.1490, time 388.69ms, mfu 0.70%\n",
            "iter 670: loss 2.2118, time 343.64ms, mfu 0.71%\n",
            "iter 680: loss 2.0865, time 351.57ms, mfu 0.71%\n",
            "iter 690: loss 2.1071, time 364.51ms, mfu 0.71%\n",
            "iter 700: loss 2.0758, time 361.00ms, mfu 0.71%\n",
            "iter 710: loss 2.2216, time 329.33ms, mfu 0.72%\n",
            "iter 720: loss 2.0716, time 331.01ms, mfu 0.73%\n",
            "iter 730: loss 2.0772, time 333.11ms, mfu 0.73%\n",
            "iter 740: loss 2.1933, time 329.14ms, mfu 0.74%\n",
            "iter 750: loss 2.1260, time 331.61ms, mfu 0.74%\n",
            "iter 760: loss 2.0342, time 325.50ms, mfu 0.75%\n",
            "iter 770: loss 2.0872, time 329.57ms, mfu 0.75%\n",
            "iter 780: loss 2.0635, time 337.60ms, mfu 0.75%\n",
            "iter 790: loss 2.0068, time 326.74ms, mfu 0.76%\n",
            "step 800: train loss 1.9516, val loss 2.0222\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 800: loss 2.0218, time 1804.00ms, mfu 0.70%\n",
            "iter 810: loss 2.0838, time 343.48ms, mfu 0.70%\n",
            "iter 820: loss 2.0927, time 334.32ms, mfu 0.71%\n",
            "iter 830: loss 2.1100, time 348.39ms, mfu 0.71%\n",
            "iter 840: loss 2.0575, time 353.83ms, mfu 0.72%\n",
            "iter 850: loss 1.9293, time 352.25ms, mfu 0.72%\n",
            "iter 860: loss 1.9997, time 351.56ms, mfu 0.72%\n",
            "iter 870: loss 2.0394, time 344.68ms, mfu 0.72%\n",
            "iter 880: loss 1.8851, time 348.60ms, mfu 0.72%\n",
            "iter 890: loss 1.9601, time 343.21ms, mfu 0.73%\n",
            "iter 900: loss 1.9729, time 358.28ms, mfu 0.73%\n",
            "iter 910: loss 1.9623, time 346.90ms, mfu 0.73%\n",
            "iter 920: loss 1.9059, time 347.35ms, mfu 0.73%\n",
            "iter 930: loss 1.9988, time 343.98ms, mfu 0.73%\n",
            "iter 940: loss 1.9421, time 349.42ms, mfu 0.73%\n",
            "iter 950: loss 1.9447, time 347.51ms, mfu 0.74%\n",
            "iter 960: loss 1.8780, time 346.71ms, mfu 0.74%\n",
            "iter 970: loss 1.9029, time 360.28ms, mfu 0.74%\n",
            "iter 980: loss 1.9320, time 346.30ms, mfu 0.74%\n",
            "iter 990: loss 1.9731, time 344.77ms, mfu 0.74%\n",
            "step 1000: train loss 1.7732, val loss 1.9081\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 1000: loss 1.9185, time 1821.11ms, mfu 0.68%\n",
            "\n",
            "=== Experiment 31/32: b64_L4_H8_E256_BS16_MI2000_D10_s31 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS16_MI2000_D10_s31.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 31\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2845, val loss 4.2795\n",
            "iter 0: loss 4.2834, time 2040.15ms, mfu -100.00%\n",
            "iter 10: loss 4.2314, time 337.22ms, mfu 0.77%\n",
            "iter 20: loss 4.0859, time 350.21ms, mfu 0.77%\n",
            "iter 30: loss 3.9043, time 345.29ms, mfu 0.77%\n",
            "iter 40: loss 3.6865, time 341.82ms, mfu 0.76%\n",
            "iter 50: loss 3.5738, time 343.79ms, mfu 0.76%\n",
            "iter 60: loss 3.4752, time 344.57ms, mfu 0.76%\n",
            "iter 70: loss 3.3322, time 346.86ms, mfu 0.76%\n",
            "iter 80: loss 3.3368, time 341.86ms, mfu 0.76%\n",
            "iter 90: loss 3.2461, time 342.60ms, mfu 0.76%\n",
            "iter 100: loss 3.0821, time 347.80ms, mfu 0.76%\n",
            "iter 110: loss 2.9844, time 349.62ms, mfu 0.76%\n",
            "iter 120: loss 2.9331, time 344.49ms, mfu 0.76%\n",
            "iter 130: loss 2.9203, time 342.64ms, mfu 0.76%\n",
            "iter 140: loss 2.8739, time 344.83ms, mfu 0.76%\n",
            "iter 150: loss 2.7756, time 345.70ms, mfu 0.76%\n",
            "iter 160: loss 2.7848, time 346.16ms, mfu 0.76%\n",
            "iter 170: loss 2.7945, time 342.69ms, mfu 0.76%\n",
            "iter 180: loss 2.7542, time 342.86ms, mfu 0.76%\n",
            "iter 190: loss 2.7697, time 345.83ms, mfu 0.76%\n",
            "step 200: train loss 2.6653, val loss 2.6782\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 200: loss 2.7041, time 1796.39ms, mfu 0.69%\n",
            "iter 210: loss 2.7372, time 345.71ms, mfu 0.70%\n",
            "iter 220: loss 2.6678, time 343.66ms, mfu 0.71%\n",
            "iter 230: loss 2.6665, time 358.94ms, mfu 0.71%\n",
            "iter 240: loss 2.6701, time 344.49ms, mfu 0.71%\n",
            "iter 250: loss 2.5731, time 333.85ms, mfu 0.72%\n",
            "iter 260: loss 2.6245, time 345.74ms, mfu 0.72%\n",
            "iter 270: loss 2.5128, time 336.37ms, mfu 0.73%\n",
            "iter 280: loss 2.5431, time 345.47ms, mfu 0.73%\n",
            "iter 290: loss 2.5226, time 340.64ms, mfu 0.73%\n",
            "iter 300: loss 2.5947, time 367.18ms, mfu 0.73%\n",
            "iter 310: loss 2.5011, time 339.36ms, mfu 0.73%\n",
            "iter 320: loss 2.4693, time 340.09ms, mfu 0.74%\n",
            "iter 330: loss 2.4171, time 348.15ms, mfu 0.74%\n",
            "iter 340: loss 2.3858, time 339.06ms, mfu 0.74%\n",
            "iter 350: loss 2.4533, time 340.56ms, mfu 0.74%\n",
            "iter 360: loss 2.4459, time 339.56ms, mfu 0.74%\n",
            "iter 370: loss 2.3527, time 349.00ms, mfu 0.74%\n",
            "iter 380: loss 2.4303, time 343.55ms, mfu 0.75%\n",
            "iter 390: loss 2.3579, time 341.19ms, mfu 0.75%\n",
            "step 400: train loss 2.3375, val loss 2.3481\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 400: loss 2.3445, time 1798.24ms, mfu 0.69%\n",
            "iter 410: loss 2.4163, time 350.98ms, mfu 0.69%\n",
            "iter 420: loss 2.3920, time 346.79ms, mfu 0.70%\n",
            "iter 430: loss 2.3421, time 339.96ms, mfu 0.70%\n",
            "iter 440: loss 2.2446, time 338.60ms, mfu 0.71%\n",
            "iter 450: loss 2.3787, time 344.38ms, mfu 0.71%\n",
            "iter 460: loss 2.3381, time 343.53ms, mfu 0.72%\n",
            "iter 470: loss 2.3083, time 342.24ms, mfu 0.72%\n",
            "iter 480: loss 2.1966, time 343.22ms, mfu 0.73%\n",
            "iter 490: loss 2.1978, time 337.74ms, mfu 0.73%\n",
            "iter 500: loss 2.2917, time 342.16ms, mfu 0.73%\n",
            "iter 510: loss 2.2567, time 344.85ms, mfu 0.74%\n",
            "iter 520: loss 2.0851, time 346.39ms, mfu 0.74%\n",
            "iter 530: loss 2.1393, time 340.14ms, mfu 0.74%\n",
            "iter 540: loss 2.1832, time 351.91ms, mfu 0.74%\n",
            "iter 550: loss 2.2135, time 342.38ms, mfu 0.74%\n",
            "iter 560: loss 2.2668, time 341.78ms, mfu 0.74%\n",
            "iter 570: loss 2.1363, time 340.82ms, mfu 0.74%\n",
            "iter 580: loss 2.0409, time 342.22ms, mfu 0.75%\n",
            "iter 590: loss 2.1296, time 340.29ms, mfu 0.75%\n",
            "step 600: train loss 2.0625, val loss 2.1077\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 600: loss 2.1933, time 1779.01ms, mfu 0.69%\n",
            "iter 610: loss 2.1014, time 363.11ms, mfu 0.69%\n",
            "iter 620: loss 2.1366, time 331.13ms, mfu 0.70%\n",
            "iter 630: loss 2.0717, time 343.98ms, mfu 0.71%\n",
            "iter 640: loss 2.1634, time 346.82ms, mfu 0.71%\n",
            "iter 650: loss 2.0916, time 343.82ms, mfu 0.71%\n",
            "iter 660: loss 2.0416, time 346.80ms, mfu 0.72%\n",
            "iter 670: loss 2.1102, time 341.86ms, mfu 0.72%\n",
            "iter 680: loss 1.9839, time 343.19ms, mfu 0.73%\n",
            "iter 690: loss 2.0148, time 346.14ms, mfu 0.73%\n",
            "iter 700: loss 1.9786, time 341.43ms, mfu 0.73%\n",
            "iter 710: loss 2.1094, time 346.29ms, mfu 0.73%\n",
            "iter 720: loss 1.9580, time 348.57ms, mfu 0.73%\n",
            "iter 730: loss 1.9340, time 338.34ms, mfu 0.74%\n",
            "iter 740: loss 2.0800, time 342.56ms, mfu 0.74%\n",
            "iter 750: loss 2.0122, time 357.06ms, mfu 0.74%\n",
            "iter 760: loss 1.9105, time 338.75ms, mfu 0.74%\n",
            "iter 770: loss 1.9862, time 347.60ms, mfu 0.74%\n",
            "iter 780: loss 1.9541, time 347.18ms, mfu 0.74%\n",
            "iter 790: loss 1.8898, time 341.63ms, mfu 0.74%\n",
            "step 800: train loss 1.8444, val loss 1.9458\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 800: loss 1.9027, time 1788.05ms, mfu 0.68%\n",
            "iter 810: loss 1.9755, time 342.73ms, mfu 0.69%\n",
            "iter 820: loss 1.9675, time 349.81ms, mfu 0.70%\n",
            "iter 830: loss 1.9740, time 345.83ms, mfu 0.70%\n",
            "iter 840: loss 1.9334, time 345.18ms, mfu 0.71%\n",
            "iter 850: loss 1.8081, time 338.56ms, mfu 0.71%\n",
            "iter 860: loss 1.8591, time 339.91ms, mfu 0.72%\n",
            "iter 870: loss 1.9262, time 341.08ms, mfu 0.72%\n",
            "iter 880: loss 1.7477, time 339.65ms, mfu 0.73%\n",
            "iter 890: loss 1.8569, time 350.83ms, mfu 0.73%\n",
            "iter 900: loss 1.8284, time 345.04ms, mfu 0.73%\n",
            "iter 910: loss 1.8147, time 343.65ms, mfu 0.73%\n",
            "iter 920: loss 1.8171, time 343.87ms, mfu 0.74%\n",
            "iter 930: loss 1.9153, time 345.51ms, mfu 0.74%\n",
            "iter 940: loss 1.8477, time 350.82ms, mfu 0.74%\n",
            "iter 950: loss 1.8226, time 348.18ms, mfu 0.74%\n",
            "iter 960: loss 1.7164, time 346.00ms, mfu 0.74%\n",
            "iter 970: loss 1.8025, time 337.76ms, mfu 0.74%\n",
            "iter 980: loss 1.7914, time 344.34ms, mfu 0.74%\n",
            "iter 990: loss 1.8725, time 346.73ms, mfu 0.74%\n",
            "step 1000: train loss 1.6645, val loss 1.8232\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1000: loss 1.7846, time 1826.04ms, mfu 0.68%\n",
            "iter 1010: loss 1.7101, time 344.47ms, mfu 0.69%\n",
            "iter 1020: loss 1.7095, time 339.19ms, mfu 0.70%\n",
            "iter 1030: loss 1.7468, time 345.33ms, mfu 0.70%\n",
            "iter 1040: loss 1.7475, time 347.41ms, mfu 0.71%\n",
            "iter 1050: loss 1.6466, time 341.87ms, mfu 0.71%\n",
            "iter 1060: loss 1.8638, time 341.93ms, mfu 0.72%\n",
            "iter 1070: loss 1.7320, time 343.68ms, mfu 0.72%\n",
            "iter 1080: loss 1.6498, time 344.28ms, mfu 0.72%\n",
            "iter 1090: loss 1.6645, time 345.31ms, mfu 0.73%\n",
            "iter 1100: loss 1.7529, time 344.80ms, mfu 0.73%\n",
            "iter 1110: loss 1.7718, time 341.09ms, mfu 0.73%\n",
            "iter 1120: loss 1.7741, time 337.90ms, mfu 0.74%\n",
            "iter 1130: loss 1.6384, time 367.13ms, mfu 0.73%\n",
            "iter 1140: loss 1.6607, time 337.66ms, mfu 0.74%\n",
            "iter 1150: loss 1.6821, time 340.44ms, mfu 0.74%\n",
            "iter 1160: loss 1.6118, time 352.38ms, mfu 0.74%\n",
            "iter 1170: loss 1.6176, time 340.99ms, mfu 0.74%\n",
            "iter 1180: loss 1.6825, time 340.08ms, mfu 0.74%\n",
            "iter 1190: loss 1.6108, time 339.11ms, mfu 0.75%\n",
            "step 1200: train loss 1.5464, val loss 1.7288\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1200: loss 1.5776, time 1821.84ms, mfu 0.69%\n",
            "iter 1210: loss 1.6813, time 338.78ms, mfu 0.69%\n",
            "iter 1220: loss 1.6487, time 341.94ms, mfu 0.70%\n",
            "iter 1230: loss 1.6480, time 350.46ms, mfu 0.70%\n",
            "iter 1240: loss 1.6313, time 336.01ms, mfu 0.71%\n",
            "iter 1250: loss 1.5301, time 333.65ms, mfu 0.72%\n",
            "iter 1260: loss 1.6610, time 340.24ms, mfu 0.72%\n",
            "iter 1270: loss 1.5679, time 338.19ms, mfu 0.73%\n",
            "iter 1280: loss 1.5308, time 341.45ms, mfu 0.73%\n",
            "iter 1290: loss 1.5784, time 338.51ms, mfu 0.73%\n",
            "iter 1300: loss 1.5608, time 349.77ms, mfu 0.73%\n",
            "iter 1310: loss 1.6508, time 343.75ms, mfu 0.74%\n",
            "iter 1320: loss 1.5269, time 334.23ms, mfu 0.74%\n",
            "iter 1330: loss 1.5102, time 342.38ms, mfu 0.74%\n",
            "iter 1340: loss 1.5083, time 338.97ms, mfu 0.74%\n",
            "iter 1350: loss 1.5886, time 342.66ms, mfu 0.75%\n",
            "iter 1360: loss 1.5890, time 343.25ms, mfu 0.75%\n",
            "iter 1370: loss 1.4775, time 346.12ms, mfu 0.75%\n",
            "iter 1380: loss 1.6173, time 341.34ms, mfu 0.75%\n",
            "iter 1390: loss 1.5651, time 338.72ms, mfu 0.75%\n",
            "step 1400: train loss 1.4687, val loss 1.6557\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1400: loss 1.5540, time 1786.91ms, mfu 0.69%\n",
            "iter 1410: loss 1.4745, time 345.98ms, mfu 0.70%\n",
            "iter 1420: loss 1.6074, time 343.84ms, mfu 0.70%\n",
            "iter 1430: loss 1.5269, time 340.00ms, mfu 0.71%\n",
            "iter 1440: loss 1.4949, time 361.99ms, mfu 0.71%\n",
            "iter 1450: loss 1.5296, time 340.25ms, mfu 0.71%\n",
            "iter 1460: loss 1.4940, time 344.16ms, mfu 0.72%\n",
            "iter 1470: loss 1.5695, time 348.11ms, mfu 0.72%\n",
            "iter 1480: loss 1.4920, time 348.72ms, mfu 0.72%\n",
            "iter 1490: loss 1.4900, time 339.74ms, mfu 0.73%\n",
            "iter 1500: loss 1.5481, time 337.20ms, mfu 0.73%\n",
            "iter 1510: loss 1.4934, time 352.02ms, mfu 0.73%\n",
            "iter 1520: loss 1.4871, time 344.76ms, mfu 0.73%\n",
            "iter 1530: loss 1.4407, time 340.48ms, mfu 0.74%\n",
            "iter 1540: loss 1.5513, time 341.08ms, mfu 0.74%\n",
            "iter 1550: loss 1.4926, time 343.64ms, mfu 0.74%\n",
            "iter 1560: loss 1.4795, time 342.83ms, mfu 0.74%\n",
            "iter 1570: loss 1.4676, time 338.40ms, mfu 0.75%\n",
            "iter 1580: loss 1.4878, time 347.50ms, mfu 0.75%\n",
            "iter 1590: loss 1.4618, time 343.03ms, mfu 0.75%\n",
            "step 1600: train loss 1.4041, val loss 1.6153\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1600: loss 1.5517, time 1822.03ms, mfu 0.69%\n",
            "iter 1610: loss 1.4567, time 341.67ms, mfu 0.69%\n",
            "iter 1620: loss 1.5994, time 340.50ms, mfu 0.70%\n",
            "iter 1630: loss 1.4484, time 343.38ms, mfu 0.71%\n",
            "iter 1640: loss 1.4653, time 345.16ms, mfu 0.71%\n",
            "iter 1650: loss 1.5466, time 346.63ms, mfu 0.71%\n",
            "iter 1660: loss 1.4326, time 344.47ms, mfu 0.72%\n",
            "iter 1670: loss 1.4656, time 345.02ms, mfu 0.72%\n",
            "iter 1680: loss 1.5131, time 344.04ms, mfu 0.73%\n",
            "iter 1690: loss 1.4730, time 344.37ms, mfu 0.73%\n",
            "iter 1700: loss 1.5521, time 348.21ms, mfu 0.73%\n",
            "iter 1710: loss 1.4819, time 334.14ms, mfu 0.73%\n",
            "iter 1720: loss 1.4788, time 342.01ms, mfu 0.74%\n",
            "iter 1730: loss 1.5389, time 339.43ms, mfu 0.74%\n",
            "iter 1740: loss 1.3753, time 340.76ms, mfu 0.74%\n",
            "iter 1750: loss 1.4405, time 347.84ms, mfu 0.74%\n",
            "iter 1760: loss 1.4931, time 341.44ms, mfu 0.74%\n",
            "iter 1770: loss 1.3401, time 344.54ms, mfu 0.75%\n",
            "iter 1780: loss 1.4529, time 338.01ms, mfu 0.75%\n",
            "iter 1790: loss 1.5011, time 343.05ms, mfu 0.75%\n",
            "step 1800: train loss 1.3519, val loss 1.5643\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1800: loss 1.3411, time 1784.80ms, mfu 0.69%\n",
            "iter 1810: loss 1.5050, time 341.49ms, mfu 0.70%\n",
            "iter 1820: loss 1.3920, time 364.84ms, mfu 0.70%\n",
            "iter 1830: loss 1.4897, time 348.62ms, mfu 0.70%\n",
            "iter 1840: loss 1.4459, time 342.47ms, mfu 0.71%\n",
            "iter 1850: loss 1.3895, time 341.96ms, mfu 0.71%\n",
            "iter 1860: loss 1.3595, time 342.84ms, mfu 0.72%\n",
            "iter 1870: loss 1.4211, time 343.83ms, mfu 0.72%\n",
            "iter 1880: loss 1.4246, time 341.23ms, mfu 0.72%\n",
            "iter 1890: loss 1.4398, time 344.25ms, mfu 0.73%\n",
            "iter 1900: loss 1.3758, time 333.31ms, mfu 0.73%\n",
            "iter 1910: loss 1.4074, time 341.98ms, mfu 0.74%\n",
            "iter 1920: loss 1.4657, time 344.87ms, mfu 0.74%\n",
            "iter 1930: loss 1.4280, time 339.39ms, mfu 0.74%\n",
            "iter 1940: loss 1.4509, time 337.99ms, mfu 0.74%\n",
            "iter 1950: loss 1.4272, time 339.39ms, mfu 0.74%\n",
            "iter 1960: loss 1.4412, time 355.19ms, mfu 0.74%\n",
            "iter 1970: loss 1.3929, time 342.51ms, mfu 0.75%\n",
            "iter 1980: loss 1.4222, time 343.43ms, mfu 0.75%\n",
            "iter 1990: loss 1.3467, time 352.78ms, mfu 0.75%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 32/32: b64_L4_H8_E256_BS16_MI2000_D20_s32 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b64_L4_H8_E256_BS16_MI2000_D20_s32.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 64\n",
            "n_layer = 4\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 32\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 3.16M\n",
            "num decayed parameter tensors: 18, with 3,178,752 parameters\n",
            "num non-decayed parameter tensors: 9, with 2,304 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2845, val loss 4.2795\n",
            "iter 0: loss 4.2715, time 2073.92ms, mfu -100.00%\n",
            "iter 10: loss 4.2257, time 352.57ms, mfu 0.74%\n",
            "iter 20: loss 4.1068, time 339.91ms, mfu 0.74%\n",
            "iter 30: loss 3.9354, time 345.96ms, mfu 0.74%\n",
            "iter 40: loss 3.7395, time 347.08ms, mfu 0.74%\n",
            "iter 50: loss 3.6156, time 369.15ms, mfu 0.74%\n",
            "iter 60: loss 3.5143, time 340.02ms, mfu 0.74%\n",
            "iter 70: loss 3.3788, time 345.48ms, mfu 0.74%\n",
            "iter 80: loss 3.3988, time 341.87ms, mfu 0.74%\n",
            "iter 90: loss 3.3331, time 347.37ms, mfu 0.74%\n",
            "iter 100: loss 3.1542, time 343.43ms, mfu 0.74%\n",
            "iter 110: loss 3.0609, time 344.69ms, mfu 0.75%\n",
            "iter 120: loss 3.0154, time 368.27ms, mfu 0.74%\n",
            "iter 130: loss 2.9864, time 342.10ms, mfu 0.74%\n",
            "iter 140: loss 2.9340, time 343.38ms, mfu 0.74%\n",
            "iter 150: loss 2.8399, time 347.84ms, mfu 0.74%\n",
            "iter 160: loss 2.8458, time 341.39ms, mfu 0.75%\n",
            "iter 170: loss 2.8432, time 346.86ms, mfu 0.75%\n",
            "iter 180: loss 2.8044, time 341.87ms, mfu 0.75%\n",
            "iter 190: loss 2.8205, time 349.96ms, mfu 0.75%\n",
            "step 200: train loss 2.6865, val loss 2.6955\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 200: loss 2.7589, time 1797.15ms, mfu 0.69%\n",
            "iter 210: loss 2.7778, time 349.91ms, mfu 0.69%\n",
            "iter 220: loss 2.7130, time 359.86ms, mfu 0.70%\n",
            "iter 230: loss 2.7006, time 364.07ms, mfu 0.70%\n",
            "iter 240: loss 2.7093, time 355.10ms, mfu 0.70%\n",
            "iter 250: loss 2.6237, time 363.63ms, mfu 0.70%\n",
            "iter 260: loss 2.6650, time 345.13ms, mfu 0.71%\n",
            "iter 270: loss 2.5516, time 341.02ms, mfu 0.71%\n",
            "iter 280: loss 2.5899, time 348.04ms, mfu 0.72%\n",
            "iter 290: loss 2.5578, time 365.11ms, mfu 0.72%\n",
            "iter 300: loss 2.6300, time 342.83ms, mfu 0.72%\n",
            "iter 310: loss 2.5496, time 348.05ms, mfu 0.72%\n",
            "iter 320: loss 2.5322, time 348.35ms, mfu 0.72%\n",
            "iter 330: loss 2.4628, time 341.82ms, mfu 0.73%\n",
            "iter 340: loss 2.4410, time 347.23ms, mfu 0.73%\n",
            "iter 350: loss 2.5024, time 342.83ms, mfu 0.73%\n",
            "iter 360: loss 2.4959, time 351.08ms, mfu 0.73%\n",
            "iter 370: loss 2.4197, time 345.96ms, mfu 0.73%\n",
            "iter 380: loss 2.4781, time 348.65ms, mfu 0.74%\n",
            "iter 390: loss 2.4106, time 345.51ms, mfu 0.74%\n",
            "step 400: train loss 2.3870, val loss 2.3957\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 400: loss 2.4019, time 1819.49ms, mfu 0.68%\n",
            "iter 410: loss 2.4562, time 342.52ms, mfu 0.69%\n",
            "iter 420: loss 2.4440, time 359.21ms, mfu 0.69%\n",
            "iter 430: loss 2.3961, time 344.16ms, mfu 0.70%\n",
            "iter 440: loss 2.3084, time 349.18ms, mfu 0.70%\n",
            "iter 450: loss 2.4291, time 346.63ms, mfu 0.71%\n",
            "iter 460: loss 2.3799, time 381.46ms, mfu 0.70%\n",
            "iter 470: loss 2.3733, time 341.34ms, mfu 0.71%\n",
            "iter 480: loss 2.2559, time 347.17ms, mfu 0.71%\n",
            "iter 490: loss 2.2806, time 357.37ms, mfu 0.71%\n",
            "iter 500: loss 2.3715, time 346.40ms, mfu 0.72%\n",
            "iter 510: loss 2.3425, time 345.42ms, mfu 0.72%\n",
            "iter 520: loss 2.1668, time 346.50ms, mfu 0.72%\n",
            "iter 530: loss 2.2320, time 362.33ms, mfu 0.72%\n",
            "iter 540: loss 2.2896, time 348.99ms, mfu 0.73%\n",
            "iter 550: loss 2.3063, time 347.16ms, mfu 0.73%\n",
            "iter 560: loss 2.3321, time 353.50ms, mfu 0.73%\n",
            "iter 570: loss 2.2438, time 344.22ms, mfu 0.73%\n",
            "iter 580: loss 2.1371, time 354.56ms, mfu 0.73%\n",
            "iter 590: loss 2.2157, time 350.55ms, mfu 0.73%\n",
            "step 600: train loss 2.1477, val loss 2.1777\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 600: loss 2.2804, time 1830.28ms, mfu 0.67%\n",
            "iter 610: loss 2.2079, time 345.71ms, mfu 0.68%\n",
            "iter 620: loss 2.2219, time 349.79ms, mfu 0.69%\n",
            "iter 630: loss 2.1772, time 364.71ms, mfu 0.69%\n",
            "iter 640: loss 2.2526, time 349.48ms, mfu 0.69%\n",
            "iter 650: loss 2.1792, time 338.51ms, mfu 0.70%\n",
            "iter 660: loss 2.1490, time 343.65ms, mfu 0.71%\n",
            "iter 670: loss 2.2118, time 344.66ms, mfu 0.71%\n",
            "iter 680: loss 2.0865, time 346.36ms, mfu 0.72%\n",
            "iter 690: loss 2.1071, time 350.26ms, mfu 0.72%\n",
            "iter 700: loss 2.0758, time 356.94ms, mfu 0.72%\n",
            "iter 710: loss 2.2216, time 347.97ms, mfu 0.72%\n",
            "iter 720: loss 2.0716, time 346.95ms, mfu 0.72%\n",
            "iter 730: loss 2.0772, time 352.40ms, mfu 0.73%\n",
            "iter 740: loss 2.1933, time 347.35ms, mfu 0.73%\n",
            "iter 750: loss 2.1260, time 346.24ms, mfu 0.73%\n",
            "iter 760: loss 2.0342, time 341.45ms, mfu 0.73%\n",
            "iter 770: loss 2.0872, time 337.23ms, mfu 0.74%\n",
            "iter 780: loss 2.0635, time 339.83ms, mfu 0.74%\n",
            "iter 790: loss 2.0068, time 340.83ms, mfu 0.74%\n",
            "step 800: train loss 1.9516, val loss 2.0222\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 800: loss 2.0218, time 1823.27ms, mfu 0.68%\n",
            "iter 810: loss 2.0838, time 334.46ms, mfu 0.69%\n",
            "iter 820: loss 2.0927, time 341.76ms, mfu 0.70%\n",
            "iter 830: loss 2.1100, time 345.21ms, mfu 0.70%\n",
            "iter 840: loss 2.0575, time 352.49ms, mfu 0.71%\n",
            "iter 850: loss 1.9293, time 340.18ms, mfu 0.71%\n",
            "iter 860: loss 1.9997, time 348.46ms, mfu 0.72%\n",
            "iter 870: loss 2.0394, time 346.03ms, mfu 0.72%\n",
            "iter 880: loss 1.8851, time 337.36ms, mfu 0.72%\n",
            "iter 890: loss 1.9601, time 339.87ms, mfu 0.73%\n",
            "iter 900: loss 1.9729, time 340.03ms, mfu 0.73%\n",
            "iter 910: loss 1.9623, time 356.29ms, mfu 0.73%\n",
            "iter 920: loss 1.9059, time 343.76ms, mfu 0.73%\n",
            "iter 930: loss 1.9988, time 340.16ms, mfu 0.74%\n",
            "iter 940: loss 1.9421, time 349.97ms, mfu 0.74%\n",
            "iter 950: loss 1.9447, time 338.97ms, mfu 0.74%\n",
            "iter 960: loss 1.8780, time 338.94ms, mfu 0.74%\n",
            "iter 970: loss 1.9029, time 337.68ms, mfu 0.75%\n",
            "iter 980: loss 1.9320, time 352.95ms, mfu 0.74%\n",
            "iter 990: loss 1.9731, time 343.75ms, mfu 0.75%\n",
            "step 1000: train loss 1.7732, val loss 1.9081\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1000: loss 1.9185, time 1826.17ms, mfu 0.69%\n",
            "iter 1010: loss 1.8682, time 345.05ms, mfu 0.69%\n",
            "iter 1020: loss 1.8300, time 347.64ms, mfu 0.70%\n",
            "iter 1030: loss 1.8503, time 346.62ms, mfu 0.70%\n",
            "iter 1040: loss 1.8582, time 339.70ms, mfu 0.71%\n",
            "iter 1050: loss 1.7987, time 339.09ms, mfu 0.71%\n",
            "iter 1060: loss 1.9402, time 336.73ms, mfu 0.72%\n",
            "iter 1070: loss 1.8656, time 334.50ms, mfu 0.73%\n",
            "iter 1080: loss 1.7900, time 349.66ms, mfu 0.73%\n",
            "iter 1090: loss 1.7927, time 346.58ms, mfu 0.73%\n",
            "iter 1100: loss 1.8465, time 337.71ms, mfu 0.73%\n",
            "iter 1110: loss 1.9080, time 339.37ms, mfu 0.74%\n",
            "iter 1120: loss 1.8644, time 346.36ms, mfu 0.74%\n",
            "iter 1130: loss 1.7837, time 335.65ms, mfu 0.74%\n",
            "iter 1140: loss 1.7625, time 341.80ms, mfu 0.74%\n",
            "iter 1150: loss 1.8016, time 350.69ms, mfu 0.74%\n",
            "iter 1160: loss 1.7300, time 342.82ms, mfu 0.74%\n",
            "iter 1170: loss 1.7546, time 334.24ms, mfu 0.75%\n",
            "iter 1180: loss 1.8385, time 339.28ms, mfu 0.75%\n",
            "iter 1190: loss 1.7079, time 346.96ms, mfu 0.75%\n",
            "step 1200: train loss 1.6516, val loss 1.8273\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1200: loss 1.6930, time 1790.72ms, mfu 0.69%\n",
            "iter 1210: loss 1.8013, time 344.37ms, mfu 0.70%\n",
            "iter 1220: loss 1.8072, time 360.04ms, mfu 0.70%\n",
            "iter 1230: loss 1.7885, time 343.72ms, mfu 0.70%\n",
            "iter 1240: loss 1.7760, time 342.03ms, mfu 0.71%\n",
            "iter 1250: loss 1.6413, time 350.85ms, mfu 0.71%\n",
            "iter 1260: loss 1.7695, time 351.91ms, mfu 0.71%\n",
            "iter 1270: loss 1.6946, time 340.43ms, mfu 0.72%\n",
            "iter 1280: loss 1.6317, time 341.16ms, mfu 0.72%\n",
            "iter 1290: loss 1.7080, time 343.64ms, mfu 0.73%\n",
            "iter 1300: loss 1.6985, time 344.57ms, mfu 0.73%\n",
            "iter 1310: loss 1.7631, time 341.22ms, mfu 0.73%\n",
            "iter 1320: loss 1.6584, time 337.39ms, mfu 0.74%\n",
            "iter 1330: loss 1.6300, time 338.27ms, mfu 0.74%\n",
            "iter 1340: loss 1.6268, time 339.59ms, mfu 0.74%\n",
            "iter 1350: loss 1.7006, time 338.74ms, mfu 0.74%\n",
            "iter 1360: loss 1.6822, time 349.04ms, mfu 0.74%\n",
            "iter 1370: loss 1.5915, time 343.48ms, mfu 0.75%\n",
            "iter 1380: loss 1.7306, time 340.83ms, mfu 0.75%\n",
            "iter 1390: loss 1.6641, time 342.46ms, mfu 0.75%\n",
            "step 1400: train loss 1.5576, val loss 1.7325\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1400: loss 1.6750, time 1808.89ms, mfu 0.69%\n",
            "iter 1410: loss 1.6001, time 342.00ms, mfu 0.69%\n",
            "iter 1420: loss 1.7059, time 344.56ms, mfu 0.70%\n",
            "iter 1430: loss 1.6589, time 348.76ms, mfu 0.71%\n",
            "iter 1440: loss 1.6027, time 349.65ms, mfu 0.71%\n",
            "iter 1450: loss 1.6183, time 345.00ms, mfu 0.71%\n",
            "iter 1460: loss 1.5864, time 343.51ms, mfu 0.72%\n",
            "iter 1470: loss 1.6748, time 343.41ms, mfu 0.72%\n",
            "iter 1480: loss 1.6063, time 343.32ms, mfu 0.72%\n",
            "iter 1490: loss 1.6004, time 344.92ms, mfu 0.73%\n",
            "iter 1500: loss 1.6761, time 343.06ms, mfu 0.73%\n",
            "iter 1510: loss 1.6322, time 343.85ms, mfu 0.73%\n",
            "iter 1520: loss 1.5557, time 345.92ms, mfu 0.73%\n",
            "iter 1530: loss 1.5757, time 345.92ms, mfu 0.74%\n",
            "iter 1540: loss 1.6587, time 342.42ms, mfu 0.74%\n",
            "iter 1550: loss 1.5907, time 345.31ms, mfu 0.74%\n",
            "iter 1560: loss 1.5816, time 340.58ms, mfu 0.74%\n",
            "iter 1570: loss 1.5915, time 341.42ms, mfu 0.74%\n",
            "iter 1580: loss 1.5918, time 346.77ms, mfu 0.74%\n",
            "iter 1590: loss 1.5651, time 341.45ms, mfu 0.75%\n",
            "step 1600: train loss 1.4905, val loss 1.6884\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1600: loss 1.6558, time 1881.12ms, mfu 0.69%\n",
            "iter 1610: loss 1.5678, time 363.10ms, mfu 0.69%\n",
            "iter 1620: loss 1.6814, time 344.56ms, mfu 0.69%\n",
            "iter 1630: loss 1.5404, time 348.67ms, mfu 0.70%\n",
            "iter 1640: loss 1.5853, time 358.31ms, mfu 0.70%\n",
            "iter 1650: loss 1.6807, time 346.34ms, mfu 0.71%\n",
            "iter 1660: loss 1.5367, time 345.13ms, mfu 0.71%\n",
            "iter 1670: loss 1.5794, time 349.05ms, mfu 0.71%\n",
            "iter 1680: loss 1.6134, time 343.28ms, mfu 0.72%\n",
            "iter 1690: loss 1.6160, time 348.93ms, mfu 0.72%\n",
            "iter 1700: loss 1.6288, time 352.43ms, mfu 0.72%\n",
            "iter 1710: loss 1.5865, time 339.35ms, mfu 0.73%\n",
            "iter 1720: loss 1.5926, time 345.99ms, mfu 0.73%\n",
            "iter 1730: loss 1.6411, time 344.21ms, mfu 0.73%\n",
            "iter 1740: loss 1.4895, time 344.29ms, mfu 0.73%\n",
            "iter 1750: loss 1.5421, time 352.04ms, mfu 0.73%\n",
            "iter 1760: loss 1.6075, time 344.13ms, mfu 0.74%\n",
            "iter 1770: loss 1.4296, time 351.99ms, mfu 0.74%\n",
            "iter 1780: loss 1.5826, time 350.88ms, mfu 0.74%\n",
            "iter 1790: loss 1.6333, time 344.67ms, mfu 0.74%\n",
            "step 1800: train loss 1.4320, val loss 1.6275\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1800: loss 1.4430, time 1808.99ms, mfu 0.68%\n",
            "iter 1810: loss 1.5662, time 341.46ms, mfu 0.69%\n",
            "iter 1820: loss 1.5154, time 339.05ms, mfu 0.69%\n",
            "iter 1830: loss 1.5979, time 341.42ms, mfu 0.70%\n",
            "iter 1840: loss 1.5619, time 360.36ms, mfu 0.70%\n",
            "iter 1850: loss 1.5000, time 340.34ms, mfu 0.71%\n",
            "iter 1860: loss 1.5111, time 340.61ms, mfu 0.71%\n",
            "iter 1870: loss 1.5223, time 340.41ms, mfu 0.72%\n",
            "iter 1880: loss 1.5435, time 340.94ms, mfu 0.72%\n",
            "iter 1890: loss 1.5677, time 336.92ms, mfu 0.73%\n",
            "iter 1900: loss 1.4775, time 343.84ms, mfu 0.73%\n",
            "iter 1910: loss 1.4935, time 342.31ms, mfu 0.73%\n",
            "iter 1920: loss 1.5532, time 342.90ms, mfu 0.74%\n",
            "iter 1930: loss 1.5215, time 342.33ms, mfu 0.74%\n",
            "iter 1940: loss 1.5472, time 339.74ms, mfu 0.74%\n",
            "iter 1950: loss 1.5186, time 341.39ms, mfu 0.74%\n",
            "iter 1960: loss 1.5556, time 342.92ms, mfu 0.74%\n",
            "iter 1970: loss 1.4703, time 337.82ms, mfu 0.75%\n",
            "iter 1980: loss 1.5170, time 345.50ms, mfu 0.75%\n",
            "iter 1990: loss 1.4324, time 348.21ms, mfu 0.75%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/nanoGPT_results\"\n",
        "samples_dir = os.path.join(base_dir, \"samples\")\n",
        "\n",
        "os.makedirs(samples_dir, exist_ok=True)\n",
        "\n",
        "# iterate over each experiment folder\n",
        "exp_folders = sorted([\n",
        "    d for d in os.listdir(base_dir)\n",
        "    if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"b\")\n",
        "])\n",
        "\n",
        "print(f\"Found {len(exp_folders)} experiment folders.\")\n",
        "\n",
        "for i, exp in enumerate(exp_folders, 1):\n",
        "    exp_path = os.path.join(base_dir, exp)\n",
        "    ckpt_path = os.path.join(exp_path, \"ckpt.pt\")\n",
        "\n",
        "    if not os.path.isfile(ckpt_path):\n",
        "        print(f\"Skipping {exp} (no ckpt.pt found)\")\n",
        "        continue\n",
        "\n",
        "    out_sample = os.path.join(samples_dir, f\"{exp}_sample.txt\")\n",
        "\n",
        "    print(f\"[{i}/{len(exp_folders)}] Generating sample for {exp}\")\n",
        "\n",
        "    cmd = (\n",
        "        f\"python /content/nanoGPT/sample.py \"\n",
        "        f\"--out_dir={exp_path} \"\n",
        "        f\"--start=' ' \"\n",
        "        f\"--num_samples=3 \"\n",
        "        f\"--max_new_tokens=200 \"\n",
        "        f\"> '{out_sample}'\"\n",
        "    )\n",
        "    subprocess.run(cmd, shell=True)\n",
        "\n",
        "print(\"✅ All samples generated and stored in:\", samples_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHR9xUDLLM43",
        "outputId": "02a2b8f6-6ef9-45e4-ff23-ecf4d291deda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32 experiment folders.\n",
            "[1/32] Generating sample for b64_L4_H4_E128_BS16_MI1000_D10_s5\n",
            "[2/32] Generating sample for b64_L4_H4_E128_BS16_MI1000_D20_s6\n",
            "[3/32] Generating sample for b64_L4_H4_E128_BS16_MI2000_D10_s7\n",
            "[4/32] Generating sample for b64_L4_H4_E128_BS16_MI2000_D20_s8\n",
            "[5/32] Generating sample for b64_L4_H4_E128_BS8_MI1000_D10_s1\n",
            "[6/32] Generating sample for b64_L4_H4_E128_BS8_MI1000_D20_s2\n",
            "[7/32] Generating sample for b64_L4_H4_E128_BS8_MI2000_D10_s3\n",
            "[8/32] Generating sample for b64_L4_H4_E128_BS8_MI2000_D20_s4\n",
            "[9/32] Generating sample for b64_L4_H4_E256_BS16_MI1000_D10_s13\n",
            "[10/32] Generating sample for b64_L4_H4_E256_BS16_MI1000_D20_s14\n",
            "[11/32] Generating sample for b64_L4_H4_E256_BS16_MI2000_D10_s15\n",
            "[12/32] Generating sample for b64_L4_H4_E256_BS16_MI2000_D20_s16\n",
            "[13/32] Generating sample for b64_L4_H4_E256_BS8_MI1000_D10_s9\n",
            "[14/32] Generating sample for b64_L4_H4_E256_BS8_MI1000_D20_s10\n",
            "[15/32] Generating sample for b64_L4_H4_E256_BS8_MI2000_D10_s11\n",
            "[16/32] Generating sample for b64_L4_H4_E256_BS8_MI2000_D20_s12\n",
            "[17/32] Generating sample for b64_L4_H8_E128_BS16_MI1000_D10_s21\n",
            "[18/32] Generating sample for b64_L4_H8_E128_BS16_MI1000_D20_s22\n",
            "[19/32] Generating sample for b64_L4_H8_E128_BS16_MI2000_D10_s23\n",
            "[20/32] Generating sample for b64_L4_H8_E128_BS16_MI2000_D20_s24\n",
            "[21/32] Generating sample for b64_L4_H8_E128_BS8_MI1000_D10_s17\n",
            "[22/32] Generating sample for b64_L4_H8_E128_BS8_MI1000_D20_s18\n",
            "[23/32] Generating sample for b64_L4_H8_E128_BS8_MI2000_D10_s19\n",
            "[24/32] Generating sample for b64_L4_H8_E128_BS8_MI2000_D20_s20\n",
            "[25/32] Generating sample for b64_L4_H8_E256_BS16_MI1000_D10_s29\n",
            "[26/32] Generating sample for b64_L4_H8_E256_BS16_MI1000_D20_s30\n",
            "[27/32] Generating sample for b64_L4_H8_E256_BS16_MI2000_D10_s31\n",
            "[28/32] Generating sample for b64_L4_H8_E256_BS16_MI2000_D20_s32\n",
            "[29/32] Generating sample for b64_L4_H8_E256_BS8_MI1000_D10_s25\n",
            "[30/32] Generating sample for b64_L4_H8_E256_BS8_MI1000_D20_s26\n",
            "[31/32] Generating sample for b64_L4_H8_E256_BS8_MI2000_D10_s27\n",
            "[32/32] Generating sample for b64_L4_H8_E256_BS8_MI2000_D20_s28\n",
            "✅ All samples generated and stored in: /content/drive/MyDrive/nanoGPT_results/samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HT5jS4lNM3T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ascoX7VJNNgE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
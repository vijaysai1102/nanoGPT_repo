{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPIy6g-Cvmch",
        "outputId": "bbf2ffca-f488-4f84-ac28-c3e61fd449a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Results will be saved to: /content/drive/MyDrive/nanoGPT_results\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/nanoGPT_results\"\n",
        "!mkdir -p \"$SAVE_DIR\"\n",
        "\n",
        "print(\"Results will be saved to:\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/karpathy/nanoGPT.git\n",
        "%cd nanoGPT\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install tqdm numpy requests matplotlib ninja\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P8W1dFRvnWT",
        "outputId": "2fddc987-9290-4b09-828e-34e3757065e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 686, done.\u001b[K\n",
            "remote: Total 686 (delta 0), reused 0 (delta 0), pack-reused 686 (from 1)\u001b[K\n",
            "Receiving objects: 100% (686/686), 974.06 KiB | 21.65 MiB/s, done.\n",
            "Resolving deltas: 100% (380/380), done.\n",
            "/content/nanoGPT\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data/shakespeare_char\n",
        "!python prepare.py\n",
        "%cd ../..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvoKhfr1vnSE",
        "outputId": "d1ca487a-4cd2-4947-bf9f-a454c4affbc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nanoGPT/data/shakespeare_char\n",
            "length of dataset in characters: 1,115,394\n",
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n",
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n",
            "/content/nanoGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_experiments.py\n",
        "import os, sys, itertools, subprocess, re, csv, time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "SAVE_DIR = os.environ.get(\"SAVE_DIR\", \"/content/drive/MyDrive/nanoGPT_results\")\n",
        "\n",
        "# Full Hyperparameter Grid\n",
        "BLOCK_SIZES = [64, 128]\n",
        "N_LAYERS = [4, 6]\n",
        "N_HEADS = [4, 8]\n",
        "N_EMBDS = [128, 256]\n",
        "BATCH_SIZES = [8, 16]\n",
        "MAX_ITERS = [1000, 2000]\n",
        "DROPOUTS = [0.1, 0.2]\n",
        "\n",
        "# Member → fixed hyperparams\n",
        "MEMBER_MAP = {\n",
        "    1: (64, 4),\n",
        "    2: (64, 6),\n",
        "    3: (128, 4),\n",
        "    4: (128, 6),\n",
        "}\n",
        "\n",
        "CONFIG_TEMPLATE = r\"\"\"\n",
        "out_dir = \"{save_dir}/{out_name}\"\n",
        "dataset = \"shakespeare_char\"\n",
        "eval_interval = 200\n",
        "log_interval = 10\n",
        "always_save_checkpoint = True\n",
        "\n",
        "batch_size = {batch_size}\n",
        "block_size = {block_size}\n",
        "n_layer = {n_layer}\n",
        "n_head = {n_head}\n",
        "n_embd = {n_embd}\n",
        "dropout = {dropout}\n",
        "\n",
        "learning_rate = 3e-4\n",
        "max_iters = {max_iters}\n",
        "lr_decay_iters = {max_iters}\n",
        "\n",
        "seed = {seed}\n",
        "device = \"{device}\"\n",
        "\n",
        "num_workers = 0\n",
        "compile = False\n",
        "\"\"\"\n",
        "\n",
        "def list_experiments(member_id):\n",
        "    block_size, n_layer = MEMBER_MAP[member_id]\n",
        "    grid = list(itertools.product(N_HEADS, N_EMBDS, BATCH_SIZES, MAX_ITERS, DROPOUTS))\n",
        "    exps = []\n",
        "    for seed, (nh, ne, bs, mi, do) in enumerate(grid, 1):\n",
        "        out_name = f\"b{block_size}_L{n_layer}_H{nh}_E{ne}_BS{bs}_MI{mi}_D{int(do*100)}_s{seed}\"\n",
        "        exps.append({\n",
        "            \"block_size\": block_size, \"n_layer\": n_layer,\n",
        "            \"n_head\": nh, \"n_embd\": ne,\n",
        "            \"batch_size\": bs, \"max_iters\": mi,\n",
        "            \"dropout\": do, \"seed\": seed,\n",
        "            \"out_name\": out_name\n",
        "        })\n",
        "    return exps\n",
        "\n",
        "def parse_losses(stdout_line):\n",
        "    m = re.search(r\"train loss ([0-9.]+).*val loss ([0-9.]+)\", stdout_line)\n",
        "    if m:\n",
        "        return float(m.group(1)), float(m.group(2))\n",
        "    return None, None\n",
        "\n",
        "def extract_model_params(logtext):\n",
        "    m = re.search(r\"number of parameters:\\s*([0-9.]+)M\", logtext)\n",
        "    if m:\n",
        "        return float(m.group(1)) * 1e6\n",
        "    return None\n",
        "\n",
        "def run_training(cfg, device):\n",
        "    cfg_file = Path(f\"{cfg['out_name']}.py\")\n",
        "    cfg_file.write_text(CONFIG_TEMPLATE.format(**cfg, save_dir=SAVE_DIR, device=device))\n",
        "\n",
        "    p = subprocess.Popen(\n",
        "        [\"python\", \"train.py\", str(cfg_file)],\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "    )\n",
        "\n",
        "    train_loss = None\n",
        "    val_loss = None\n",
        "    param_count = None\n",
        "    log_buf = \"\"\n",
        "\n",
        "    for line in p.stdout:\n",
        "        print(line, end=\"\")\n",
        "        log_buf += line\n",
        "        tl, vl = parse_losses(line)\n",
        "        if tl is not None:\n",
        "            train_loss, val_loss = tl, vl\n",
        "\n",
        "        if param_count is None:\n",
        "            param_count = extract_model_params(log_buf)\n",
        "\n",
        "    p.wait()\n",
        "    loss_gap = val_loss - train_loss if train_loss and val_loss else None\n",
        "    return train_loss, val_loss, loss_gap, param_count, cfg_file\n",
        "\n",
        "def main():\n",
        "    member_id = int(sys.argv[1])\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    result_csv = Path(SAVE_DIR) / \"results.csv\"\n",
        "    if not result_csv.exists():\n",
        "        with open(result_csv, \"w\") as f:\n",
        "            csv.writer(f).writerow([\n",
        "                \"Experiment\",\n",
        "                \"Train Loss\",\n",
        "                \"Val Loss\",\n",
        "                \"Loss Gap\",\n",
        "                \"Total Params\",\n",
        "                \"Config Path\"\n",
        "            ])\n",
        "\n",
        "    exps = list_experiments(member_id)\n",
        "    print(f\"Running {len(exps)} experiments for Member {member_id}\")\n",
        "\n",
        "    for i, exp in enumerate(exps, 1):\n",
        "        print(f\"\\n=== Experiment {i}/{len(exps)}: {exp['out_name']} ===\")\n",
        "        tr, vl, gap, params, cfg_path = run_training(exp, device)\n",
        "\n",
        "        with open(result_csv, \"a\") as f:\n",
        "            csv.writer(f).writerow([\n",
        "                exp[\"out_name\"], tr, vl, gap, params, str(cfg_path.resolve())\n",
        "            ])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITc-tc9XvnOw",
        "outputId": "88f519db-eafd-48e7-a5af-91065fd8f99f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_experiments.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SAVE_DIR\"] = SAVE_DIR\n"
      ],
      "metadata": {
        "id": "q7nucKG6vnKd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6_51zXSQTiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_experiments.py 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw2Nz9hzvnE4",
        "outputId": "1785139f-5335-422b-d74a-473e1e489e67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "iter 1440: loss 1.9541, time 486.77ms, mfu 0.43%\n",
            "iter 1450: loss 1.9107, time 495.35ms, mfu 0.43%\n",
            "iter 1460: loss 1.9259, time 491.21ms, mfu 0.43%\n",
            "iter 1470: loss 1.8854, time 485.98ms, mfu 0.43%\n",
            "iter 1480: loss 1.9060, time 499.24ms, mfu 0.43%\n",
            "iter 1490: loss 1.9370, time 487.99ms, mfu 0.43%\n",
            "iter 1500: loss 1.8871, time 475.66ms, mfu 0.44%\n",
            "iter 1510: loss 1.9487, time 476.59ms, mfu 0.44%\n",
            "iter 1520: loss 1.9197, time 466.55ms, mfu 0.44%\n",
            "iter 1530: loss 1.9436, time 475.11ms, mfu 0.44%\n",
            "iter 1540: loss 1.8867, time 479.51ms, mfu 0.44%\n",
            "iter 1550: loss 1.8750, time 469.95ms, mfu 0.45%\n",
            "iter 1560: loss 1.8685, time 485.44ms, mfu 0.45%\n",
            "iter 1570: loss 1.8725, time 491.63ms, mfu 0.45%\n",
            "iter 1580: loss 1.8941, time 487.65ms, mfu 0.45%\n",
            "iter 1590: loss 1.9062, time 485.07ms, mfu 0.45%\n",
            "step 1600: train loss 1.7470, val loss 1.8863\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E128_BS16_MI2000_D20_s8\n",
            "iter 1600: loss 1.9014, time 2346.15ms, mfu 0.41%\n",
            "iter 1610: loss 1.9260, time 484.15ms, mfu 0.42%\n",
            "iter 1620: loss 1.8715, time 501.60ms, mfu 0.42%\n",
            "iter 1630: loss 1.8695, time 475.00ms, mfu 0.42%\n",
            "iter 1640: loss 1.8836, time 484.11ms, mfu 0.42%\n",
            "iter 1650: loss 1.8254, time 482.76ms, mfu 0.43%\n",
            "iter 1660: loss 1.8296, time 480.28ms, mfu 0.43%\n",
            "iter 1670: loss 1.8206, time 510.41ms, mfu 0.43%\n",
            "iter 1680: loss 1.8266, time 473.53ms, mfu 0.43%\n",
            "iter 1690: loss 1.8233, time 469.26ms, mfu 0.44%\n",
            "iter 1700: loss 1.7491, time 480.78ms, mfu 0.44%\n",
            "iter 1710: loss 1.8351, time 467.15ms, mfu 0.44%\n",
            "iter 1720: loss 1.8347, time 468.30ms, mfu 0.44%\n",
            "iter 1730: loss 1.8111, time 470.24ms, mfu 0.45%\n",
            "iter 1740: loss 1.8452, time 484.31ms, mfu 0.45%\n",
            "iter 1750: loss 1.7864, time 501.64ms, mfu 0.45%\n",
            "iter 1760: loss 1.8231, time 465.07ms, mfu 0.45%\n",
            "iter 1770: loss 1.8357, time 473.03ms, mfu 0.45%\n",
            "iter 1780: loss 1.8845, time 479.23ms, mfu 0.45%\n",
            "iter 1790: loss 1.8238, time 465.69ms, mfu 0.45%\n",
            "step 1800: train loss 1.6589, val loss 1.8286\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E128_BS16_MI2000_D20_s8\n",
            "iter 1800: loss 1.7762, time 2266.62ms, mfu 0.42%\n",
            "iter 1810: loss 1.7613, time 473.89ms, mfu 0.42%\n",
            "iter 1820: loss 1.7433, time 476.61ms, mfu 0.42%\n",
            "iter 1830: loss 1.7452, time 467.42ms, mfu 0.43%\n",
            "iter 1840: loss 1.7410, time 456.01ms, mfu 0.43%\n",
            "iter 1850: loss 1.7597, time 504.45ms, mfu 0.43%\n",
            "iter 1860: loss 1.7314, time 471.79ms, mfu 0.44%\n",
            "iter 1870: loss 1.6755, time 465.59ms, mfu 0.44%\n",
            "iter 1880: loss 1.8451, time 472.08ms, mfu 0.44%\n",
            "iter 1890: loss 1.8084, time 482.00ms, mfu 0.44%\n",
            "iter 1900: loss 1.7437, time 472.04ms, mfu 0.45%\n",
            "iter 1910: loss 1.7562, time 465.55ms, mfu 0.45%\n",
            "iter 1920: loss 1.7087, time 460.94ms, mfu 0.45%\n",
            "iter 1930: loss 1.6941, time 465.76ms, mfu 0.45%\n",
            "iter 1940: loss 1.7059, time 464.16ms, mfu 0.45%\n",
            "iter 1950: loss 1.7865, time 473.59ms, mfu 0.45%\n",
            "iter 1960: loss 1.7797, time 462.57ms, mfu 0.46%\n",
            "iter 1970: loss 1.7954, time 469.59ms, mfu 0.46%\n",
            "iter 1980: loss 1.7374, time 486.92ms, mfu 0.46%\n",
            "iter 1990: loss 1.7735, time 466.52ms, mfu 0.46%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 9/32: b128_L6_H4_E256_BS8_MI1000_D10_s9 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS8_MI1000_D10_s9.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D10_s9\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 9\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2264, val loss 4.2235\n",
            "iter 0: loss 4.2134, time 2499.26ms, mfu -100.00%\n",
            "iter 10: loss 4.1496, time 448.92ms, mfu 0.90%\n",
            "iter 20: loss 3.9738, time 454.36ms, mfu 0.90%\n",
            "iter 30: loss 3.7213, time 451.20ms, mfu 0.90%\n",
            "iter 40: loss 3.5601, time 458.16ms, mfu 0.90%\n",
            "iter 50: loss 3.4790, time 465.02ms, mfu 0.89%\n",
            "iter 60: loss 3.3526, time 470.55ms, mfu 0.89%\n",
            "iter 70: loss 3.2454, time 461.63ms, mfu 0.89%\n",
            "iter 80: loss 3.1849, time 445.25ms, mfu 0.89%\n",
            "iter 90: loss 3.0632, time 452.46ms, mfu 0.89%\n",
            "iter 100: loss 3.0574, time 464.53ms, mfu 0.89%\n",
            "iter 110: loss 2.9014, time 449.98ms, mfu 0.89%\n",
            "iter 120: loss 2.9394, time 454.99ms, mfu 0.89%\n",
            "iter 130: loss 2.8772, time 458.83ms, mfu 0.89%\n",
            "iter 140: loss 2.8965, time 443.38ms, mfu 0.89%\n",
            "iter 150: loss 2.8053, time 451.88ms, mfu 0.89%\n",
            "iter 160: loss 2.7366, time 454.89ms, mfu 0.89%\n",
            "iter 170: loss 2.7671, time 440.09ms, mfu 0.89%\n",
            "iter 180: loss 2.7105, time 463.34ms, mfu 0.89%\n",
            "iter 190: loss 2.7241, time 444.95ms, mfu 0.89%\n",
            "step 200: train loss 2.6782, val loss 2.6897\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 200: loss 2.6696, time 2338.03ms, mfu 0.82%\n",
            "iter 210: loss 2.6724, time 448.97ms, mfu 0.83%\n",
            "iter 220: loss 2.6380, time 453.68ms, mfu 0.84%\n",
            "iter 230: loss 2.6557, time 449.56ms, mfu 0.84%\n",
            "iter 240: loss 2.6564, time 457.81ms, mfu 0.85%\n",
            "iter 250: loss 2.7093, time 451.36ms, mfu 0.85%\n",
            "iter 260: loss 2.4994, time 454.46ms, mfu 0.85%\n",
            "iter 270: loss 2.5836, time 474.46ms, mfu 0.85%\n",
            "iter 280: loss 2.5212, time 449.02ms, mfu 0.86%\n",
            "iter 290: loss 2.5110, time 440.58ms, mfu 0.86%\n",
            "iter 300: loss 2.5737, time 448.61ms, mfu 0.87%\n",
            "iter 310: loss 2.5722, time 450.61ms, mfu 0.87%\n",
            "iter 320: loss 2.5157, time 445.35ms, mfu 0.88%\n",
            "iter 330: loss 2.4949, time 472.43ms, mfu 0.87%\n",
            "iter 340: loss 2.4983, time 449.22ms, mfu 0.88%\n",
            "iter 350: loss 2.4582, time 442.69ms, mfu 0.88%\n",
            "iter 360: loss 2.4843, time 468.23ms, mfu 0.88%\n",
            "iter 370: loss 2.4764, time 447.31ms, mfu 0.88%\n",
            "iter 380: loss 2.4293, time 441.24ms, mfu 0.88%\n",
            "iter 390: loss 2.5210, time 463.73ms, mfu 0.88%\n",
            "step 400: train loss 2.3956, val loss 2.4049\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 400: loss 2.3776, time 2228.26ms, mfu 0.81%\n",
            "iter 410: loss 2.3817, time 468.94ms, mfu 0.82%\n",
            "iter 420: loss 2.3981, time 457.13ms, mfu 0.82%\n",
            "iter 430: loss 2.4210, time 462.80ms, mfu 0.83%\n",
            "iter 440: loss 2.3553, time 458.53ms, mfu 0.83%\n",
            "iter 450: loss 2.4236, time 453.29ms, mfu 0.84%\n",
            "iter 460: loss 2.3172, time 455.15ms, mfu 0.84%\n",
            "iter 470: loss 2.3535, time 489.37ms, mfu 0.84%\n",
            "iter 480: loss 2.4257, time 456.75ms, mfu 0.85%\n",
            "iter 490: loss 2.3468, time 467.45ms, mfu 0.85%\n",
            "iter 500: loss 2.3234, time 447.47ms, mfu 0.85%\n",
            "iter 510: loss 2.2709, time 440.70ms, mfu 0.86%\n",
            "iter 520: loss 2.2969, time 464.61ms, mfu 0.86%\n",
            "iter 530: loss 2.2766, time 450.89ms, mfu 0.87%\n",
            "iter 540: loss 2.3044, time 455.57ms, mfu 0.87%\n",
            "iter 550: loss 2.2696, time 455.32ms, mfu 0.87%\n",
            "iter 560: loss 2.2365, time 448.25ms, mfu 0.87%\n",
            "iter 570: loss 2.1996, time 484.71ms, mfu 0.87%\n",
            "iter 580: loss 2.1999, time 443.48ms, mfu 0.87%\n",
            "iter 590: loss 2.3149, time 444.31ms, mfu 0.88%\n",
            "step 600: train loss 2.1426, val loss 2.1737\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 600: loss 2.2082, time 2270.89ms, mfu 0.81%\n",
            "iter 610: loss 2.2123, time 458.41ms, mfu 0.81%\n",
            "iter 620: loss 2.1520, time 471.28ms, mfu 0.82%\n",
            "iter 630: loss 2.1616, time 454.55ms, mfu 0.83%\n",
            "iter 640: loss 2.0890, time 449.01ms, mfu 0.83%\n",
            "iter 650: loss 2.1232, time 448.74ms, mfu 0.84%\n",
            "iter 660: loss 2.1349, time 439.75ms, mfu 0.85%\n",
            "iter 670: loss 2.1694, time 468.14ms, mfu 0.85%\n",
            "iter 680: loss 2.0892, time 467.48ms, mfu 0.85%\n",
            "iter 690: loss 2.1255, time 470.46ms, mfu 0.85%\n",
            "iter 700: loss 2.0663, time 457.24ms, mfu 0.86%\n",
            "iter 710: loss 2.1295, time 441.68ms, mfu 0.86%\n",
            "iter 720: loss 2.0242, time 441.47ms, mfu 0.87%\n",
            "iter 730: loss 2.0645, time 443.94ms, mfu 0.87%\n",
            "iter 740: loss 2.0322, time 453.05ms, mfu 0.87%\n",
            "iter 750: loss 2.0985, time 452.03ms, mfu 0.88%\n",
            "iter 760: loss 1.9954, time 456.83ms, mfu 0.88%\n",
            "iter 770: loss 1.9581, time 467.76ms, mfu 0.87%\n",
            "iter 780: loss 1.9717, time 448.74ms, mfu 0.88%\n",
            "iter 790: loss 2.0534, time 455.46ms, mfu 0.88%\n",
            "step 800: train loss 1.8856, val loss 1.9804\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 800: loss 1.8945, time 2257.43ms, mfu 0.81%\n",
            "iter 810: loss 1.9212, time 456.35ms, mfu 0.82%\n",
            "iter 820: loss 1.9369, time 453.75ms, mfu 0.82%\n",
            "iter 830: loss 1.9258, time 472.63ms, mfu 0.83%\n",
            "iter 840: loss 1.9710, time 449.38ms, mfu 0.83%\n",
            "iter 850: loss 1.9185, time 462.73ms, mfu 0.84%\n",
            "iter 860: loss 1.9132, time 446.92ms, mfu 0.84%\n",
            "iter 870: loss 1.8020, time 445.55ms, mfu 0.85%\n",
            "iter 880: loss 1.8223, time 466.15ms, mfu 0.85%\n",
            "iter 890: loss 1.8797, time 443.49ms, mfu 0.86%\n",
            "iter 900: loss 1.9011, time 451.65ms, mfu 0.86%\n",
            "iter 910: loss 1.9024, time 457.22ms, mfu 0.86%\n",
            "iter 920: loss 1.6952, time 452.79ms, mfu 0.87%\n",
            "iter 930: loss 1.8009, time 462.18ms, mfu 0.87%\n",
            "iter 940: loss 1.7983, time 451.10ms, mfu 0.87%\n",
            "iter 950: loss 1.7456, time 445.51ms, mfu 0.87%\n",
            "iter 960: loss 1.8391, time 459.46ms, mfu 0.87%\n",
            "iter 970: loss 1.7489, time 448.27ms, mfu 0.88%\n",
            "iter 980: loss 1.9488, time 454.89ms, mfu 0.88%\n",
            "iter 990: loss 1.7398, time 459.92ms, mfu 0.88%\n",
            "step 1000: train loss 1.6741, val loss 1.8271\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D10_s9\n",
            "iter 1000: loss 1.7680, time 2275.85ms, mfu 0.81%\n",
            "\n",
            "=== Experiment 10/32: b128_L6_H4_E256_BS8_MI1000_D20_s10 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS8_MI1000_D20_s10.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D20_s10\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 10\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2264, val loss 4.2235\n",
            "iter 0: loss 4.2072, time 2482.10ms, mfu -100.00%\n",
            "iter 10: loss 4.1560, time 449.44ms, mfu 0.90%\n",
            "iter 20: loss 4.0079, time 460.14ms, mfu 0.90%\n",
            "iter 30: loss 3.7777, time 441.16ms, mfu 0.90%\n",
            "iter 40: loss 3.6094, time 441.83ms, mfu 0.90%\n",
            "iter 50: loss 3.5152, time 473.14ms, mfu 0.90%\n",
            "iter 60: loss 3.3969, time 445.30ms, mfu 0.90%\n",
            "iter 70: loss 3.3214, time 444.26ms, mfu 0.90%\n",
            "iter 80: loss 3.2543, time 458.63ms, mfu 0.90%\n",
            "iter 90: loss 3.1314, time 443.09ms, mfu 0.90%\n",
            "iter 100: loss 3.1207, time 445.80ms, mfu 0.90%\n",
            "iter 110: loss 2.9492, time 449.25ms, mfu 0.90%\n",
            "iter 120: loss 2.9978, time 450.82ms, mfu 0.90%\n",
            "iter 130: loss 2.9232, time 456.39ms, mfu 0.90%\n",
            "iter 140: loss 2.9372, time 444.12ms, mfu 0.90%\n",
            "iter 150: loss 2.8468, time 455.76ms, mfu 0.90%\n",
            "iter 160: loss 2.7854, time 468.49ms, mfu 0.89%\n",
            "iter 170: loss 2.8129, time 449.65ms, mfu 0.89%\n",
            "iter 180: loss 2.7480, time 454.80ms, mfu 0.89%\n",
            "iter 190: loss 2.7504, time 460.14ms, mfu 0.89%\n",
            "step 200: train loss 2.6942, val loss 2.7006\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 200: loss 2.7159, time 2275.06ms, mfu 0.82%\n",
            "iter 210: loss 2.7042, time 446.20ms, mfu 0.83%\n",
            "iter 220: loss 2.6670, time 453.50ms, mfu 0.84%\n",
            "iter 230: loss 2.6897, time 449.55ms, mfu 0.84%\n",
            "iter 240: loss 2.6932, time 448.99ms, mfu 0.85%\n",
            "iter 250: loss 2.7414, time 451.27ms, mfu 0.85%\n",
            "iter 260: loss 2.5239, time 443.91ms, mfu 0.86%\n",
            "iter 270: loss 2.6175, time 457.04ms, mfu 0.86%\n",
            "iter 280: loss 2.5393, time 446.97ms, mfu 0.87%\n",
            "iter 290: loss 2.5447, time 464.69ms, mfu 0.87%\n",
            "iter 300: loss 2.5989, time 450.88ms, mfu 0.87%\n",
            "iter 310: loss 2.6197, time 461.12ms, mfu 0.87%\n",
            "iter 320: loss 2.5521, time 464.64ms, mfu 0.87%\n",
            "iter 330: loss 2.5184, time 451.93ms, mfu 0.87%\n",
            "iter 340: loss 2.5360, time 457.37ms, mfu 0.87%\n",
            "iter 350: loss 2.5008, time 445.77ms, mfu 0.88%\n",
            "iter 360: loss 2.5214, time 454.42ms, mfu 0.88%\n",
            "iter 370: loss 2.5044, time 444.00ms, mfu 0.88%\n",
            "iter 380: loss 2.4672, time 439.94ms, mfu 0.88%\n",
            "iter 390: loss 2.5694, time 444.43ms, mfu 0.89%\n",
            "step 400: train loss 2.4401, val loss 2.4419\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 400: loss 2.4175, time 2267.18ms, mfu 0.82%\n",
            "iter 410: loss 2.4458, time 457.71ms, mfu 0.82%\n",
            "iter 420: loss 2.4367, time 451.98ms, mfu 0.83%\n",
            "iter 430: loss 2.4718, time 448.11ms, mfu 0.84%\n",
            "iter 440: loss 2.3835, time 449.46ms, mfu 0.84%\n",
            "iter 450: loss 2.4652, time 452.17ms, mfu 0.85%\n",
            "iter 460: loss 2.3655, time 440.78ms, mfu 0.86%\n",
            "iter 470: loss 2.4102, time 437.70ms, mfu 0.86%\n",
            "iter 480: loss 2.4870, time 435.00ms, mfu 0.87%\n",
            "iter 490: loss 2.4082, time 434.35ms, mfu 0.88%\n",
            "iter 500: loss 2.3999, time 456.54ms, mfu 0.88%\n",
            "iter 510: loss 2.3429, time 448.33ms, mfu 0.88%\n",
            "iter 520: loss 2.3548, time 440.07ms, mfu 0.88%\n",
            "iter 530: loss 2.3499, time 483.94ms, mfu 0.88%\n",
            "iter 540: loss 2.3753, time 436.50ms, mfu 0.88%\n",
            "iter 550: loss 2.3491, time 451.18ms, mfu 0.88%\n",
            "iter 560: loss 2.3126, time 438.01ms, mfu 0.89%\n",
            "iter 570: loss 2.2824, time 444.19ms, mfu 0.89%\n",
            "iter 580: loss 2.2710, time 450.39ms, mfu 0.89%\n",
            "iter 590: loss 2.3882, time 453.63ms, mfu 0.89%\n",
            "step 600: train loss 2.2069, val loss 2.2290\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 600: loss 2.2869, time 2226.47ms, mfu 0.82%\n",
            "iter 610: loss 2.2850, time 470.80ms, mfu 0.82%\n",
            "iter 620: loss 2.2576, time 444.17ms, mfu 0.83%\n",
            "iter 630: loss 2.2649, time 470.54ms, mfu 0.84%\n",
            "iter 640: loss 2.1985, time 442.55ms, mfu 0.84%\n",
            "iter 650: loss 2.2224, time 452.45ms, mfu 0.85%\n",
            "iter 660: loss 2.2238, time 457.48ms, mfu 0.85%\n",
            "iter 670: loss 2.2565, time 443.58ms, mfu 0.86%\n",
            "iter 680: loss 2.1903, time 437.12ms, mfu 0.86%\n",
            "iter 690: loss 2.2116, time 450.55ms, mfu 0.87%\n",
            "iter 700: loss 2.1815, time 444.29ms, mfu 0.87%\n",
            "iter 710: loss 2.2238, time 436.62ms, mfu 0.88%\n",
            "iter 720: loss 2.1481, time 453.33ms, mfu 0.88%\n",
            "iter 730: loss 2.1715, time 451.15ms, mfu 0.88%\n",
            "iter 740: loss 2.1338, time 458.54ms, mfu 0.88%\n",
            "iter 750: loss 2.1954, time 446.70ms, mfu 0.88%\n",
            "iter 760: loss 2.1043, time 451.95ms, mfu 0.88%\n",
            "iter 770: loss 2.0815, time 457.08ms, mfu 0.88%\n",
            "iter 780: loss 2.0924, time 436.80ms, mfu 0.89%\n",
            "iter 790: loss 2.1853, time 433.77ms, mfu 0.89%\n",
            "step 800: train loss 1.9788, val loss 2.0500\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 800: loss 2.0130, time 2212.25ms, mfu 0.82%\n",
            "iter 810: loss 2.0425, time 465.03ms, mfu 0.83%\n",
            "iter 820: loss 2.0660, time 443.96ms, mfu 0.83%\n",
            "iter 830: loss 2.0372, time 469.52ms, mfu 0.84%\n",
            "iter 840: loss 2.0686, time 447.91ms, mfu 0.84%\n",
            "iter 850: loss 2.0374, time 447.11ms, mfu 0.85%\n",
            "iter 860: loss 2.0227, time 449.27ms, mfu 0.85%\n",
            "iter 870: loss 1.9256, time 447.82ms, mfu 0.86%\n",
            "iter 880: loss 1.9301, time 456.99ms, mfu 0.86%\n",
            "iter 890: loss 1.9761, time 443.34ms, mfu 0.87%\n",
            "iter 900: loss 2.0118, time 469.16ms, mfu 0.87%\n",
            "iter 910: loss 2.0312, time 448.00ms, mfu 0.87%\n",
            "iter 920: loss 1.8687, time 452.04ms, mfu 0.87%\n",
            "iter 930: loss 1.9289, time 450.07ms, mfu 0.88%\n",
            "iter 940: loss 1.9406, time 448.84ms, mfu 0.88%\n",
            "iter 950: loss 1.8848, time 467.50ms, mfu 0.88%\n",
            "iter 960: loss 1.9616, time 440.26ms, mfu 0.88%\n",
            "iter 970: loss 1.8686, time 451.21ms, mfu 0.88%\n",
            "iter 980: loss 2.0429, time 446.86ms, mfu 0.88%\n",
            "iter 990: loss 1.8369, time 461.26ms, mfu 0.88%\n",
            "step 1000: train loss 1.7860, val loss 1.9060\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI1000_D20_s10\n",
            "iter 1000: loss 1.9120, time 2220.55ms, mfu 0.81%\n",
            "\n",
            "=== Experiment 11/32: b128_L6_H4_E256_BS8_MI2000_D10_s11 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS8_MI2000_D10_s11.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 11\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2264, val loss 4.2235\n",
            "iter 0: loss 4.2134, time 2453.86ms, mfu -100.00%\n",
            "iter 10: loss 4.1496, time 451.45ms, mfu 0.90%\n",
            "iter 20: loss 3.9738, time 447.47ms, mfu 0.90%\n",
            "iter 30: loss 3.7213, time 456.86ms, mfu 0.90%\n",
            "iter 40: loss 3.5601, time 443.04ms, mfu 0.90%\n",
            "iter 50: loss 3.4790, time 451.82ms, mfu 0.90%\n",
            "iter 60: loss 3.3526, time 444.62ms, mfu 0.90%\n",
            "iter 70: loss 3.2454, time 453.67ms, mfu 0.90%\n",
            "iter 80: loss 3.1849, time 440.43ms, mfu 0.90%\n",
            "iter 90: loss 3.0632, time 466.57ms, mfu 0.90%\n",
            "iter 100: loss 3.0574, time 449.62ms, mfu 0.90%\n",
            "iter 110: loss 2.9014, time 451.91ms, mfu 0.90%\n",
            "iter 120: loss 2.9394, time 458.25ms, mfu 0.89%\n",
            "iter 130: loss 2.8772, time 441.42ms, mfu 0.90%\n",
            "iter 140: loss 2.8965, time 456.81ms, mfu 0.90%\n",
            "iter 150: loss 2.8053, time 457.02ms, mfu 0.89%\n",
            "iter 160: loss 2.7366, time 436.70ms, mfu 0.90%\n",
            "iter 170: loss 2.7671, time 440.87ms, mfu 0.90%\n",
            "iter 180: loss 2.7105, time 451.70ms, mfu 0.90%\n",
            "iter 190: loss 2.7241, time 452.00ms, mfu 0.90%\n",
            "step 200: train loss 2.6782, val loss 2.6897\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 200: loss 2.6696, time 2221.35ms, mfu 0.83%\n",
            "iter 210: loss 2.6724, time 453.83ms, mfu 0.83%\n",
            "iter 220: loss 2.6380, time 452.08ms, mfu 0.84%\n",
            "iter 230: loss 2.6557, time 476.93ms, mfu 0.84%\n",
            "iter 240: loss 2.6564, time 457.90ms, mfu 0.84%\n",
            "iter 250: loss 2.7093, time 457.66ms, mfu 0.85%\n",
            "iter 260: loss 2.4994, time 445.30ms, mfu 0.85%\n",
            "iter 270: loss 2.5836, time 464.26ms, mfu 0.86%\n",
            "iter 280: loss 2.5212, time 450.96ms, mfu 0.86%\n",
            "iter 290: loss 2.5110, time 442.06ms, mfu 0.87%\n",
            "iter 300: loss 2.5737, time 442.02ms, mfu 0.87%\n",
            "iter 310: loss 2.5722, time 472.72ms, mfu 0.87%\n",
            "iter 320: loss 2.5157, time 438.46ms, mfu 0.87%\n",
            "iter 330: loss 2.4949, time 446.24ms, mfu 0.88%\n",
            "iter 340: loss 2.4983, time 446.41ms, mfu 0.88%\n",
            "iter 350: loss 2.4582, time 442.93ms, mfu 0.88%\n",
            "iter 360: loss 2.4843, time 450.78ms, mfu 0.88%\n",
            "iter 370: loss 2.4764, time 455.02ms, mfu 0.89%\n",
            "iter 380: loss 2.4293, time 449.57ms, mfu 0.89%\n",
            "iter 390: loss 2.5210, time 462.90ms, mfu 0.89%\n",
            "step 400: train loss 2.3956, val loss 2.4049\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 400: loss 2.3776, time 2212.34ms, mfu 0.81%\n",
            "iter 410: loss 2.3817, time 449.51ms, mfu 0.82%\n",
            "iter 420: loss 2.3981, time 455.86ms, mfu 0.83%\n",
            "iter 430: loss 2.4210, time 444.87ms, mfu 0.84%\n",
            "iter 440: loss 2.3553, time 448.11ms, mfu 0.84%\n",
            "iter 450: loss 2.4236, time 444.08ms, mfu 0.85%\n",
            "iter 460: loss 2.3172, time 444.33ms, mfu 0.86%\n",
            "iter 470: loss 2.3535, time 448.77ms, mfu 0.86%\n",
            "iter 480: loss 2.4257, time 445.53ms, mfu 0.87%\n",
            "iter 490: loss 2.3468, time 438.55ms, mfu 0.87%\n",
            "iter 500: loss 2.3234, time 451.87ms, mfu 0.87%\n",
            "iter 510: loss 2.2709, time 457.10ms, mfu 0.87%\n",
            "iter 520: loss 2.2969, time 457.52ms, mfu 0.88%\n",
            "iter 530: loss 2.2766, time 438.31ms, mfu 0.88%\n",
            "iter 540: loss 2.3044, time 443.16ms, mfu 0.88%\n",
            "iter 550: loss 2.2696, time 463.21ms, mfu 0.88%\n",
            "iter 560: loss 2.2365, time 440.91ms, mfu 0.89%\n",
            "iter 570: loss 2.1996, time 442.84ms, mfu 0.89%\n",
            "iter 580: loss 2.1999, time 442.52ms, mfu 0.89%\n",
            "iter 590: loss 2.3149, time 439.38ms, mfu 0.89%\n",
            "step 600: train loss 2.1426, val loss 2.1737\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 600: loss 2.2082, time 2269.56ms, mfu 0.82%\n",
            "iter 610: loss 2.2123, time 442.74ms, mfu 0.83%\n",
            "iter 620: loss 2.1520, time 435.49ms, mfu 0.84%\n",
            "iter 630: loss 2.1616, time 449.82ms, mfu 0.85%\n",
            "iter 640: loss 2.0890, time 452.00ms, mfu 0.85%\n",
            "iter 650: loss 2.1232, time 455.36ms, mfu 0.86%\n",
            "iter 660: loss 2.1349, time 448.53ms, mfu 0.86%\n",
            "iter 670: loss 2.1694, time 451.58ms, mfu 0.86%\n",
            "iter 680: loss 2.0892, time 446.47ms, mfu 0.87%\n",
            "iter 690: loss 2.1255, time 456.06ms, mfu 0.87%\n",
            "iter 700: loss 2.0663, time 443.20ms, mfu 0.87%\n",
            "iter 710: loss 2.1295, time 442.79ms, mfu 0.88%\n",
            "iter 720: loss 2.0242, time 434.71ms, mfu 0.88%\n",
            "iter 730: loss 2.0645, time 439.82ms, mfu 0.89%\n",
            "iter 740: loss 2.0322, time 433.98ms, mfu 0.89%\n",
            "iter 750: loss 2.0985, time 455.65ms, mfu 0.89%\n",
            "iter 760: loss 1.9954, time 453.01ms, mfu 0.89%\n",
            "iter 770: loss 1.9581, time 441.35ms, mfu 0.89%\n",
            "iter 780: loss 1.9717, time 452.62ms, mfu 0.89%\n",
            "iter 790: loss 2.0534, time 482.29ms, mfu 0.89%\n",
            "step 800: train loss 1.8856, val loss 1.9804\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 800: loss 1.8945, time 2258.52ms, mfu 0.82%\n",
            "iter 810: loss 1.9212, time 443.65ms, mfu 0.83%\n",
            "iter 820: loss 1.9369, time 446.47ms, mfu 0.83%\n",
            "iter 830: loss 1.9258, time 455.78ms, mfu 0.84%\n",
            "iter 840: loss 1.9710, time 469.87ms, mfu 0.84%\n",
            "iter 850: loss 1.9185, time 445.61ms, mfu 0.85%\n",
            "iter 860: loss 1.9132, time 446.98ms, mfu 0.85%\n",
            "iter 870: loss 1.8020, time 441.46ms, mfu 0.86%\n",
            "iter 880: loss 1.8223, time 435.44ms, mfu 0.87%\n",
            "iter 890: loss 1.8797, time 445.22ms, mfu 0.87%\n",
            "iter 900: loss 1.9011, time 430.54ms, mfu 0.88%\n",
            "iter 910: loss 1.9024, time 435.15ms, mfu 0.88%\n",
            "iter 920: loss 1.6952, time 452.07ms, mfu 0.88%\n",
            "iter 930: loss 1.8009, time 441.96ms, mfu 0.89%\n",
            "iter 940: loss 1.7983, time 448.22ms, mfu 0.89%\n",
            "iter 950: loss 1.7456, time 451.71ms, mfu 0.89%\n",
            "iter 960: loss 1.8391, time 445.15ms, mfu 0.89%\n",
            "iter 970: loss 1.7489, time 443.59ms, mfu 0.89%\n",
            "iter 980: loss 1.9488, time 431.66ms, mfu 0.90%\n",
            "iter 990: loss 1.7398, time 432.15ms, mfu 0.90%\n",
            "step 1000: train loss 1.6741, val loss 1.8271\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1000: loss 1.7680, time 2298.21ms, mfu 0.83%\n",
            "iter 1010: loss 1.8865, time 438.17ms, mfu 0.84%\n",
            "iter 1020: loss 1.7399, time 439.24ms, mfu 0.85%\n",
            "iter 1030: loss 1.7047, time 462.70ms, mfu 0.85%\n",
            "iter 1040: loss 1.6867, time 447.46ms, mfu 0.85%\n",
            "iter 1050: loss 1.7380, time 440.68ms, mfu 0.86%\n",
            "iter 1060: loss 1.7793, time 441.91ms, mfu 0.87%\n",
            "iter 1070: loss 1.7187, time 443.87ms, mfu 0.87%\n",
            "iter 1080: loss 1.6388, time 452.91ms, mfu 0.87%\n",
            "iter 1090: loss 1.6482, time 445.09ms, mfu 0.88%\n",
            "iter 1100: loss 1.7354, time 442.90ms, mfu 0.88%\n",
            "iter 1110: loss 1.7557, time 442.04ms, mfu 0.88%\n",
            "iter 1120: loss 1.6314, time 438.69ms, mfu 0.89%\n",
            "iter 1130: loss 1.5717, time 446.35ms, mfu 0.89%\n",
            "iter 1140: loss 1.6835, time 444.54ms, mfu 0.89%\n",
            "iter 1150: loss 1.7175, time 440.53ms, mfu 0.89%\n",
            "iter 1160: loss 1.6925, time 463.65ms, mfu 0.89%\n",
            "iter 1170: loss 1.6179, time 442.95ms, mfu 0.89%\n",
            "iter 1180: loss 1.6704, time 442.46ms, mfu 0.90%\n",
            "iter 1190: loss 1.5981, time 451.33ms, mfu 0.90%\n",
            "step 1200: train loss 1.5365, val loss 1.7307\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1200: loss 1.6134, time 2221.51ms, mfu 0.82%\n",
            "iter 1210: loss 1.7189, time 471.55ms, mfu 0.83%\n",
            "iter 1220: loss 1.5560, time 438.76ms, mfu 0.84%\n",
            "iter 1230: loss 1.4972, time 463.86ms, mfu 0.84%\n",
            "iter 1240: loss 1.5702, time 446.98ms, mfu 0.85%\n",
            "iter 1250: loss 1.6317, time 440.59ms, mfu 0.85%\n",
            "iter 1260: loss 1.5294, time 431.73ms, mfu 0.86%\n",
            "iter 1270: loss 1.5937, time 463.84ms, mfu 0.86%\n",
            "iter 1280: loss 1.5793, time 438.63ms, mfu 0.87%\n",
            "iter 1290: loss 1.5810, time 445.21ms, mfu 0.87%\n",
            "iter 1300: loss 1.5978, time 450.08ms, mfu 0.88%\n",
            "iter 1310: loss 1.4555, time 447.34ms, mfu 0.88%\n",
            "iter 1320: loss 1.5472, time 453.10ms, mfu 0.88%\n",
            "iter 1330: loss 1.6512, time 450.85ms, mfu 0.88%\n",
            "iter 1340: loss 1.5545, time 444.54ms, mfu 0.88%\n",
            "iter 1350: loss 1.6413, time 459.59ms, mfu 0.88%\n",
            "iter 1360: loss 1.5649, time 447.82ms, mfu 0.89%\n",
            "iter 1370: loss 1.5456, time 435.76ms, mfu 0.89%\n",
            "iter 1380: loss 1.4924, time 449.47ms, mfu 0.89%\n",
            "iter 1390: loss 1.5944, time 440.68ms, mfu 0.89%\n",
            "step 1400: train loss 1.4606, val loss 1.6464\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1400: loss 1.4248, time 2267.54ms, mfu 0.82%\n",
            "iter 1410: loss 1.6022, time 438.19ms, mfu 0.83%\n",
            "iter 1420: loss 1.6430, time 450.12ms, mfu 0.84%\n",
            "iter 1430: loss 1.5097, time 436.66ms, mfu 0.85%\n",
            "iter 1440: loss 1.4670, time 440.54ms, mfu 0.85%\n",
            "iter 1450: loss 1.4596, time 439.91ms, mfu 0.86%\n",
            "iter 1460: loss 1.5985, time 441.58ms, mfu 0.87%\n",
            "iter 1470: loss 1.5432, time 441.87ms, mfu 0.87%\n",
            "iter 1480: loss 1.4518, time 445.78ms, mfu 0.87%\n",
            "iter 1490: loss 1.5839, time 455.20ms, mfu 0.88%\n",
            "iter 1500: loss 1.4355, time 445.47ms, mfu 0.88%\n",
            "iter 1510: loss 1.4763, time 450.29ms, mfu 0.88%\n",
            "iter 1520: loss 1.3787, time 437.46ms, mfu 0.89%\n",
            "iter 1530: loss 1.5083, time 443.30ms, mfu 0.89%\n",
            "iter 1540: loss 1.5308, time 444.20ms, mfu 0.89%\n",
            "iter 1550: loss 1.4874, time 467.14ms, mfu 0.89%\n",
            "iter 1560: loss 1.4803, time 447.82ms, mfu 0.89%\n",
            "iter 1570: loss 1.4541, time 445.93ms, mfu 0.89%\n",
            "iter 1580: loss 1.4560, time 447.65ms, mfu 0.89%\n",
            "iter 1590: loss 1.5081, time 469.06ms, mfu 0.89%\n",
            "step 1600: train loss 1.3689, val loss 1.5850\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1600: loss 1.5412, time 2296.30ms, mfu 0.82%\n",
            "iter 1610: loss 1.4481, time 463.29ms, mfu 0.82%\n",
            "iter 1620: loss 1.4112, time 460.74ms, mfu 0.83%\n",
            "iter 1630: loss 1.3714, time 446.36ms, mfu 0.84%\n",
            "iter 1640: loss 1.3828, time 478.15ms, mfu 0.84%\n",
            "iter 1650: loss 1.4303, time 456.49ms, mfu 0.84%\n",
            "iter 1660: loss 1.3155, time 504.01ms, mfu 0.84%\n",
            "iter 1670: loss 1.4845, time 454.32ms, mfu 0.84%\n",
            "iter 1680: loss 1.4261, time 505.93ms, mfu 0.84%\n",
            "iter 1690: loss 1.4072, time 518.36ms, mfu 0.83%\n",
            "iter 1700: loss 1.4678, time 501.29ms, mfu 0.83%\n",
            "iter 1710: loss 1.4278, time 505.35ms, mfu 0.83%\n",
            "iter 1720: loss 1.5027, time 448.39ms, mfu 0.83%\n",
            "iter 1730: loss 1.4283, time 453.49ms, mfu 0.84%\n",
            "iter 1740: loss 1.5391, time 511.81ms, mfu 0.84%\n",
            "iter 1750: loss 1.4799, time 443.24ms, mfu 0.84%\n",
            "iter 1760: loss 1.5054, time 443.77ms, mfu 0.85%\n",
            "iter 1770: loss 1.5974, time 438.79ms, mfu 0.86%\n",
            "iter 1780: loss 1.3930, time 438.38ms, mfu 0.86%\n",
            "iter 1790: loss 1.4039, time 454.32ms, mfu 0.87%\n",
            "step 1800: train loss 1.3255, val loss 1.5582\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "iter 1800: loss 1.3892, time 2260.04ms, mfu 0.80%\n",
            "iter 1810: loss 1.5698, time 442.02ms, mfu 0.81%\n",
            "iter 1820: loss 1.3361, time 456.92ms, mfu 0.82%\n",
            "iter 1830: loss 1.4739, time 479.19ms, mfu 0.82%\n",
            "iter 1840: loss 1.3369, time 455.73ms, mfu 0.83%\n",
            "iter 1850: loss 1.3374, time 437.85ms, mfu 0.84%\n",
            "iter 1860: loss 1.5427, time 436.79ms, mfu 0.84%\n",
            "iter 1870: loss 1.3693, time 460.25ms, mfu 0.85%\n",
            "iter 1880: loss 1.3347, time 439.87ms, mfu 0.86%\n",
            "iter 1890: loss 1.3840, time 447.60ms, mfu 0.86%\n",
            "iter 1900: loss 1.4261, time 443.42ms, mfu 0.87%\n",
            "iter 1910: loss 1.2566, time 439.70ms, mfu 0.87%\n",
            "iter 1920: loss 1.3475, time 440.07ms, mfu 0.88%\n",
            "iter 1930: loss 1.2429, time 444.32ms, mfu 0.88%\n",
            "iter 1940: loss 1.3351, time 451.16ms, mfu 0.88%\n",
            "iter 1950: loss 1.4351, time 448.38ms, mfu 0.88%\n",
            "iter 1960: loss 1.4089, time 454.18ms, mfu 0.88%\n",
            "iter 1970: loss 1.4283, time 448.11ms, mfu 0.89%\n",
            "iter 1980: loss 1.4129, time 474.32ms, mfu 0.88%\n",
            "iter 1990: loss 1.4100, time 456.88ms, mfu 0.88%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 12/32: b128_L6_H4_E256_BS8_MI2000_D20_s12 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS8_MI2000_D20_s12.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 12\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2264, val loss 4.2235\n",
            "iter 0: loss 4.2072, time 2444.17ms, mfu -100.00%\n",
            "iter 10: loss 4.1560, time 442.62ms, mfu 0.91%\n",
            "iter 20: loss 4.0079, time 497.48ms, mfu 0.90%\n",
            "iter 30: loss 3.7777, time 442.87ms, mfu 0.90%\n",
            "iter 40: loss 3.6094, time 451.42ms, mfu 0.90%\n",
            "iter 50: loss 3.5152, time 457.59ms, mfu 0.90%\n",
            "iter 60: loss 3.3969, time 453.24ms, mfu 0.90%\n",
            "iter 70: loss 3.3214, time 470.23ms, mfu 0.90%\n",
            "iter 80: loss 3.2543, time 480.77ms, mfu 0.89%\n",
            "iter 90: loss 3.1314, time 455.95ms, mfu 0.89%\n",
            "iter 100: loss 3.1207, time 465.49ms, mfu 0.89%\n",
            "iter 110: loss 2.9492, time 492.50ms, mfu 0.88%\n",
            "iter 120: loss 2.9978, time 451.38ms, mfu 0.88%\n",
            "iter 130: loss 2.9232, time 444.91ms, mfu 0.89%\n",
            "iter 140: loss 2.9372, time 441.15ms, mfu 0.89%\n",
            "iter 150: loss 2.8468, time 461.20ms, mfu 0.89%\n",
            "iter 160: loss 2.7854, time 453.38ms, mfu 0.89%\n",
            "iter 170: loss 2.8129, time 450.40ms, mfu 0.89%\n",
            "iter 180: loss 2.7480, time 456.03ms, mfu 0.89%\n",
            "iter 190: loss 2.7504, time 453.56ms, mfu 0.89%\n",
            "step 200: train loss 2.6942, val loss 2.7006\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 200: loss 2.7159, time 2230.29ms, mfu 0.82%\n",
            "iter 210: loss 2.7042, time 445.37ms, mfu 0.83%\n",
            "iter 220: loss 2.6670, time 444.78ms, mfu 0.84%\n",
            "iter 230: loss 2.6897, time 479.86ms, mfu 0.84%\n",
            "iter 240: loss 2.6932, time 462.74ms, mfu 0.84%\n",
            "iter 250: loss 2.7414, time 439.17ms, mfu 0.85%\n",
            "iter 260: loss 2.5239, time 455.06ms, mfu 0.85%\n",
            "iter 270: loss 2.6175, time 452.71ms, mfu 0.86%\n",
            "iter 280: loss 2.5393, time 458.30ms, mfu 0.86%\n",
            "iter 290: loss 2.5447, time 451.46ms, mfu 0.86%\n",
            "iter 300: loss 2.5989, time 462.02ms, mfu 0.86%\n",
            "iter 310: loss 2.6197, time 463.51ms, mfu 0.86%\n",
            "iter 320: loss 2.5521, time 483.94ms, mfu 0.86%\n",
            "iter 330: loss 2.5184, time 455.64ms, mfu 0.86%\n",
            "iter 340: loss 2.5360, time 450.27ms, mfu 0.87%\n",
            "iter 350: loss 2.5008, time 455.87ms, mfu 0.87%\n",
            "iter 360: loss 2.5214, time 473.86ms, mfu 0.87%\n",
            "iter 370: loss 2.5044, time 451.61ms, mfu 0.87%\n",
            "iter 380: loss 2.4672, time 470.35ms, mfu 0.87%\n",
            "iter 390: loss 2.5694, time 457.91ms, mfu 0.87%\n",
            "step 400: train loss 2.4401, val loss 2.4419\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 400: loss 2.4175, time 2198.68ms, mfu 0.80%\n",
            "iter 410: loss 2.4458, time 448.37ms, mfu 0.81%\n",
            "iter 420: loss 2.4367, time 454.56ms, mfu 0.82%\n",
            "iter 430: loss 2.4718, time 463.75ms, mfu 0.82%\n",
            "iter 440: loss 2.3835, time 457.57ms, mfu 0.83%\n",
            "iter 450: loss 2.4652, time 450.93ms, mfu 0.84%\n",
            "iter 460: loss 2.3655, time 448.62ms, mfu 0.84%\n",
            "iter 470: loss 2.4102, time 442.43ms, mfu 0.85%\n",
            "iter 480: loss 2.4870, time 445.50ms, mfu 0.86%\n",
            "iter 490: loss 2.4082, time 472.61ms, mfu 0.86%\n",
            "iter 500: loss 2.3999, time 461.41ms, mfu 0.86%\n",
            "iter 510: loss 2.3429, time 463.71ms, mfu 0.86%\n",
            "iter 520: loss 2.3548, time 452.32ms, mfu 0.86%\n",
            "iter 530: loss 2.3499, time 458.44ms, mfu 0.86%\n",
            "iter 540: loss 2.3753, time 473.85ms, mfu 0.86%\n",
            "iter 550: loss 2.3491, time 444.83ms, mfu 0.87%\n",
            "iter 560: loss 2.3126, time 457.09ms, mfu 0.87%\n",
            "iter 570: loss 2.2824, time 483.39ms, mfu 0.87%\n",
            "iter 580: loss 2.2710, time 445.60ms, mfu 0.87%\n",
            "iter 590: loss 2.3882, time 450.01ms, mfu 0.87%\n",
            "step 600: train loss 2.2069, val loss 2.2290\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 600: loss 2.2869, time 2232.97ms, mfu 0.80%\n",
            "iter 610: loss 2.2850, time 440.24ms, mfu 0.82%\n",
            "iter 620: loss 2.2576, time 471.63ms, mfu 0.82%\n",
            "iter 630: loss 2.2649, time 456.22ms, mfu 0.83%\n",
            "iter 640: loss 2.1985, time 460.52ms, mfu 0.83%\n",
            "iter 650: loss 2.2224, time 466.56ms, mfu 0.83%\n",
            "iter 660: loss 2.2238, time 439.25ms, mfu 0.84%\n",
            "iter 670: loss 2.2565, time 459.09ms, mfu 0.85%\n",
            "iter 680: loss 2.1903, time 456.45ms, mfu 0.85%\n",
            "iter 690: loss 2.2116, time 455.66ms, mfu 0.85%\n",
            "iter 700: loss 2.1815, time 461.61ms, mfu 0.86%\n",
            "iter 710: loss 2.2238, time 448.80ms, mfu 0.86%\n",
            "iter 720: loss 2.1481, time 480.28ms, mfu 0.86%\n",
            "iter 730: loss 2.1715, time 448.01ms, mfu 0.86%\n",
            "iter 740: loss 2.1338, time 448.76ms, mfu 0.87%\n",
            "iter 750: loss 2.1954, time 475.09ms, mfu 0.87%\n",
            "iter 760: loss 2.1043, time 460.35ms, mfu 0.87%\n",
            "iter 770: loss 2.0815, time 441.71ms, mfu 0.87%\n",
            "iter 780: loss 2.0924, time 461.44ms, mfu 0.87%\n",
            "iter 790: loss 2.1853, time 461.31ms, mfu 0.87%\n",
            "step 800: train loss 1.9788, val loss 2.0500\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 800: loss 2.0130, time 2279.16ms, mfu 0.80%\n",
            "iter 810: loss 2.0425, time 492.27ms, mfu 0.80%\n",
            "iter 820: loss 2.0660, time 463.74ms, mfu 0.81%\n",
            "iter 830: loss 2.0372, time 452.21ms, mfu 0.82%\n",
            "iter 840: loss 2.0686, time 458.97ms, mfu 0.83%\n",
            "iter 850: loss 2.0374, time 445.82ms, mfu 0.83%\n",
            "iter 860: loss 2.0227, time 456.05ms, mfu 0.84%\n",
            "iter 870: loss 1.9256, time 462.31ms, mfu 0.84%\n",
            "iter 880: loss 1.9301, time 462.84ms, mfu 0.85%\n",
            "iter 890: loss 1.9761, time 485.27ms, mfu 0.84%\n",
            "iter 900: loss 2.0118, time 446.71ms, mfu 0.85%\n",
            "iter 910: loss 2.0312, time 444.72ms, mfu 0.86%\n",
            "iter 920: loss 1.8687, time 459.10ms, mfu 0.86%\n",
            "iter 930: loss 1.9289, time 452.65ms, mfu 0.86%\n",
            "iter 940: loss 1.9406, time 457.51ms, mfu 0.86%\n",
            "iter 950: loss 1.8848, time 460.91ms, mfu 0.87%\n",
            "iter 960: loss 1.9616, time 465.44ms, mfu 0.87%\n",
            "iter 970: loss 1.8686, time 446.72ms, mfu 0.87%\n",
            "iter 980: loss 2.0429, time 453.77ms, mfu 0.87%\n",
            "iter 990: loss 1.8369, time 453.33ms, mfu 0.87%\n",
            "step 1000: train loss 1.7860, val loss 1.9060\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1000: loss 1.9120, time 2278.28ms, mfu 0.80%\n",
            "iter 1010: loss 2.0178, time 459.51ms, mfu 0.81%\n",
            "iter 1020: loss 1.8531, time 448.55ms, mfu 0.82%\n",
            "iter 1030: loss 1.8295, time 481.47ms, mfu 0.82%\n",
            "iter 1040: loss 1.8186, time 456.34ms, mfu 0.83%\n",
            "iter 1050: loss 1.8760, time 452.60ms, mfu 0.84%\n",
            "iter 1060: loss 1.9338, time 473.98ms, mfu 0.84%\n",
            "iter 1070: loss 1.8441, time 461.50ms, mfu 0.84%\n",
            "iter 1080: loss 1.8004, time 443.78ms, mfu 0.85%\n",
            "iter 1090: loss 1.8009, time 461.72ms, mfu 0.85%\n",
            "iter 1100: loss 1.8625, time 443.50ms, mfu 0.86%\n",
            "iter 1110: loss 1.8686, time 440.40ms, mfu 0.86%\n",
            "iter 1120: loss 1.7821, time 451.68ms, mfu 0.87%\n",
            "iter 1130: loss 1.7225, time 452.42ms, mfu 0.87%\n",
            "iter 1140: loss 1.8192, time 463.19ms, mfu 0.87%\n",
            "iter 1150: loss 1.8325, time 450.71ms, mfu 0.87%\n",
            "iter 1160: loss 1.7871, time 448.78ms, mfu 0.87%\n",
            "iter 1170: loss 1.7224, time 486.61ms, mfu 0.87%\n",
            "iter 1180: loss 1.8241, time 447.70ms, mfu 0.87%\n",
            "iter 1190: loss 1.7140, time 460.12ms, mfu 0.87%\n",
            "step 1200: train loss 1.6347, val loss 1.8168\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1200: loss 1.7075, time 2250.89ms, mfu 0.80%\n",
            "iter 1210: loss 1.8533, time 449.22ms, mfu 0.81%\n",
            "iter 1220: loss 1.6851, time 468.74ms, mfu 0.82%\n",
            "iter 1230: loss 1.6245, time 439.70ms, mfu 0.83%\n",
            "iter 1240: loss 1.6945, time 442.68ms, mfu 0.84%\n",
            "iter 1250: loss 1.7384, time 454.63ms, mfu 0.84%\n",
            "iter 1260: loss 1.6393, time 450.79ms, mfu 0.85%\n",
            "iter 1270: loss 1.7456, time 464.08ms, mfu 0.85%\n",
            "iter 1280: loss 1.7229, time 453.11ms, mfu 0.85%\n",
            "iter 1290: loss 1.7229, time 453.56ms, mfu 0.86%\n",
            "iter 1300: loss 1.6962, time 459.33ms, mfu 0.86%\n",
            "iter 1310: loss 1.5447, time 448.82ms, mfu 0.86%\n",
            "iter 1320: loss 1.6865, time 448.17ms, mfu 0.87%\n",
            "iter 1330: loss 1.7413, time 453.52ms, mfu 0.87%\n",
            "iter 1340: loss 1.6844, time 449.72ms, mfu 0.87%\n",
            "iter 1350: loss 1.7566, time 471.86ms, mfu 0.87%\n",
            "iter 1360: loss 1.6912, time 479.64ms, mfu 0.87%\n",
            "iter 1370: loss 1.6786, time 462.18ms, mfu 0.87%\n",
            "iter 1380: loss 1.6037, time 491.70ms, mfu 0.86%\n",
            "iter 1390: loss 1.7465, time 476.96ms, mfu 0.86%\n",
            "step 1400: train loss 1.5565, val loss 1.7339\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1400: loss 1.5679, time 2295.98ms, mfu 0.79%\n",
            "iter 1410: loss 1.7062, time 450.97ms, mfu 0.80%\n",
            "iter 1420: loss 1.7689, time 462.71ms, mfu 0.81%\n",
            "iter 1430: loss 1.6355, time 450.29ms, mfu 0.82%\n",
            "iter 1440: loss 1.5909, time 465.86ms, mfu 0.82%\n",
            "iter 1450: loss 1.5714, time 452.35ms, mfu 0.83%\n",
            "iter 1460: loss 1.7031, time 446.81ms, mfu 0.84%\n",
            "iter 1470: loss 1.6564, time 448.16ms, mfu 0.85%\n",
            "iter 1480: loss 1.5578, time 457.32ms, mfu 0.85%\n",
            "iter 1490: loss 1.7026, time 450.48ms, mfu 0.85%\n",
            "iter 1500: loss 1.5402, time 441.74ms, mfu 0.86%\n",
            "iter 1510: loss 1.5895, time 470.96ms, mfu 0.86%\n",
            "iter 1520: loss 1.5060, time 476.74ms, mfu 0.86%\n",
            "iter 1530: loss 1.6291, time 442.90ms, mfu 0.86%\n",
            "iter 1540: loss 1.6327, time 462.41ms, mfu 0.87%\n",
            "iter 1550: loss 1.5925, time 451.44ms, mfu 0.87%\n",
            "iter 1560: loss 1.5824, time 476.90ms, mfu 0.87%\n",
            "iter 1570: loss 1.5903, time 462.42ms, mfu 0.87%\n",
            "iter 1580: loss 1.5655, time 458.66ms, mfu 0.87%\n",
            "iter 1590: loss 1.6163, time 454.77ms, mfu 0.87%\n",
            "step 1600: train loss 1.4600, val loss 1.6691\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1600: loss 1.6753, time 2269.83ms, mfu 0.80%\n",
            "iter 1610: loss 1.5393, time 466.20ms, mfu 0.81%\n",
            "iter 1620: loss 1.5260, time 445.71ms, mfu 0.82%\n",
            "iter 1630: loss 1.4725, time 481.13ms, mfu 0.82%\n",
            "iter 1640: loss 1.5193, time 455.73ms, mfu 0.83%\n",
            "iter 1650: loss 1.5604, time 463.66ms, mfu 0.83%\n",
            "iter 1660: loss 1.4391, time 477.84ms, mfu 0.83%\n",
            "iter 1670: loss 1.5794, time 446.26ms, mfu 0.84%\n",
            "iter 1680: loss 1.5470, time 449.47ms, mfu 0.85%\n",
            "iter 1690: loss 1.4931, time 472.89ms, mfu 0.85%\n",
            "iter 1700: loss 1.5706, time 462.69ms, mfu 0.85%\n",
            "iter 1710: loss 1.5780, time 452.26ms, mfu 0.85%\n",
            "iter 1720: loss 1.6006, time 444.56ms, mfu 0.86%\n",
            "iter 1730: loss 1.5256, time 449.10ms, mfu 0.86%\n",
            "iter 1740: loss 1.6322, time 464.28ms, mfu 0.86%\n",
            "iter 1750: loss 1.5869, time 441.52ms, mfu 0.87%\n",
            "iter 1760: loss 1.6220, time 453.29ms, mfu 0.87%\n",
            "iter 1770: loss 1.7243, time 490.79ms, mfu 0.87%\n",
            "iter 1780: loss 1.5146, time 452.12ms, mfu 0.87%\n",
            "iter 1790: loss 1.5052, time 454.36ms, mfu 0.87%\n",
            "step 1800: train loss 1.4167, val loss 1.6242\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "iter 1800: loss 1.4956, time 2251.56ms, mfu 0.80%\n",
            "iter 1810: loss 1.6439, time 463.74ms, mfu 0.81%\n",
            "iter 1820: loss 1.4490, time 507.05ms, mfu 0.81%\n",
            "iter 1830: loss 1.6170, time 458.93ms, mfu 0.82%\n",
            "iter 1840: loss 1.3995, time 449.91ms, mfu 0.82%\n",
            "iter 1850: loss 1.4608, time 449.00ms, mfu 0.83%\n",
            "iter 1860: loss 1.6267, time 463.00ms, mfu 0.84%\n",
            "iter 1870: loss 1.4669, time 464.56ms, mfu 0.84%\n",
            "iter 1880: loss 1.4306, time 452.99ms, mfu 0.84%\n",
            "iter 1890: loss 1.4967, time 470.04ms, mfu 0.85%\n",
            "iter 1900: loss 1.5511, time 469.29ms, mfu 0.85%\n",
            "iter 1910: loss 1.3713, time 446.40ms, mfu 0.85%\n",
            "iter 1920: loss 1.4411, time 449.80ms, mfu 0.86%\n",
            "iter 1930: loss 1.3746, time 459.67ms, mfu 0.86%\n",
            "iter 1940: loss 1.4195, time 454.70ms, mfu 0.86%\n",
            "iter 1950: loss 1.5452, time 466.01ms, mfu 0.86%\n",
            "iter 1960: loss 1.5006, time 462.72ms, mfu 0.86%\n",
            "iter 1970: loss 1.5275, time 456.27ms, mfu 0.87%\n",
            "iter 1980: loss 1.5255, time 455.68ms, mfu 0.87%\n",
            "iter 1990: loss 1.5234, time 449.46ms, mfu 0.87%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 13/32: b128_L6_H4_E256_BS16_MI1000_D10_s13 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS16_MI1000_D10_s13.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D10_s13\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 13\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2263, val loss 4.2232\n",
            "iter 0: loss 4.2267, time 2676.27ms, mfu -100.00%\n",
            "iter 10: loss 4.1546, time 486.80ms, mfu 1.66%\n",
            "iter 20: loss 3.9787, time 468.49ms, mfu 1.67%\n",
            "iter 30: loss 3.7674, time 469.80ms, mfu 1.67%\n",
            "iter 40: loss 3.5797, time 478.48ms, mfu 1.67%\n",
            "iter 50: loss 3.4405, time 467.60ms, mfu 1.68%\n",
            "iter 60: loss 3.4041, time 481.06ms, mfu 1.68%\n",
            "iter 70: loss 3.2822, time 481.22ms, mfu 1.68%\n",
            "iter 80: loss 3.1613, time 492.77ms, mfu 1.68%\n",
            "iter 90: loss 3.1011, time 474.03ms, mfu 1.68%\n",
            "iter 100: loss 2.9855, time 477.40ms, mfu 1.68%\n",
            "iter 110: loss 2.9992, time 471.87ms, mfu 1.68%\n",
            "iter 120: loss 2.8586, time 482.69ms, mfu 1.68%\n",
            "iter 130: loss 2.8659, time 484.71ms, mfu 1.68%\n",
            "iter 140: loss 2.8396, time 484.00ms, mfu 1.68%\n",
            "iter 150: loss 2.7873, time 485.38ms, mfu 1.68%\n",
            "iter 160: loss 2.7791, time 482.81ms, mfu 1.68%\n",
            "iter 170: loss 2.7703, time 474.17ms, mfu 1.68%\n",
            "iter 180: loss 2.7302, time 486.42ms, mfu 1.68%\n",
            "iter 190: loss 2.7479, time 469.40ms, mfu 1.68%\n",
            "step 200: train loss 2.6686, val loss 2.6766\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 200: loss 2.7000, time 2395.57ms, mfu 1.55%\n",
            "iter 210: loss 2.6758, time 466.66ms, mfu 1.57%\n",
            "iter 220: loss 2.6143, time 462.80ms, mfu 1.59%\n",
            "iter 230: loss 2.6368, time 459.82ms, mfu 1.60%\n",
            "iter 240: loss 2.6663, time 502.27ms, mfu 1.60%\n",
            "iter 250: loss 2.5503, time 464.67ms, mfu 1.62%\n",
            "iter 260: loss 2.5817, time 455.28ms, mfu 1.63%\n",
            "iter 270: loss 2.5190, time 461.92ms, mfu 1.64%\n",
            "iter 280: loss 2.5305, time 477.54ms, mfu 1.65%\n",
            "iter 290: loss 2.5602, time 479.67ms, mfu 1.65%\n",
            "iter 300: loss 2.5009, time 476.69ms, mfu 1.66%\n",
            "iter 310: loss 2.5025, time 477.80ms, mfu 1.66%\n",
            "iter 320: loss 2.4815, time 481.17ms, mfu 1.66%\n",
            "iter 330: loss 2.4600, time 488.70ms, mfu 1.66%\n",
            "iter 340: loss 2.4350, time 470.80ms, mfu 1.67%\n",
            "iter 350: loss 2.5069, time 457.84ms, mfu 1.68%\n",
            "iter 360: loss 2.4161, time 462.26ms, mfu 1.68%\n",
            "iter 370: loss 2.4904, time 489.23ms, mfu 1.68%\n",
            "iter 380: loss 2.4203, time 458.97ms, mfu 1.69%\n",
            "iter 390: loss 2.4206, time 463.06ms, mfu 1.69%\n",
            "step 400: train loss 2.3513, val loss 2.3618\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 400: loss 2.4398, time 2394.93ms, mfu 1.56%\n",
            "iter 410: loss 2.3291, time 462.07ms, mfu 1.58%\n",
            "iter 420: loss 2.3725, time 492.57ms, mfu 1.58%\n",
            "iter 430: loss 2.4240, time 478.55ms, mfu 1.59%\n",
            "iter 440: loss 2.4096, time 475.03ms, mfu 1.61%\n",
            "iter 450: loss 2.3286, time 463.26ms, mfu 1.62%\n",
            "iter 460: loss 2.3909, time 461.45ms, mfu 1.63%\n",
            "iter 470: loss 2.2986, time 506.66ms, mfu 1.63%\n",
            "iter 480: loss 2.2574, time 465.73ms, mfu 1.64%\n",
            "iter 490: loss 2.2609, time 467.65ms, mfu 1.65%\n",
            "iter 500: loss 2.2611, time 482.10ms, mfu 1.65%\n",
            "iter 510: loss 2.2538, time 468.02ms, mfu 1.66%\n",
            "iter 520: loss 2.2724, time 471.48ms, mfu 1.66%\n",
            "iter 530: loss 2.3133, time 470.93ms, mfu 1.67%\n",
            "iter 540: loss 2.1617, time 476.88ms, mfu 1.67%\n",
            "iter 550: loss 2.2177, time 462.48ms, mfu 1.68%\n",
            "iter 560: loss 2.2303, time 462.08ms, mfu 1.69%\n",
            "iter 570: loss 2.2137, time 500.77ms, mfu 1.68%\n",
            "iter 580: loss 2.2165, time 490.08ms, mfu 1.68%\n",
            "iter 590: loss 2.1340, time 466.51ms, mfu 1.68%\n",
            "step 600: train loss 2.0885, val loss 2.1376\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 600: loss 2.0873, time 2421.59ms, mfu 1.55%\n",
            "iter 610: loss 2.1139, time 493.23ms, mfu 1.56%\n",
            "iter 620: loss 2.1020, time 462.99ms, mfu 1.58%\n",
            "iter 630: loss 2.1557, time 470.77ms, mfu 1.59%\n",
            "iter 640: loss 2.0661, time 469.11ms, mfu 1.60%\n",
            "iter 650: loss 2.0688, time 463.65ms, mfu 1.62%\n",
            "iter 660: loss 2.0586, time 475.11ms, mfu 1.63%\n",
            "iter 670: loss 2.0692, time 517.16ms, mfu 1.62%\n",
            "iter 680: loss 2.0529, time 484.74ms, mfu 1.62%\n",
            "iter 690: loss 2.0302, time 463.53ms, mfu 1.64%\n",
            "iter 700: loss 1.9854, time 458.70ms, mfu 1.65%\n",
            "iter 710: loss 2.0479, time 473.98ms, mfu 1.65%\n",
            "iter 720: loss 2.0259, time 477.64ms, mfu 1.66%\n",
            "iter 730: loss 1.9740, time 500.85ms, mfu 1.65%\n",
            "iter 740: loss 2.0371, time 457.42ms, mfu 1.67%\n",
            "iter 750: loss 1.9871, time 465.94ms, mfu 1.67%\n",
            "iter 760: loss 1.9202, time 481.94ms, mfu 1.67%\n",
            "iter 770: loss 1.9235, time 482.04ms, mfu 1.67%\n",
            "iter 780: loss 1.8950, time 467.20ms, mfu 1.68%\n",
            "iter 790: loss 1.9566, time 466.04ms, mfu 1.68%\n",
            "step 800: train loss 1.8025, val loss 1.9207\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 800: loss 1.8576, time 2398.33ms, mfu 1.55%\n",
            "iter 810: loss 1.8400, time 474.47ms, mfu 1.57%\n",
            "iter 820: loss 1.8651, time 476.57ms, mfu 1.58%\n",
            "iter 830: loss 1.8764, time 464.16ms, mfu 1.59%\n",
            "iter 840: loss 1.8801, time 481.18ms, mfu 1.60%\n",
            "iter 850: loss 1.8356, time 457.84ms, mfu 1.62%\n",
            "iter 860: loss 1.9230, time 470.18ms, mfu 1.63%\n",
            "iter 870: loss 1.8502, time 481.80ms, mfu 1.63%\n",
            "iter 880: loss 1.6966, time 478.28ms, mfu 1.64%\n",
            "iter 890: loss 1.7565, time 492.85ms, mfu 1.64%\n",
            "iter 900: loss 1.7987, time 465.93ms, mfu 1.65%\n",
            "iter 910: loss 1.7961, time 459.69ms, mfu 1.66%\n",
            "iter 920: loss 1.7742, time 470.98ms, mfu 1.67%\n",
            "iter 930: loss 1.7420, time 468.38ms, mfu 1.67%\n",
            "iter 940: loss 1.7442, time 463.85ms, mfu 1.68%\n",
            "iter 950: loss 1.8317, time 468.49ms, mfu 1.68%\n",
            "iter 960: loss 1.7966, time 473.75ms, mfu 1.69%\n",
            "iter 970: loss 1.6617, time 496.99ms, mfu 1.68%\n",
            "iter 980: loss 1.7678, time 468.56ms, mfu 1.68%\n",
            "iter 990: loss 1.7182, time 461.44ms, mfu 1.69%\n",
            "step 1000: train loss 1.5965, val loss 1.7711\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D10_s13\n",
            "iter 1000: loss 1.7266, time 2454.91ms, mfu 1.56%\n",
            "\n",
            "=== Experiment 14/32: b128_L6_H4_E256_BS16_MI1000_D20_s14 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS16_MI1000_D20_s14.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D20_s14\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 14\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2263, val loss 4.2232\n",
            "iter 0: loss 4.2219, time 2671.82ms, mfu -100.00%\n",
            "iter 10: loss 4.1623, time 481.96ms, mfu 1.68%\n",
            "iter 20: loss 4.0094, time 466.72ms, mfu 1.68%\n",
            "iter 30: loss 3.8146, time 499.61ms, mfu 1.68%\n",
            "iter 40: loss 3.6218, time 477.05ms, mfu 1.68%\n",
            "iter 50: loss 3.4769, time 461.14ms, mfu 1.69%\n",
            "iter 60: loss 3.4459, time 483.66ms, mfu 1.68%\n",
            "iter 70: loss 3.3474, time 474.65ms, mfu 1.69%\n",
            "iter 80: loss 3.2405, time 486.70ms, mfu 1.68%\n",
            "iter 90: loss 3.1666, time 461.71ms, mfu 1.69%\n",
            "iter 100: loss 3.0472, time 465.95ms, mfu 1.69%\n",
            "iter 110: loss 3.0540, time 473.42ms, mfu 1.70%\n",
            "iter 120: loss 2.9040, time 466.60ms, mfu 1.70%\n",
            "iter 130: loss 2.9117, time 480.77ms, mfu 1.70%\n",
            "iter 140: loss 2.8838, time 474.62ms, mfu 1.70%\n",
            "iter 150: loss 2.8376, time 477.22ms, mfu 1.70%\n",
            "iter 160: loss 2.8232, time 479.73ms, mfu 1.70%\n",
            "iter 170: loss 2.8222, time 503.95ms, mfu 1.69%\n",
            "iter 180: loss 2.7678, time 497.02ms, mfu 1.68%\n",
            "iter 190: loss 2.7833, time 479.31ms, mfu 1.68%\n",
            "step 200: train loss 2.6862, val loss 2.6895\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 200: loss 2.7337, time 2389.47ms, mfu 1.55%\n",
            "iter 210: loss 2.7024, time 474.50ms, mfu 1.56%\n",
            "iter 220: loss 2.6539, time 506.10ms, mfu 1.57%\n",
            "iter 230: loss 2.6691, time 494.31ms, mfu 1.57%\n",
            "iter 240: loss 2.7013, time 486.37ms, mfu 1.58%\n",
            "iter 250: loss 2.5820, time 466.95ms, mfu 1.60%\n",
            "iter 260: loss 2.6155, time 498.74ms, mfu 1.60%\n",
            "iter 270: loss 2.5454, time 465.92ms, mfu 1.61%\n",
            "iter 280: loss 2.5733, time 479.10ms, mfu 1.62%\n",
            "iter 290: loss 2.5870, time 472.17ms, mfu 1.63%\n",
            "iter 300: loss 2.5368, time 486.76ms, mfu 1.63%\n",
            "iter 310: loss 2.5302, time 481.29ms, mfu 1.64%\n",
            "iter 320: loss 2.5256, time 479.81ms, mfu 1.64%\n",
            "iter 330: loss 2.4889, time 469.14ms, mfu 1.65%\n",
            "iter 340: loss 2.4677, time 455.01ms, mfu 1.66%\n",
            "iter 350: loss 2.5359, time 466.03ms, mfu 1.67%\n",
            "iter 360: loss 2.4499, time 459.64ms, mfu 1.68%\n",
            "iter 370: loss 2.5258, time 468.51ms, mfu 1.68%\n",
            "iter 380: loss 2.4674, time 464.90ms, mfu 1.69%\n",
            "iter 390: loss 2.4647, time 454.72ms, mfu 1.70%\n",
            "step 400: train loss 2.3989, val loss 2.4022\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 400: loss 2.4786, time 2380.18ms, mfu 1.56%\n",
            "iter 410: loss 2.3865, time 464.82ms, mfu 1.58%\n",
            "iter 420: loss 2.4247, time 459.77ms, mfu 1.60%\n",
            "iter 430: loss 2.4575, time 475.83ms, mfu 1.61%\n",
            "iter 440: loss 2.4606, time 456.04ms, mfu 1.62%\n",
            "iter 450: loss 2.3862, time 517.18ms, mfu 1.62%\n",
            "iter 460: loss 2.4415, time 466.33ms, mfu 1.63%\n",
            "iter 470: loss 2.3460, time 507.43ms, mfu 1.63%\n",
            "iter 480: loss 2.3064, time 488.33ms, mfu 1.63%\n",
            "iter 490: loss 2.3260, time 492.90ms, mfu 1.63%\n",
            "iter 500: loss 2.3241, time 462.48ms, mfu 1.64%\n",
            "iter 510: loss 2.3235, time 463.99ms, mfu 1.65%\n",
            "iter 520: loss 2.3294, time 474.05ms, mfu 1.66%\n",
            "iter 530: loss 2.3641, time 475.99ms, mfu 1.66%\n",
            "iter 540: loss 2.2198, time 508.76ms, mfu 1.65%\n",
            "iter 550: loss 2.2935, time 458.41ms, mfu 1.67%\n",
            "iter 560: loss 2.2900, time 513.88ms, mfu 1.66%\n",
            "iter 570: loss 2.2831, time 459.39ms, mfu 1.67%\n",
            "iter 580: loss 2.2861, time 461.06ms, mfu 1.68%\n",
            "iter 590: loss 2.2208, time 472.97ms, mfu 1.68%\n",
            "step 600: train loss 2.1360, val loss 2.1720\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 600: loss 2.1688, time 2392.34ms, mfu 1.54%\n",
            "iter 610: loss 2.1968, time 477.84ms, mfu 1.56%\n",
            "iter 620: loss 2.1818, time 474.46ms, mfu 1.57%\n",
            "iter 630: loss 2.2297, time 464.41ms, mfu 1.59%\n",
            "iter 640: loss 2.1543, time 505.23ms, mfu 1.59%\n",
            "iter 650: loss 2.1389, time 479.61ms, mfu 1.60%\n",
            "iter 660: loss 2.1441, time 501.33ms, mfu 1.60%\n",
            "iter 670: loss 2.1432, time 468.88ms, mfu 1.61%\n",
            "iter 680: loss 2.1419, time 484.56ms, mfu 1.62%\n",
            "iter 690: loss 2.1247, time 459.04ms, mfu 1.63%\n",
            "iter 700: loss 2.0919, time 497.58ms, mfu 1.63%\n",
            "iter 710: loss 2.1401, time 478.66ms, mfu 1.64%\n",
            "iter 720: loss 2.1227, time 473.89ms, mfu 1.65%\n",
            "iter 730: loss 2.0751, time 510.43ms, mfu 1.64%\n",
            "iter 740: loss 2.1145, time 468.37ms, mfu 1.65%\n",
            "iter 750: loss 2.0692, time 476.62ms, mfu 1.65%\n",
            "iter 760: loss 2.0320, time 464.13ms, mfu 1.66%\n",
            "iter 770: loss 2.0236, time 464.07ms, mfu 1.67%\n",
            "iter 780: loss 1.9931, time 464.68ms, mfu 1.68%\n",
            "iter 790: loss 2.0531, time 467.60ms, mfu 1.68%\n",
            "step 800: train loss 1.8909, val loss 1.9860\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 800: loss 1.9785, time 2379.96ms, mfu 1.55%\n",
            "iter 810: loss 1.9719, time 455.77ms, mfu 1.57%\n",
            "iter 820: loss 2.0035, time 478.22ms, mfu 1.58%\n",
            "iter 830: loss 1.9947, time 456.14ms, mfu 1.60%\n",
            "iter 840: loss 1.9901, time 464.51ms, mfu 1.62%\n",
            "iter 850: loss 1.9451, time 453.06ms, mfu 1.63%\n",
            "iter 860: loss 2.0219, time 481.93ms, mfu 1.64%\n",
            "iter 870: loss 1.9440, time 466.74ms, mfu 1.65%\n",
            "iter 880: loss 1.8306, time 469.51ms, mfu 1.65%\n",
            "iter 890: loss 1.8781, time 471.95ms, mfu 1.66%\n",
            "iter 900: loss 1.9330, time 456.10ms, mfu 1.67%\n",
            "iter 910: loss 1.9119, time 469.55ms, mfu 1.68%\n",
            "iter 920: loss 1.8787, time 471.87ms, mfu 1.68%\n",
            "iter 930: loss 1.8628, time 468.92ms, mfu 1.68%\n",
            "iter 940: loss 1.8527, time 456.78ms, mfu 1.69%\n",
            "iter 950: loss 1.9465, time 470.87ms, mfu 1.70%\n",
            "iter 960: loss 1.9038, time 462.46ms, mfu 1.70%\n",
            "iter 970: loss 1.8004, time 462.36ms, mfu 1.71%\n",
            "iter 980: loss 1.9052, time 498.35ms, mfu 1.70%\n",
            "iter 990: loss 1.8371, time 480.77ms, mfu 1.70%\n",
            "step 1000: train loss 1.6972, val loss 1.8593\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI1000_D20_s14\n",
            "iter 1000: loss 1.8504, time 2376.40ms, mfu 1.56%\n",
            "\n",
            "=== Experiment 15/32: b128_L6_H4_E256_BS16_MI2000_D10_s15 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS16_MI2000_D10_s15.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 15\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2263, val loss 4.2232\n",
            "iter 0: loss 4.2267, time 2622.35ms, mfu -100.00%\n",
            "iter 10: loss 4.1546, time 459.02ms, mfu 1.76%\n",
            "iter 20: loss 3.9787, time 460.84ms, mfu 1.76%\n",
            "iter 30: loss 3.7674, time 487.35ms, mfu 1.75%\n",
            "iter 40: loss 3.5797, time 469.09ms, mfu 1.75%\n",
            "iter 50: loss 3.4405, time 486.73ms, mfu 1.74%\n",
            "iter 60: loss 3.4041, time 461.59ms, mfu 1.74%\n",
            "iter 70: loss 3.2822, time 473.11ms, mfu 1.74%\n",
            "iter 80: loss 3.1613, time 463.66ms, mfu 1.74%\n",
            "iter 90: loss 3.1011, time 466.06ms, mfu 1.74%\n",
            "iter 100: loss 2.9855, time 469.90ms, mfu 1.74%\n",
            "iter 110: loss 2.9992, time 457.07ms, mfu 1.74%\n",
            "iter 120: loss 2.8586, time 493.11ms, mfu 1.73%\n",
            "iter 130: loss 2.8659, time 480.36ms, mfu 1.72%\n",
            "iter 140: loss 2.8396, time 478.71ms, mfu 1.72%\n",
            "iter 150: loss 2.7873, time 457.82ms, mfu 1.73%\n",
            "iter 160: loss 2.7791, time 479.13ms, mfu 1.72%\n",
            "iter 170: loss 2.7703, time 486.40ms, mfu 1.72%\n",
            "iter 180: loss 2.7302, time 464.52ms, mfu 1.72%\n",
            "iter 190: loss 2.7479, time 463.15ms, mfu 1.72%\n",
            "step 200: train loss 2.6686, val loss 2.6766\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 200: loss 2.7000, time 2402.25ms, mfu 1.58%\n",
            "iter 210: loss 2.6758, time 457.12ms, mfu 1.60%\n",
            "iter 220: loss 2.6143, time 480.20ms, mfu 1.61%\n",
            "iter 230: loss 2.6368, time 492.83ms, mfu 1.61%\n",
            "iter 240: loss 2.6663, time 510.94ms, mfu 1.61%\n",
            "iter 250: loss 2.5503, time 458.40ms, mfu 1.62%\n",
            "iter 260: loss 2.5817, time 456.37ms, mfu 1.64%\n",
            "iter 270: loss 2.5190, time 470.48ms, mfu 1.65%\n",
            "iter 280: loss 2.5305, time 467.91ms, mfu 1.66%\n",
            "iter 290: loss 2.5602, time 474.47ms, mfu 1.66%\n",
            "iter 300: loss 2.5009, time 465.93ms, mfu 1.67%\n",
            "iter 310: loss 2.5025, time 480.84ms, mfu 1.67%\n",
            "iter 320: loss 2.4815, time 487.25ms, mfu 1.67%\n",
            "iter 330: loss 2.4600, time 457.15ms, mfu 1.68%\n",
            "iter 340: loss 2.4350, time 457.52ms, mfu 1.69%\n",
            "iter 350: loss 2.5069, time 460.82ms, mfu 1.69%\n",
            "iter 360: loss 2.4161, time 464.87ms, mfu 1.70%\n",
            "iter 370: loss 2.4904, time 471.43ms, mfu 1.70%\n",
            "iter 380: loss 2.4203, time 498.53ms, mfu 1.69%\n",
            "iter 390: loss 2.4206, time 463.22ms, mfu 1.70%\n",
            "step 400: train loss 2.3513, val loss 2.3618\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 400: loss 2.4398, time 2393.14ms, mfu 1.56%\n",
            "iter 410: loss 2.3291, time 474.82ms, mfu 1.58%\n",
            "iter 420: loss 2.3725, time 475.48ms, mfu 1.59%\n",
            "iter 430: loss 2.4240, time 475.13ms, mfu 1.60%\n",
            "iter 440: loss 2.4096, time 462.16ms, mfu 1.61%\n",
            "iter 450: loss 2.3286, time 516.07ms, mfu 1.61%\n",
            "iter 460: loss 2.3909, time 532.41ms, mfu 1.60%\n",
            "iter 470: loss 2.2986, time 501.07ms, mfu 1.60%\n",
            "iter 480: loss 2.2574, time 477.39ms, mfu 1.61%\n",
            "iter 490: loss 2.2609, time 468.87ms, mfu 1.62%\n",
            "iter 500: loss 2.2611, time 466.78ms, mfu 1.63%\n",
            "iter 510: loss 2.2538, time 500.22ms, mfu 1.63%\n",
            "iter 520: loss 2.2724, time 477.90ms, mfu 1.64%\n",
            "iter 530: loss 2.3133, time 478.34ms, mfu 1.64%\n",
            "iter 540: loss 2.1617, time 465.41ms, mfu 1.65%\n",
            "iter 550: loss 2.2177, time 454.99ms, mfu 1.66%\n",
            "iter 560: loss 2.2303, time 493.35ms, mfu 1.66%\n",
            "iter 570: loss 2.2137, time 487.53ms, mfu 1.66%\n",
            "iter 580: loss 2.2165, time 467.59ms, mfu 1.67%\n",
            "iter 590: loss 2.1340, time 468.03ms, mfu 1.67%\n",
            "step 600: train loss 2.0885, val loss 2.1376\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 600: loss 2.0873, time 2331.33ms, mfu 1.54%\n",
            "iter 610: loss 2.1139, time 472.14ms, mfu 1.56%\n",
            "iter 620: loss 2.1020, time 467.16ms, mfu 1.58%\n",
            "iter 630: loss 2.1557, time 495.08ms, mfu 1.58%\n",
            "iter 640: loss 2.0661, time 468.27ms, mfu 1.60%\n",
            "iter 650: loss 2.0688, time 462.60ms, mfu 1.61%\n",
            "iter 660: loss 2.0586, time 464.75ms, mfu 1.62%\n",
            "iter 670: loss 2.0692, time 480.70ms, mfu 1.63%\n",
            "iter 680: loss 2.0529, time 506.84ms, mfu 1.63%\n",
            "iter 690: loss 2.0302, time 456.85ms, mfu 1.64%\n",
            "iter 700: loss 1.9854, time 470.16ms, mfu 1.65%\n",
            "iter 710: loss 2.0479, time 468.81ms, mfu 1.66%\n",
            "iter 720: loss 2.0259, time 501.67ms, mfu 1.65%\n",
            "iter 730: loss 1.9740, time 508.73ms, mfu 1.65%\n",
            "iter 740: loss 2.0371, time 460.92ms, mfu 1.66%\n",
            "iter 750: loss 1.9871, time 455.79ms, mfu 1.67%\n",
            "iter 760: loss 1.9202, time 463.28ms, mfu 1.68%\n",
            "iter 770: loss 1.9235, time 467.57ms, mfu 1.68%\n",
            "iter 780: loss 1.8950, time 460.97ms, mfu 1.69%\n",
            "iter 790: loss 1.9566, time 482.98ms, mfu 1.69%\n",
            "step 800: train loss 1.8025, val loss 1.9207\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 800: loss 1.8576, time 2400.54ms, mfu 1.55%\n",
            "iter 810: loss 1.8400, time 468.12ms, mfu 1.57%\n",
            "iter 820: loss 1.8651, time 499.47ms, mfu 1.57%\n",
            "iter 830: loss 1.8764, time 464.02ms, mfu 1.59%\n",
            "iter 840: loss 1.8801, time 462.66ms, mfu 1.61%\n",
            "iter 850: loss 1.8356, time 464.43ms, mfu 1.62%\n",
            "iter 860: loss 1.9230, time 476.03ms, mfu 1.63%\n",
            "iter 870: loss 1.8502, time 474.71ms, mfu 1.64%\n",
            "iter 880: loss 1.6966, time 474.16ms, mfu 1.64%\n",
            "iter 890: loss 1.7565, time 461.91ms, mfu 1.65%\n",
            "iter 900: loss 1.7987, time 470.92ms, mfu 1.66%\n",
            "iter 910: loss 1.7961, time 451.92ms, mfu 1.67%\n",
            "iter 920: loss 1.7742, time 464.38ms, mfu 1.68%\n",
            "iter 930: loss 1.7420, time 463.48ms, mfu 1.69%\n",
            "iter 940: loss 1.7442, time 456.34ms, mfu 1.69%\n",
            "iter 950: loss 1.8317, time 457.20ms, mfu 1.70%\n",
            "iter 960: loss 1.7966, time 457.52ms, mfu 1.71%\n",
            "iter 970: loss 1.6617, time 454.77ms, mfu 1.72%\n",
            "iter 980: loss 1.7678, time 465.10ms, mfu 1.72%\n",
            "iter 990: loss 1.7182, time 465.41ms, mfu 1.72%\n",
            "step 1000: train loss 1.5965, val loss 1.7711\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1000: loss 1.7266, time 2442.42ms, mfu 1.58%\n",
            "iter 1010: loss 1.6668, time 519.90ms, mfu 1.58%\n",
            "iter 1020: loss 1.7173, time 485.49ms, mfu 1.59%\n",
            "iter 1030: loss 1.6480, time 454.38ms, mfu 1.61%\n",
            "iter 1040: loss 1.7295, time 453.94ms, mfu 1.62%\n",
            "iter 1050: loss 1.6739, time 466.40ms, mfu 1.63%\n",
            "iter 1060: loss 1.7782, time 456.53ms, mfu 1.65%\n",
            "iter 1070: loss 1.7001, time 465.27ms, mfu 1.66%\n",
            "iter 1080: loss 1.5724, time 450.62ms, mfu 1.67%\n",
            "iter 1090: loss 1.6337, time 450.13ms, mfu 1.68%\n",
            "iter 1100: loss 1.6394, time 468.95ms, mfu 1.69%\n",
            "iter 1110: loss 1.5982, time 487.87ms, mfu 1.68%\n",
            "iter 1120: loss 1.5850, time 459.67ms, mfu 1.69%\n",
            "iter 1130: loss 1.6082, time 451.50ms, mfu 1.70%\n",
            "iter 1140: loss 1.6402, time 472.44ms, mfu 1.70%\n",
            "iter 1150: loss 1.6358, time 471.08ms, mfu 1.70%\n",
            "iter 1160: loss 1.5883, time 466.24ms, mfu 1.71%\n",
            "iter 1170: loss 1.5748, time 490.27ms, mfu 1.70%\n",
            "iter 1180: loss 1.5335, time 465.96ms, mfu 1.70%\n",
            "iter 1190: loss 1.5253, time 455.63ms, mfu 1.71%\n",
            "step 1200: train loss 1.4611, val loss 1.6596\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1200: loss 1.5446, time 2398.60ms, mfu 1.57%\n",
            "iter 1210: loss 1.5289, time 451.08ms, mfu 1.60%\n",
            "iter 1220: loss 1.5274, time 455.01ms, mfu 1.61%\n",
            "iter 1230: loss 1.5230, time 465.18ms, mfu 1.63%\n",
            "iter 1240: loss 1.6104, time 453.67ms, mfu 1.64%\n",
            "iter 1250: loss 1.5711, time 468.50ms, mfu 1.65%\n",
            "iter 1260: loss 1.5390, time 456.99ms, mfu 1.66%\n",
            "iter 1270: loss 1.5468, time 457.36ms, mfu 1.67%\n",
            "iter 1280: loss 1.5750, time 466.09ms, mfu 1.68%\n",
            "iter 1290: loss 1.5713, time 452.57ms, mfu 1.69%\n",
            "iter 1300: loss 1.4800, time 491.95ms, mfu 1.69%\n",
            "iter 1310: loss 1.6172, time 490.45ms, mfu 1.68%\n",
            "iter 1320: loss 1.4878, time 470.59ms, mfu 1.69%\n",
            "iter 1330: loss 1.4580, time 467.27ms, mfu 1.69%\n",
            "iter 1340: loss 1.4770, time 465.37ms, mfu 1.69%\n",
            "iter 1350: loss 1.5182, time 458.13ms, mfu 1.70%\n",
            "iter 1360: loss 1.5014, time 456.82ms, mfu 1.71%\n",
            "iter 1370: loss 1.4637, time 460.76ms, mfu 1.71%\n",
            "iter 1380: loss 1.4918, time 477.71ms, mfu 1.71%\n",
            "iter 1390: loss 1.4747, time 477.41ms, mfu 1.71%\n",
            "step 1400: train loss 1.3806, val loss 1.5902\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1400: loss 1.5295, time 2396.11ms, mfu 1.57%\n",
            "iter 1410: loss 1.4501, time 481.77ms, mfu 1.58%\n",
            "iter 1420: loss 1.4964, time 464.30ms, mfu 1.60%\n",
            "iter 1430: loss 1.4540, time 485.53ms, mfu 1.61%\n",
            "iter 1440: loss 1.5396, time 489.08ms, mfu 1.61%\n",
            "iter 1450: loss 1.4843, time 502.21ms, mfu 1.61%\n",
            "iter 1460: loss 1.4577, time 488.89ms, mfu 1.61%\n",
            "iter 1470: loss 1.4661, time 482.42ms, mfu 1.62%\n",
            "iter 1480: loss 1.4071, time 519.95ms, mfu 1.61%\n",
            "iter 1490: loss 1.3890, time 466.95ms, mfu 1.63%\n",
            "iter 1500: loss 1.3993, time 483.51ms, mfu 1.63%\n",
            "iter 1510: loss 1.3759, time 475.77ms, mfu 1.64%\n",
            "iter 1520: loss 1.4450, time 475.44ms, mfu 1.64%\n",
            "iter 1530: loss 1.3761, time 497.01ms, mfu 1.64%\n",
            "iter 1540: loss 1.3955, time 478.97ms, mfu 1.65%\n",
            "iter 1550: loss 1.4243, time 500.34ms, mfu 1.64%\n",
            "iter 1560: loss 1.4277, time 465.48ms, mfu 1.65%\n",
            "iter 1570: loss 1.4415, time 466.77ms, mfu 1.66%\n",
            "iter 1580: loss 1.3622, time 486.84ms, mfu 1.66%\n",
            "iter 1590: loss 1.3645, time 484.23ms, mfu 1.66%\n",
            "step 1600: train loss 1.3146, val loss 1.5452\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1600: loss 1.4125, time 2460.82ms, mfu 1.53%\n",
            "iter 1610: loss 1.3530, time 469.51ms, mfu 1.55%\n",
            "iter 1620: loss 1.3845, time 466.16ms, mfu 1.57%\n",
            "iter 1630: loss 1.3491, time 490.19ms, mfu 1.57%\n",
            "iter 1640: loss 1.4216, time 478.27ms, mfu 1.59%\n",
            "iter 1650: loss 1.4012, time 482.12ms, mfu 1.60%\n",
            "iter 1660: loss 1.3736, time 483.58ms, mfu 1.60%\n",
            "iter 1670: loss 1.3910, time 471.47ms, mfu 1.61%\n",
            "iter 1680: loss 1.4300, time 497.98ms, mfu 1.61%\n",
            "iter 1690: loss 1.3231, time 470.77ms, mfu 1.63%\n",
            "iter 1700: loss 1.3114, time 474.90ms, mfu 1.63%\n",
            "iter 1710: loss 1.3641, time 474.61ms, mfu 1.64%\n",
            "iter 1720: loss 1.3471, time 470.60ms, mfu 1.65%\n",
            "iter 1730: loss 1.3347, time 487.55ms, mfu 1.65%\n",
            "iter 1740: loss 1.3480, time 502.03ms, mfu 1.64%\n",
            "iter 1750: loss 1.4860, time 504.44ms, mfu 1.64%\n",
            "iter 1760: loss 1.3610, time 554.84ms, mfu 1.62%\n",
            "iter 1770: loss 1.3380, time 459.83ms, mfu 1.64%\n",
            "iter 1780: loss 1.3067, time 511.13ms, mfu 1.63%\n",
            "iter 1790: loss 1.3287, time 466.82ms, mfu 1.64%\n",
            "step 1800: train loss 1.2584, val loss 1.5116\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "iter 1800: loss 1.3747, time 2525.86ms, mfu 1.51%\n",
            "iter 1810: loss 1.3438, time 468.87ms, mfu 1.53%\n",
            "iter 1820: loss 1.2994, time 474.84ms, mfu 1.55%\n",
            "iter 1830: loss 1.3269, time 516.69ms, mfu 1.55%\n",
            "iter 1840: loss 1.3305, time 468.48ms, mfu 1.57%\n",
            "iter 1850: loss 1.3092, time 459.28ms, mfu 1.59%\n",
            "iter 1860: loss 1.2966, time 459.15ms, mfu 1.60%\n",
            "iter 1870: loss 1.2885, time 483.36ms, mfu 1.61%\n",
            "iter 1880: loss 1.3510, time 462.14ms, mfu 1.62%\n",
            "iter 1890: loss 1.3406, time 462.51ms, mfu 1.64%\n",
            "iter 1900: loss 1.2665, time 479.67ms, mfu 1.64%\n",
            "iter 1910: loss 1.2695, time 468.83ms, mfu 1.65%\n",
            "iter 1920: loss 1.2712, time 477.27ms, mfu 1.65%\n",
            "iter 1930: loss 1.3194, time 477.36ms, mfu 1.66%\n",
            "iter 1940: loss 1.3625, time 469.79ms, mfu 1.66%\n",
            "iter 1950: loss 1.3098, time 461.99ms, mfu 1.67%\n",
            "iter 1960: loss 1.3346, time 489.84ms, mfu 1.67%\n",
            "iter 1970: loss 1.3524, time 474.28ms, mfu 1.67%\n",
            "iter 1980: loss 1.3293, time 462.23ms, mfu 1.68%\n",
            "iter 1990: loss 1.3039, time 468.50ms, mfu 1.69%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 16/32: b128_L6_H4_E256_BS16_MI2000_D20_s16 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H4_E256_BS16_MI2000_D20_s16.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 4\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 16\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2263, val loss 4.2232\n",
            "iter 0: loss 4.2219, time 2654.36ms, mfu -100.00%\n",
            "iter 10: loss 4.1623, time 502.04ms, mfu 1.61%\n",
            "iter 20: loss 4.0094, time 471.97ms, mfu 1.62%\n",
            "iter 30: loss 3.8146, time 534.21ms, mfu 1.61%\n",
            "iter 40: loss 3.6218, time 469.72ms, mfu 1.62%\n",
            "iter 50: loss 3.4769, time 462.71ms, mfu 1.63%\n",
            "iter 60: loss 3.4459, time 489.36ms, mfu 1.64%\n",
            "iter 70: loss 3.3474, time 485.61ms, mfu 1.64%\n",
            "iter 80: loss 3.2405, time 476.12ms, mfu 1.64%\n",
            "iter 90: loss 3.1666, time 477.03ms, mfu 1.65%\n",
            "iter 100: loss 3.0472, time 469.76ms, mfu 1.66%\n",
            "iter 110: loss 3.0540, time 459.80ms, mfu 1.67%\n",
            "iter 120: loss 2.9040, time 492.69ms, mfu 1.66%\n",
            "iter 130: loss 2.9117, time 493.13ms, mfu 1.66%\n",
            "iter 140: loss 2.8838, time 491.80ms, mfu 1.66%\n",
            "iter 150: loss 2.8376, time 473.48ms, mfu 1.66%\n",
            "iter 160: loss 2.8232, time 466.41ms, mfu 1.67%\n",
            "iter 170: loss 2.8222, time 472.13ms, mfu 1.68%\n",
            "iter 180: loss 2.7678, time 477.15ms, mfu 1.68%\n",
            "iter 190: loss 2.7833, time 492.38ms, mfu 1.67%\n",
            "step 200: train loss 2.6862, val loss 2.6895\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 200: loss 2.7337, time 2435.95ms, mfu 1.54%\n",
            "iter 210: loss 2.7024, time 491.18ms, mfu 1.55%\n",
            "iter 220: loss 2.6539, time 489.90ms, mfu 1.56%\n",
            "iter 230: loss 2.6691, time 469.70ms, mfu 1.58%\n",
            "iter 240: loss 2.7013, time 471.14ms, mfu 1.59%\n",
            "iter 250: loss 2.5820, time 469.44ms, mfu 1.60%\n",
            "iter 260: loss 2.6155, time 478.95ms, mfu 1.61%\n",
            "iter 270: loss 2.5454, time 459.94ms, mfu 1.63%\n",
            "iter 280: loss 2.5733, time 464.58ms, mfu 1.64%\n",
            "iter 290: loss 2.5870, time 476.96ms, mfu 1.64%\n",
            "iter 300: loss 2.5368, time 472.40ms, mfu 1.65%\n",
            "iter 310: loss 2.5302, time 474.68ms, mfu 1.66%\n",
            "iter 320: loss 2.5256, time 468.62ms, mfu 1.66%\n",
            "iter 330: loss 2.4889, time 480.94ms, mfu 1.66%\n",
            "iter 340: loss 2.4677, time 482.17ms, mfu 1.67%\n",
            "iter 350: loss 2.5359, time 484.12ms, mfu 1.67%\n",
            "iter 360: loss 2.4499, time 479.94ms, mfu 1.67%\n",
            "iter 370: loss 2.5258, time 464.45ms, mfu 1.68%\n",
            "iter 380: loss 2.4674, time 471.81ms, mfu 1.68%\n",
            "iter 390: loss 2.4647, time 487.67ms, mfu 1.68%\n",
            "step 400: train loss 2.3989, val loss 2.4022\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 400: loss 2.4786, time 2433.93ms, mfu 1.54%\n",
            "iter 410: loss 2.3865, time 486.24ms, mfu 1.55%\n",
            "iter 420: loss 2.4247, time 480.68ms, mfu 1.57%\n",
            "iter 430: loss 2.4575, time 479.81ms, mfu 1.58%\n",
            "iter 440: loss 2.4606, time 471.22ms, mfu 1.59%\n",
            "iter 450: loss 2.3862, time 471.40ms, mfu 1.60%\n",
            "iter 460: loss 2.4415, time 490.31ms, mfu 1.61%\n",
            "iter 470: loss 2.3460, time 475.39ms, mfu 1.62%\n",
            "iter 480: loss 2.3064, time 475.05ms, mfu 1.63%\n",
            "iter 490: loss 2.3260, time 479.08ms, mfu 1.63%\n",
            "iter 500: loss 2.3241, time 475.90ms, mfu 1.64%\n",
            "iter 510: loss 2.3235, time 474.98ms, mfu 1.65%\n",
            "iter 520: loss 2.3294, time 475.01ms, mfu 1.65%\n",
            "iter 530: loss 2.3641, time 482.36ms, mfu 1.65%\n",
            "iter 540: loss 2.2198, time 483.42ms, mfu 1.66%\n",
            "iter 550: loss 2.2935, time 466.42ms, mfu 1.66%\n",
            "iter 560: loss 2.2900, time 488.20ms, mfu 1.66%\n",
            "iter 570: loss 2.2831, time 463.20ms, mfu 1.67%\n",
            "iter 580: loss 2.2861, time 462.78ms, mfu 1.68%\n",
            "iter 590: loss 2.2208, time 512.06ms, mfu 1.67%\n",
            "step 600: train loss 2.1360, val loss 2.1720\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 600: loss 2.1688, time 2414.79ms, mfu 1.54%\n",
            "iter 610: loss 2.1968, time 505.41ms, mfu 1.54%\n",
            "iter 620: loss 2.1818, time 464.01ms, mfu 1.56%\n",
            "iter 630: loss 2.2297, time 472.66ms, mfu 1.58%\n",
            "iter 640: loss 2.1543, time 498.46ms, mfu 1.58%\n",
            "iter 650: loss 2.1389, time 481.77ms, mfu 1.59%\n",
            "iter 660: loss 2.1441, time 487.61ms, mfu 1.60%\n",
            "iter 670: loss 2.1432, time 474.08ms, mfu 1.61%\n",
            "iter 680: loss 2.1419, time 463.06ms, mfu 1.62%\n",
            "iter 690: loss 2.1247, time 476.76ms, mfu 1.63%\n",
            "iter 700: loss 2.0919, time 486.59ms, mfu 1.63%\n",
            "iter 710: loss 2.1401, time 471.98ms, mfu 1.64%\n",
            "iter 720: loss 2.1227, time 478.22ms, mfu 1.65%\n",
            "iter 730: loss 2.0751, time 492.07ms, mfu 1.65%\n",
            "iter 740: loss 2.1145, time 474.74ms, mfu 1.65%\n",
            "iter 750: loss 2.0692, time 476.85ms, mfu 1.66%\n",
            "iter 760: loss 2.0320, time 480.09ms, mfu 1.66%\n",
            "iter 770: loss 2.0236, time 471.64ms, mfu 1.66%\n",
            "iter 780: loss 1.9931, time 486.23ms, mfu 1.66%\n",
            "iter 790: loss 2.0531, time 484.57ms, mfu 1.66%\n",
            "step 800: train loss 1.8909, val loss 1.9860\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 800: loss 1.9785, time 2402.61ms, mfu 1.53%\n",
            "iter 810: loss 1.9719, time 463.67ms, mfu 1.55%\n",
            "iter 820: loss 2.0035, time 465.60ms, mfu 1.57%\n",
            "iter 830: loss 1.9947, time 484.89ms, mfu 1.58%\n",
            "iter 840: loss 1.9901, time 493.52ms, mfu 1.59%\n",
            "iter 850: loss 1.9451, time 469.59ms, mfu 1.60%\n",
            "iter 860: loss 2.0219, time 466.81ms, mfu 1.61%\n",
            "iter 870: loss 1.9440, time 463.77ms, mfu 1.63%\n",
            "iter 880: loss 1.8306, time 485.98ms, mfu 1.63%\n",
            "iter 890: loss 1.8781, time 488.90ms, mfu 1.63%\n",
            "iter 900: loss 1.9330, time 467.14ms, mfu 1.64%\n",
            "iter 910: loss 1.9119, time 485.72ms, mfu 1.64%\n",
            "iter 920: loss 1.8787, time 466.80ms, mfu 1.65%\n",
            "iter 930: loss 1.8628, time 472.81ms, mfu 1.66%\n",
            "iter 940: loss 1.8527, time 466.33ms, mfu 1.67%\n",
            "iter 950: loss 1.9465, time 469.49ms, mfu 1.67%\n",
            "iter 960: loss 1.9038, time 503.45ms, mfu 1.67%\n",
            "iter 970: loss 1.8004, time 464.43ms, mfu 1.67%\n",
            "iter 980: loss 1.9052, time 467.83ms, mfu 1.68%\n",
            "iter 990: loss 1.8371, time 489.93ms, mfu 1.68%\n",
            "step 1000: train loss 1.6972, val loss 1.8593\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1000: loss 1.8504, time 2387.95ms, mfu 1.54%\n",
            "iter 1010: loss 1.8052, time 494.41ms, mfu 1.55%\n",
            "iter 1020: loss 1.8322, time 479.35ms, mfu 1.56%\n",
            "iter 1030: loss 1.7791, time 479.38ms, mfu 1.58%\n",
            "iter 1040: loss 1.8555, time 474.56ms, mfu 1.59%\n",
            "iter 1050: loss 1.7982, time 473.36ms, mfu 1.60%\n",
            "iter 1060: loss 1.8847, time 482.69ms, mfu 1.61%\n",
            "iter 1070: loss 1.8591, time 478.22ms, mfu 1.62%\n",
            "iter 1080: loss 1.7173, time 466.68ms, mfu 1.63%\n",
            "iter 1090: loss 1.7562, time 478.25ms, mfu 1.63%\n",
            "iter 1100: loss 1.7537, time 456.05ms, mfu 1.65%\n",
            "iter 1110: loss 1.7174, time 480.13ms, mfu 1.65%\n",
            "iter 1120: loss 1.7128, time 483.78ms, mfu 1.65%\n",
            "iter 1130: loss 1.7115, time 470.03ms, mfu 1.66%\n",
            "iter 1140: loss 1.7650, time 476.43ms, mfu 1.66%\n",
            "iter 1150: loss 1.7447, time 466.34ms, mfu 1.67%\n",
            "iter 1160: loss 1.7366, time 479.30ms, mfu 1.67%\n",
            "iter 1170: loss 1.6901, time 479.61ms, mfu 1.67%\n",
            "iter 1180: loss 1.6444, time 457.65ms, mfu 1.68%\n",
            "iter 1190: loss 1.6440, time 463.73ms, mfu 1.69%\n",
            "step 1200: train loss 1.5644, val loss 1.7511\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1200: loss 1.6506, time 2410.55ms, mfu 1.55%\n",
            "iter 1210: loss 1.6570, time 480.64ms, mfu 1.57%\n",
            "iter 1220: loss 1.6526, time 471.71ms, mfu 1.58%\n",
            "iter 1230: loss 1.6337, time 474.73ms, mfu 1.59%\n",
            "iter 1240: loss 1.7433, time 471.32ms, mfu 1.61%\n",
            "iter 1250: loss 1.6993, time 473.12ms, mfu 1.62%\n",
            "iter 1260: loss 1.6567, time 474.88ms, mfu 1.62%\n",
            "iter 1270: loss 1.6501, time 478.71ms, mfu 1.63%\n",
            "iter 1280: loss 1.6685, time 478.23ms, mfu 1.64%\n",
            "iter 1290: loss 1.6844, time 472.86ms, mfu 1.64%\n",
            "iter 1300: loss 1.5942, time 491.27ms, mfu 1.64%\n",
            "iter 1310: loss 1.7355, time 481.46ms, mfu 1.65%\n",
            "iter 1320: loss 1.6102, time 471.51ms, mfu 1.65%\n",
            "iter 1330: loss 1.6143, time 484.40ms, mfu 1.66%\n",
            "iter 1340: loss 1.5839, time 468.92ms, mfu 1.66%\n",
            "iter 1350: loss 1.6341, time 471.42ms, mfu 1.67%\n",
            "iter 1360: loss 1.6025, time 466.49ms, mfu 1.67%\n",
            "iter 1370: loss 1.5749, time 470.15ms, mfu 1.68%\n",
            "iter 1380: loss 1.6057, time 477.55ms, mfu 1.68%\n",
            "iter 1390: loss 1.6149, time 464.78ms, mfu 1.69%\n",
            "step 1400: train loss 1.4682, val loss 1.6661\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1400: loss 1.6248, time 2478.58ms, mfu 1.55%\n",
            "iter 1410: loss 1.5735, time 475.28ms, mfu 1.57%\n",
            "iter 1420: loss 1.6261, time 476.05ms, mfu 1.58%\n",
            "iter 1430: loss 1.5569, time 496.82ms, mfu 1.58%\n",
            "iter 1440: loss 1.6435, time 474.27ms, mfu 1.60%\n",
            "iter 1450: loss 1.6016, time 466.18ms, mfu 1.61%\n",
            "iter 1460: loss 1.5684, time 461.77ms, mfu 1.62%\n",
            "iter 1470: loss 1.5816, time 484.77ms, mfu 1.63%\n",
            "iter 1480: loss 1.4973, time 476.91ms, mfu 1.63%\n",
            "iter 1490: loss 1.5217, time 477.76ms, mfu 1.64%\n",
            "iter 1500: loss 1.5014, time 471.31ms, mfu 1.65%\n",
            "iter 1510: loss 1.4967, time 467.04ms, mfu 1.66%\n",
            "iter 1520: loss 1.5660, time 475.56ms, mfu 1.66%\n",
            "iter 1530: loss 1.4744, time 486.18ms, mfu 1.66%\n",
            "iter 1540: loss 1.5148, time 469.04ms, mfu 1.67%\n",
            "iter 1550: loss 1.5228, time 490.02ms, mfu 1.67%\n",
            "iter 1560: loss 1.5402, time 493.27ms, mfu 1.66%\n",
            "iter 1570: loss 1.5499, time 486.92ms, mfu 1.66%\n",
            "iter 1580: loss 1.4594, time 493.09ms, mfu 1.66%\n",
            "iter 1590: loss 1.4536, time 473.23ms, mfu 1.67%\n",
            "step 1600: train loss 1.4017, val loss 1.6077\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1600: loss 1.5245, time 2437.78ms, mfu 1.53%\n",
            "iter 1610: loss 1.4763, time 499.49ms, mfu 1.54%\n",
            "iter 1620: loss 1.4839, time 496.03ms, mfu 1.55%\n",
            "iter 1630: loss 1.4592, time 493.31ms, mfu 1.56%\n",
            "iter 1640: loss 1.5340, time 473.65ms, mfu 1.57%\n",
            "iter 1650: loss 1.5044, time 474.43ms, mfu 1.59%\n",
            "iter 1660: loss 1.4802, time 486.59ms, mfu 1.59%\n",
            "iter 1670: loss 1.4629, time 465.08ms, mfu 1.61%\n",
            "iter 1680: loss 1.5351, time 478.99ms, mfu 1.62%\n",
            "iter 1690: loss 1.4437, time 478.54ms, mfu 1.62%\n",
            "iter 1700: loss 1.4015, time 489.31ms, mfu 1.63%\n",
            "iter 1710: loss 1.4598, time 469.35ms, mfu 1.64%\n",
            "iter 1720: loss 1.4599, time 462.14ms, mfu 1.65%\n",
            "iter 1730: loss 1.4394, time 488.52ms, mfu 1.65%\n",
            "iter 1740: loss 1.4905, time 464.98ms, mfu 1.66%\n",
            "iter 1750: loss 1.5762, time 487.54ms, mfu 1.66%\n",
            "iter 1760: loss 1.4671, time 462.76ms, mfu 1.67%\n",
            "iter 1770: loss 1.4368, time 464.73ms, mfu 1.67%\n",
            "iter 1780: loss 1.4034, time 490.22ms, mfu 1.67%\n",
            "iter 1790: loss 1.4441, time 471.65ms, mfu 1.68%\n",
            "step 1800: train loss 1.3494, val loss 1.5664\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "iter 1800: loss 1.4802, time 2452.79ms, mfu 1.54%\n",
            "iter 1810: loss 1.4530, time 468.69ms, mfu 1.56%\n",
            "iter 1820: loss 1.4126, time 469.51ms, mfu 1.58%\n",
            "iter 1830: loss 1.4290, time 468.56ms, mfu 1.59%\n",
            "iter 1840: loss 1.4348, time 465.87ms, mfu 1.60%\n",
            "iter 1850: loss 1.4175, time 503.17ms, mfu 1.61%\n",
            "iter 1860: loss 1.4194, time 469.71ms, mfu 1.62%\n",
            "iter 1870: loss 1.3853, time 468.47ms, mfu 1.63%\n",
            "iter 1880: loss 1.4638, time 468.69ms, mfu 1.64%\n",
            "iter 1890: loss 1.4784, time 464.40ms, mfu 1.65%\n",
            "iter 1900: loss 1.3784, time 477.38ms, mfu 1.65%\n",
            "iter 1910: loss 1.3853, time 483.19ms, mfu 1.65%\n",
            "iter 1920: loss 1.4055, time 476.98ms, mfu 1.66%\n",
            "iter 1930: loss 1.4455, time 501.86ms, mfu 1.65%\n",
            "iter 1940: loss 1.4833, time 481.80ms, mfu 1.66%\n",
            "iter 1950: loss 1.4500, time 464.99ms, mfu 1.66%\n",
            "iter 1960: loss 1.4238, time 484.53ms, mfu 1.66%\n",
            "iter 1970: loss 1.4780, time 469.91ms, mfu 1.67%\n",
            "iter 1980: loss 1.4130, time 477.50ms, mfu 1.67%\n",
            "iter 1990: loss 1.3935, time 458.71ms, mfu 1.68%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 17/32: b128_L6_H8_E128_BS8_MI1000_D10_s17 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS8_MI1000_D10_s17.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D10_s17\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 17\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1933, val loss 4.1893\n",
            "iter 0: loss 4.2078, time 2492.78ms, mfu -100.00%\n",
            "iter 10: loss 4.1783, time 453.28ms, mfu 0.24%\n",
            "iter 20: loss 4.1466, time 477.02ms, mfu 0.24%\n",
            "iter 30: loss 4.0622, time 448.71ms, mfu 0.24%\n",
            "iter 40: loss 3.9679, time 440.06ms, mfu 0.24%\n",
            "iter 50: loss 3.8668, time 445.41ms, mfu 0.24%\n",
            "iter 60: loss 3.7975, time 446.25ms, mfu 0.24%\n",
            "iter 70: loss 3.7272, time 454.85ms, mfu 0.24%\n",
            "iter 80: loss 3.6942, time 462.23ms, mfu 0.24%\n",
            "iter 90: loss 3.6337, time 445.78ms, mfu 0.24%\n",
            "iter 100: loss 3.6230, time 457.54ms, mfu 0.24%\n",
            "iter 110: loss 3.5836, time 447.38ms, mfu 0.24%\n",
            "iter 120: loss 3.5267, time 450.57ms, mfu 0.24%\n",
            "iter 130: loss 3.4753, time 445.12ms, mfu 0.24%\n",
            "iter 140: loss 3.4291, time 465.05ms, mfu 0.24%\n",
            "iter 150: loss 3.4309, time 454.38ms, mfu 0.24%\n",
            "iter 160: loss 3.3960, time 435.51ms, mfu 0.24%\n",
            "iter 170: loss 3.3484, time 478.33ms, mfu 0.24%\n",
            "iter 180: loss 3.3123, time 450.31ms, mfu 0.24%\n",
            "iter 190: loss 3.2519, time 438.01ms, mfu 0.24%\n",
            "step 200: train loss 3.2297, val loss 3.2368\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 200: loss 3.2614, time 2172.62ms, mfu 0.22%\n",
            "iter 210: loss 3.1787, time 448.36ms, mfu 0.22%\n",
            "iter 220: loss 3.2430, time 442.16ms, mfu 0.23%\n",
            "iter 230: loss 3.1992, time 443.88ms, mfu 0.23%\n",
            "iter 240: loss 3.1769, time 452.76ms, mfu 0.23%\n",
            "iter 250: loss 3.1292, time 438.66ms, mfu 0.23%\n",
            "iter 260: loss 3.1241, time 451.96ms, mfu 0.23%\n",
            "iter 270: loss 3.0943, time 464.81ms, mfu 0.23%\n",
            "iter 280: loss 3.0449, time 454.39ms, mfu 0.23%\n",
            "iter 290: loss 3.0059, time 451.84ms, mfu 0.23%\n",
            "iter 300: loss 2.9998, time 444.19ms, mfu 0.24%\n",
            "iter 310: loss 2.9394, time 458.90ms, mfu 0.24%\n",
            "iter 320: loss 2.9525, time 445.05ms, mfu 0.24%\n",
            "iter 330: loss 2.8867, time 492.34ms, mfu 0.24%\n",
            "iter 340: loss 2.9272, time 497.90ms, mfu 0.23%\n",
            "iter 350: loss 2.8309, time 439.63ms, mfu 0.24%\n",
            "iter 360: loss 2.8761, time 447.21ms, mfu 0.24%\n",
            "iter 370: loss 2.8371, time 447.59ms, mfu 0.24%\n",
            "iter 380: loss 2.8086, time 453.58ms, mfu 0.24%\n",
            "iter 390: loss 2.8360, time 474.24ms, mfu 0.24%\n",
            "step 400: train loss 2.7523, val loss 2.7616\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 400: loss 2.7263, time 2112.40ms, mfu 0.22%\n",
            "iter 410: loss 2.7190, time 473.52ms, mfu 0.22%\n",
            "iter 420: loss 2.7488, time 459.84ms, mfu 0.22%\n",
            "iter 430: loss 2.7080, time 440.42ms, mfu 0.22%\n",
            "iter 440: loss 2.7239, time 439.29ms, mfu 0.23%\n",
            "iter 450: loss 2.6304, time 461.73ms, mfu 0.23%\n",
            "iter 460: loss 2.6907, time 453.24ms, mfu 0.23%\n",
            "iter 470: loss 2.6750, time 448.36ms, mfu 0.23%\n",
            "iter 480: loss 2.6405, time 435.11ms, mfu 0.23%\n",
            "iter 490: loss 2.6504, time 457.64ms, mfu 0.23%\n",
            "iter 500: loss 2.5799, time 445.40ms, mfu 0.23%\n",
            "iter 510: loss 2.5814, time 461.18ms, mfu 0.23%\n",
            "iter 520: loss 2.5715, time 457.26ms, mfu 0.23%\n",
            "iter 530: loss 2.6135, time 443.33ms, mfu 0.24%\n",
            "iter 540: loss 2.5116, time 433.83ms, mfu 0.24%\n",
            "iter 550: loss 2.5223, time 451.33ms, mfu 0.24%\n",
            "iter 560: loss 2.4657, time 449.11ms, mfu 0.24%\n",
            "iter 570: loss 2.5306, time 444.52ms, mfu 0.24%\n",
            "iter 580: loss 2.5135, time 445.11ms, mfu 0.24%\n",
            "iter 590: loss 2.4666, time 457.85ms, mfu 0.24%\n",
            "step 600: train loss 2.4659, val loss 2.4691\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 600: loss 2.5241, time 2187.45ms, mfu 0.22%\n",
            "iter 610: loss 2.4523, time 453.36ms, mfu 0.22%\n",
            "iter 620: loss 2.4436, time 445.09ms, mfu 0.22%\n",
            "iter 630: loss 2.4648, time 462.84ms, mfu 0.23%\n",
            "iter 640: loss 2.3980, time 447.24ms, mfu 0.23%\n",
            "iter 650: loss 2.4586, time 458.02ms, mfu 0.23%\n",
            "iter 660: loss 2.4555, time 444.72ms, mfu 0.23%\n",
            "iter 670: loss 2.5131, time 442.53ms, mfu 0.23%\n",
            "iter 680: loss 2.4253, time 443.77ms, mfu 0.23%\n",
            "iter 690: loss 2.4296, time 443.99ms, mfu 0.23%\n",
            "iter 700: loss 2.4396, time 472.21ms, mfu 0.23%\n",
            "iter 710: loss 2.4371, time 470.06ms, mfu 0.23%\n",
            "iter 720: loss 2.4867, time 486.95ms, mfu 0.23%\n",
            "iter 730: loss 2.4623, time 471.75ms, mfu 0.23%\n",
            "iter 740: loss 2.4400, time 443.45ms, mfu 0.23%\n",
            "iter 750: loss 2.3877, time 445.35ms, mfu 0.24%\n",
            "iter 760: loss 2.3995, time 457.46ms, mfu 0.24%\n",
            "iter 770: loss 2.4148, time 455.56ms, mfu 0.24%\n",
            "iter 780: loss 2.3567, time 457.02ms, mfu 0.24%\n",
            "iter 790: loss 2.4455, time 468.57ms, mfu 0.24%\n",
            "step 800: train loss 2.3043, val loss 2.3188\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 800: loss 2.3616, time 2140.88ms, mfu 0.22%\n",
            "iter 810: loss 2.3429, time 446.68ms, mfu 0.22%\n",
            "iter 820: loss 2.3267, time 466.59ms, mfu 0.22%\n",
            "iter 830: loss 2.2949, time 498.63ms, mfu 0.22%\n",
            "iter 840: loss 2.3004, time 444.78ms, mfu 0.22%\n",
            "iter 850: loss 2.4013, time 441.49ms, mfu 0.23%\n",
            "iter 860: loss 2.3586, time 456.22ms, mfu 0.23%\n",
            "iter 870: loss 2.2854, time 434.08ms, mfu 0.23%\n",
            "iter 880: loss 2.2818, time 441.09ms, mfu 0.23%\n",
            "iter 890: loss 2.3258, time 453.41ms, mfu 0.23%\n",
            "iter 900: loss 2.3336, time 438.52ms, mfu 0.23%\n",
            "iter 910: loss 2.2668, time 466.51ms, mfu 0.23%\n",
            "iter 920: loss 2.2595, time 435.43ms, mfu 0.24%\n",
            "iter 930: loss 2.2832, time 447.79ms, mfu 0.24%\n",
            "iter 940: loss 2.2297, time 464.00ms, mfu 0.24%\n",
            "iter 950: loss 2.2599, time 442.52ms, mfu 0.24%\n",
            "iter 960: loss 2.2167, time 447.35ms, mfu 0.24%\n",
            "iter 970: loss 2.2316, time 462.01ms, mfu 0.24%\n",
            "iter 980: loss 2.2581, time 443.20ms, mfu 0.24%\n",
            "iter 990: loss 2.1799, time 474.89ms, mfu 0.24%\n",
            "step 1000: train loss 2.1477, val loss 2.1883\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D10_s17\n",
            "iter 1000: loss 2.3162, time 2149.04ms, mfu 0.22%\n",
            "\n",
            "=== Experiment 18/32: b128_L6_H8_E128_BS8_MI1000_D20_s18 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS8_MI1000_D20_s18.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D20_s18\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 18\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1933, val loss 4.1893\n",
            "iter 0: loss 4.2074, time 2474.69ms, mfu -100.00%\n",
            "iter 10: loss 4.1794, time 469.21ms, mfu 0.23%\n",
            "iter 20: loss 4.1523, time 496.21ms, mfu 0.23%\n",
            "iter 30: loss 4.0799, time 459.80ms, mfu 0.23%\n",
            "iter 40: loss 3.9932, time 456.22ms, mfu 0.23%\n",
            "iter 50: loss 3.8942, time 476.93ms, mfu 0.23%\n",
            "iter 60: loss 3.8201, time 467.25ms, mfu 0.23%\n",
            "iter 70: loss 3.7479, time 460.23ms, mfu 0.23%\n",
            "iter 80: loss 3.7152, time 483.61ms, mfu 0.23%\n",
            "iter 90: loss 3.6621, time 460.12ms, mfu 0.23%\n",
            "iter 100: loss 3.6629, time 459.04ms, mfu 0.23%\n",
            "iter 110: loss 3.6293, time 462.69ms, mfu 0.23%\n",
            "iter 120: loss 3.5674, time 487.10ms, mfu 0.23%\n",
            "iter 130: loss 3.5129, time 468.81ms, mfu 0.23%\n",
            "iter 140: loss 3.4713, time 465.37ms, mfu 0.23%\n",
            "iter 150: loss 3.4660, time 460.60ms, mfu 0.23%\n",
            "iter 160: loss 3.4303, time 459.64ms, mfu 0.23%\n",
            "iter 170: loss 3.3865, time 447.23ms, mfu 0.23%\n",
            "iter 180: loss 3.3399, time 458.00ms, mfu 0.24%\n",
            "iter 190: loss 3.2826, time 466.62ms, mfu 0.24%\n",
            "step 200: train loss 3.2431, val loss 3.2522\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 200: loss 3.2943, time 2207.78ms, mfu 0.22%\n",
            "iter 210: loss 3.2180, time 447.45ms, mfu 0.22%\n",
            "iter 220: loss 3.2741, time 443.15ms, mfu 0.22%\n",
            "iter 230: loss 3.2279, time 472.82ms, mfu 0.22%\n",
            "iter 240: loss 3.2099, time 458.96ms, mfu 0.22%\n",
            "iter 250: loss 3.1534, time 453.90ms, mfu 0.23%\n",
            "iter 260: loss 3.1527, time 496.32ms, mfu 0.23%\n",
            "iter 270: loss 3.1200, time 463.04ms, mfu 0.23%\n",
            "iter 280: loss 3.0686, time 497.32ms, mfu 0.23%\n",
            "iter 290: loss 3.0414, time 444.72ms, mfu 0.23%\n",
            "iter 300: loss 3.0295, time 488.98ms, mfu 0.23%\n",
            "iter 310: loss 2.9700, time 463.38ms, mfu 0.23%\n",
            "iter 320: loss 2.9743, time 469.00ms, mfu 0.23%\n",
            "iter 330: loss 2.9079, time 450.52ms, mfu 0.23%\n",
            "iter 340: loss 2.9496, time 523.50ms, mfu 0.23%\n",
            "iter 350: loss 2.8504, time 465.00ms, mfu 0.23%\n",
            "iter 360: loss 2.9090, time 452.97ms, mfu 0.23%\n",
            "iter 370: loss 2.8572, time 503.26ms, mfu 0.23%\n",
            "iter 380: loss 2.8360, time 452.88ms, mfu 0.23%\n",
            "iter 390: loss 2.8615, time 472.07ms, mfu 0.23%\n",
            "step 400: train loss 2.7717, val loss 2.7778\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 400: loss 2.7415, time 2181.16ms, mfu 0.21%\n",
            "iter 410: loss 2.7537, time 498.49ms, mfu 0.21%\n",
            "iter 420: loss 2.7695, time 448.64ms, mfu 0.22%\n",
            "iter 430: loss 2.7366, time 473.86ms, mfu 0.22%\n",
            "iter 440: loss 2.7560, time 458.43ms, mfu 0.22%\n",
            "iter 450: loss 2.6562, time 449.48ms, mfu 0.22%\n",
            "iter 460: loss 2.7147, time 476.52ms, mfu 0.22%\n",
            "iter 470: loss 2.7009, time 472.14ms, mfu 0.22%\n",
            "iter 480: loss 2.6734, time 448.32ms, mfu 0.23%\n",
            "iter 490: loss 2.6786, time 455.60ms, mfu 0.23%\n",
            "iter 500: loss 2.6112, time 462.07ms, mfu 0.23%\n",
            "iter 510: loss 2.6013, time 456.12ms, mfu 0.23%\n",
            "iter 520: loss 2.5937, time 488.89ms, mfu 0.23%\n",
            "iter 530: loss 2.6396, time 457.00ms, mfu 0.23%\n",
            "iter 540: loss 2.5322, time 488.24ms, mfu 0.23%\n",
            "iter 550: loss 2.5638, time 457.66ms, mfu 0.23%\n",
            "iter 560: loss 2.4981, time 453.91ms, mfu 0.23%\n",
            "iter 570: loss 2.5563, time 494.25ms, mfu 0.23%\n",
            "iter 580: loss 2.5472, time 442.85ms, mfu 0.23%\n",
            "iter 590: loss 2.4819, time 511.03ms, mfu 0.23%\n",
            "step 600: train loss 2.4873, val loss 2.4885\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 600: loss 2.5563, time 2193.41ms, mfu 0.21%\n",
            "iter 610: loss 2.4848, time 471.13ms, mfu 0.21%\n",
            "iter 620: loss 2.4829, time 448.20ms, mfu 0.22%\n",
            "iter 630: loss 2.4969, time 452.65ms, mfu 0.22%\n",
            "iter 640: loss 2.4264, time 481.13ms, mfu 0.22%\n",
            "iter 650: loss 2.5030, time 458.25ms, mfu 0.22%\n",
            "iter 660: loss 2.4904, time 447.26ms, mfu 0.22%\n",
            "iter 670: loss 2.5260, time 458.66ms, mfu 0.23%\n",
            "iter 680: loss 2.4701, time 446.15ms, mfu 0.23%\n",
            "iter 690: loss 2.4816, time 444.53ms, mfu 0.23%\n",
            "iter 700: loss 2.4566, time 451.92ms, mfu 0.23%\n",
            "iter 710: loss 2.4767, time 463.52ms, mfu 0.23%\n",
            "iter 720: loss 2.5194, time 468.15ms, mfu 0.23%\n",
            "iter 730: loss 2.4903, time 477.02ms, mfu 0.23%\n",
            "iter 740: loss 2.4516, time 446.04ms, mfu 0.23%\n",
            "iter 750: loss 2.4372, time 443.84ms, mfu 0.23%\n",
            "iter 760: loss 2.4249, time 443.57ms, mfu 0.23%\n",
            "iter 770: loss 2.4514, time 458.25ms, mfu 0.24%\n",
            "iter 780: loss 2.4024, time 439.10ms, mfu 0.24%\n",
            "iter 790: loss 2.4729, time 448.02ms, mfu 0.24%\n",
            "step 800: train loss 2.3384, val loss 2.3488\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 800: loss 2.4096, time 2138.60ms, mfu 0.22%\n",
            "iter 810: loss 2.3851, time 461.82ms, mfu 0.22%\n",
            "iter 820: loss 2.3719, time 457.91ms, mfu 0.22%\n",
            "iter 830: loss 2.3364, time 442.30ms, mfu 0.22%\n",
            "iter 840: loss 2.3448, time 442.64ms, mfu 0.23%\n",
            "iter 850: loss 2.4481, time 465.80ms, mfu 0.23%\n",
            "iter 860: loss 2.4096, time 441.53ms, mfu 0.23%\n",
            "iter 870: loss 2.3318, time 447.62ms, mfu 0.23%\n",
            "iter 880: loss 2.3384, time 447.64ms, mfu 0.23%\n",
            "iter 890: loss 2.3910, time 448.27ms, mfu 0.23%\n",
            "iter 900: loss 2.4057, time 453.83ms, mfu 0.23%\n",
            "iter 910: loss 2.3214, time 446.84ms, mfu 0.24%\n",
            "iter 920: loss 2.3216, time 454.00ms, mfu 0.24%\n",
            "iter 930: loss 2.3469, time 470.39ms, mfu 0.24%\n",
            "iter 940: loss 2.2857, time 449.28ms, mfu 0.24%\n",
            "iter 950: loss 2.3237, time 443.22ms, mfu 0.24%\n",
            "iter 960: loss 2.2931, time 471.50ms, mfu 0.24%\n",
            "iter 970: loss 2.3088, time 451.94ms, mfu 0.24%\n",
            "iter 980: loss 2.3469, time 455.42ms, mfu 0.24%\n",
            "iter 990: loss 2.2688, time 455.98ms, mfu 0.24%\n",
            "step 1000: train loss 2.2022, val loss 2.2337\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI1000_D20_s18\n",
            "iter 1000: loss 2.3627, time 2316.22ms, mfu 0.22%\n",
            "\n",
            "=== Experiment 19/32: b128_L6_H8_E128_BS8_MI2000_D10_s19 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS8_MI2000_D10_s19.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 19\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1933, val loss 4.1893\n",
            "iter 0: loss 4.2078, time 2533.46ms, mfu -100.00%\n",
            "iter 10: loss 4.1783, time 463.45ms, mfu 0.24%\n",
            "iter 20: loss 4.1466, time 457.06ms, mfu 0.24%\n",
            "iter 30: loss 4.0622, time 452.18ms, mfu 0.24%\n",
            "iter 40: loss 3.9679, time 449.72ms, mfu 0.24%\n",
            "iter 50: loss 3.8668, time 456.59ms, mfu 0.24%\n",
            "iter 60: loss 3.7975, time 456.84ms, mfu 0.24%\n",
            "iter 70: loss 3.7272, time 451.72ms, mfu 0.24%\n",
            "iter 80: loss 3.6942, time 451.69ms, mfu 0.24%\n",
            "iter 90: loss 3.6337, time 440.82ms, mfu 0.24%\n",
            "iter 100: loss 3.6230, time 448.35ms, mfu 0.24%\n",
            "iter 110: loss 3.5836, time 463.16ms, mfu 0.24%\n",
            "iter 120: loss 3.5267, time 465.04ms, mfu 0.24%\n",
            "iter 130: loss 3.4753, time 450.26ms, mfu 0.24%\n",
            "iter 140: loss 3.4291, time 494.85ms, mfu 0.24%\n",
            "iter 150: loss 3.4309, time 462.64ms, mfu 0.24%\n",
            "iter 160: loss 3.3960, time 442.08ms, mfu 0.24%\n",
            "iter 170: loss 3.3484, time 447.28ms, mfu 0.24%\n",
            "iter 180: loss 3.3123, time 445.00ms, mfu 0.24%\n",
            "iter 190: loss 3.2519, time 446.18ms, mfu 0.24%\n",
            "step 200: train loss 3.2297, val loss 3.2368\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 200: loss 3.2614, time 2239.00ms, mfu 0.22%\n",
            "iter 210: loss 3.1787, time 475.21ms, mfu 0.22%\n",
            "iter 220: loss 3.2430, time 455.83ms, mfu 0.22%\n",
            "iter 230: loss 3.1992, time 449.40ms, mfu 0.23%\n",
            "iter 240: loss 3.1769, time 456.69ms, mfu 0.23%\n",
            "iter 250: loss 3.1292, time 467.47ms, mfu 0.23%\n",
            "iter 260: loss 3.1241, time 463.03ms, mfu 0.23%\n",
            "iter 270: loss 3.0943, time 440.22ms, mfu 0.23%\n",
            "iter 280: loss 3.0449, time 453.71ms, mfu 0.23%\n",
            "iter 290: loss 3.0059, time 442.11ms, mfu 0.23%\n",
            "iter 300: loss 2.9998, time 451.47ms, mfu 0.23%\n",
            "iter 310: loss 2.9394, time 441.96ms, mfu 0.24%\n",
            "iter 320: loss 2.9525, time 446.10ms, mfu 0.24%\n",
            "iter 330: loss 2.8867, time 445.70ms, mfu 0.24%\n",
            "iter 340: loss 2.9272, time 439.12ms, mfu 0.24%\n",
            "iter 350: loss 2.8309, time 432.39ms, mfu 0.24%\n",
            "iter 360: loss 2.8761, time 450.16ms, mfu 0.24%\n",
            "iter 370: loss 2.8371, time 466.95ms, mfu 0.24%\n",
            "iter 380: loss 2.8086, time 442.61ms, mfu 0.24%\n",
            "iter 390: loss 2.8360, time 440.24ms, mfu 0.24%\n",
            "step 400: train loss 2.7523, val loss 2.7616\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 400: loss 2.7263, time 2136.31ms, mfu 0.22%\n",
            "iter 410: loss 2.7190, time 473.32ms, mfu 0.22%\n",
            "iter 420: loss 2.7488, time 457.87ms, mfu 0.22%\n",
            "iter 430: loss 2.7080, time 458.40ms, mfu 0.23%\n",
            "iter 440: loss 2.7239, time 459.77ms, mfu 0.23%\n",
            "iter 450: loss 2.6304, time 445.90ms, mfu 0.23%\n",
            "iter 460: loss 2.6907, time 438.00ms, mfu 0.23%\n",
            "iter 470: loss 2.6750, time 449.75ms, mfu 0.23%\n",
            "iter 480: loss 2.6405, time 450.20ms, mfu 0.23%\n",
            "iter 490: loss 2.6504, time 459.52ms, mfu 0.23%\n",
            "iter 500: loss 2.5799, time 466.44ms, mfu 0.23%\n",
            "iter 510: loss 2.5814, time 436.62ms, mfu 0.24%\n",
            "iter 520: loss 2.5715, time 446.26ms, mfu 0.24%\n",
            "iter 530: loss 2.6135, time 469.42ms, mfu 0.24%\n",
            "iter 540: loss 2.5116, time 442.17ms, mfu 0.24%\n",
            "iter 550: loss 2.5223, time 448.55ms, mfu 0.24%\n",
            "iter 560: loss 2.4657, time 454.90ms, mfu 0.24%\n",
            "iter 570: loss 2.5306, time 442.84ms, mfu 0.24%\n",
            "iter 580: loss 2.5135, time 439.28ms, mfu 0.24%\n",
            "iter 590: loss 2.4666, time 439.04ms, mfu 0.24%\n",
            "step 600: train loss 2.4659, val loss 2.4691\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 600: loss 2.5241, time 2104.08ms, mfu 0.22%\n",
            "iter 610: loss 2.4523, time 464.76ms, mfu 0.22%\n",
            "iter 620: loss 2.4436, time 448.89ms, mfu 0.23%\n",
            "iter 630: loss 2.4648, time 439.68ms, mfu 0.23%\n",
            "iter 640: loss 2.3980, time 436.17ms, mfu 0.23%\n",
            "iter 650: loss 2.4586, time 448.92ms, mfu 0.23%\n",
            "iter 660: loss 2.4555, time 451.74ms, mfu 0.23%\n",
            "iter 670: loss 2.5131, time 462.47ms, mfu 0.23%\n",
            "iter 680: loss 2.4253, time 439.38ms, mfu 0.23%\n",
            "iter 690: loss 2.4296, time 445.04ms, mfu 0.24%\n",
            "iter 700: loss 2.4396, time 453.19ms, mfu 0.24%\n",
            "iter 710: loss 2.4371, time 446.59ms, mfu 0.24%\n",
            "iter 720: loss 2.4867, time 437.87ms, mfu 0.24%\n",
            "iter 730: loss 2.4623, time 449.97ms, mfu 0.24%\n",
            "iter 740: loss 2.4400, time 440.67ms, mfu 0.24%\n",
            "iter 750: loss 2.3877, time 438.20ms, mfu 0.24%\n",
            "iter 760: loss 2.3995, time 440.35ms, mfu 0.24%\n",
            "iter 770: loss 2.4148, time 441.93ms, mfu 0.24%\n",
            "iter 780: loss 2.3567, time 435.95ms, mfu 0.24%\n",
            "iter 790: loss 2.4455, time 437.00ms, mfu 0.24%\n",
            "step 800: train loss 2.3043, val loss 2.3188\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 800: loss 2.3616, time 2158.89ms, mfu 0.22%\n",
            "iter 810: loss 2.3429, time 449.73ms, mfu 0.23%\n",
            "iter 820: loss 2.3267, time 444.14ms, mfu 0.23%\n",
            "iter 830: loss 2.2949, time 438.01ms, mfu 0.23%\n",
            "iter 840: loss 2.3004, time 447.10ms, mfu 0.23%\n",
            "iter 850: loss 2.4013, time 448.07ms, mfu 0.23%\n",
            "iter 860: loss 2.3586, time 449.16ms, mfu 0.23%\n",
            "iter 870: loss 2.2854, time 438.95ms, mfu 0.24%\n",
            "iter 880: loss 2.2818, time 448.35ms, mfu 0.24%\n",
            "iter 890: loss 2.3258, time 448.30ms, mfu 0.24%\n",
            "iter 900: loss 2.3336, time 439.98ms, mfu 0.24%\n",
            "iter 910: loss 2.2668, time 443.83ms, mfu 0.24%\n",
            "iter 920: loss 2.2595, time 442.33ms, mfu 0.24%\n",
            "iter 930: loss 2.2832, time 440.46ms, mfu 0.24%\n",
            "iter 940: loss 2.2297, time 445.71ms, mfu 0.24%\n",
            "iter 950: loss 2.2599, time 446.22ms, mfu 0.24%\n",
            "iter 960: loss 2.2167, time 450.99ms, mfu 0.24%\n",
            "iter 970: loss 2.2316, time 470.51ms, mfu 0.24%\n",
            "iter 980: loss 2.2581, time 451.21ms, mfu 0.24%\n",
            "iter 990: loss 2.1799, time 463.71ms, mfu 0.24%\n",
            "step 1000: train loss 2.1477, val loss 2.1883\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1000: loss 2.3162, time 2148.94ms, mfu 0.22%\n",
            "iter 1010: loss 2.1502, time 445.78ms, mfu 0.22%\n",
            "iter 1020: loss 2.1331, time 448.02ms, mfu 0.23%\n",
            "iter 1030: loss 2.2522, time 449.09ms, mfu 0.23%\n",
            "iter 1040: loss 2.1570, time 443.21ms, mfu 0.23%\n",
            "iter 1050: loss 2.2168, time 435.56ms, mfu 0.23%\n",
            "iter 1060: loss 2.1595, time 440.99ms, mfu 0.23%\n",
            "iter 1070: loss 2.1265, time 455.55ms, mfu 0.23%\n",
            "iter 1080: loss 2.2535, time 459.59ms, mfu 0.23%\n",
            "iter 1090: loss 2.1115, time 450.70ms, mfu 0.23%\n",
            "iter 1100: loss 2.1508, time 471.34ms, mfu 0.23%\n",
            "iter 1110: loss 2.1044, time 433.94ms, mfu 0.24%\n",
            "iter 1120: loss 2.1495, time 435.21ms, mfu 0.24%\n",
            "iter 1130: loss 2.0976, time 445.01ms, mfu 0.24%\n",
            "iter 1140: loss 2.0981, time 441.79ms, mfu 0.24%\n",
            "iter 1150: loss 2.1381, time 443.08ms, mfu 0.24%\n",
            "iter 1160: loss 2.0994, time 442.61ms, mfu 0.24%\n",
            "iter 1170: loss 2.0312, time 492.68ms, mfu 0.24%\n",
            "iter 1180: loss 2.0733, time 443.47ms, mfu 0.24%\n",
            "iter 1190: loss 2.1588, time 452.53ms, mfu 0.24%\n",
            "step 1200: train loss 1.9955, val loss 2.0542\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1200: loss 2.1364, time 2175.56ms, mfu 0.22%\n",
            "iter 1210: loss 2.1186, time 490.76ms, mfu 0.22%\n",
            "iter 1220: loss 2.1594, time 448.46ms, mfu 0.22%\n",
            "iter 1230: loss 2.0153, time 449.30ms, mfu 0.23%\n",
            "iter 1240: loss 2.0428, time 462.11ms, mfu 0.23%\n",
            "iter 1250: loss 2.0954, time 446.40ms, mfu 0.23%\n",
            "iter 1260: loss 2.0752, time 447.28ms, mfu 0.23%\n",
            "iter 1270: loss 1.9516, time 439.64ms, mfu 0.23%\n",
            "iter 1280: loss 2.0621, time 455.27ms, mfu 0.23%\n",
            "iter 1290: loss 2.0118, time 435.81ms, mfu 0.23%\n",
            "iter 1300: loss 2.0800, time 443.43ms, mfu 0.24%\n",
            "iter 1310: loss 1.9609, time 452.61ms, mfu 0.24%\n",
            "iter 1320: loss 1.9271, time 441.02ms, mfu 0.24%\n",
            "iter 1330: loss 1.9083, time 457.12ms, mfu 0.24%\n",
            "iter 1340: loss 2.0014, time 466.56ms, mfu 0.24%\n",
            "iter 1350: loss 2.0189, time 443.03ms, mfu 0.24%\n",
            "iter 1360: loss 1.9215, time 456.44ms, mfu 0.24%\n",
            "iter 1370: loss 1.9083, time 440.88ms, mfu 0.24%\n",
            "iter 1380: loss 1.9433, time 466.93ms, mfu 0.24%\n",
            "iter 1390: loss 2.0758, time 472.97ms, mfu 0.24%\n",
            "step 1400: train loss 1.8349, val loss 1.9440\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1400: loss 2.0028, time 2191.72ms, mfu 0.22%\n",
            "iter 1410: loss 1.9194, time 471.25ms, mfu 0.22%\n",
            "iter 1420: loss 1.9675, time 457.30ms, mfu 0.22%\n",
            "iter 1430: loss 1.9380, time 450.17ms, mfu 0.22%\n",
            "iter 1440: loss 1.9018, time 450.16ms, mfu 0.23%\n",
            "iter 1450: loss 1.8693, time 450.27ms, mfu 0.23%\n",
            "iter 1460: loss 1.9052, time 444.54ms, mfu 0.23%\n",
            "iter 1470: loss 1.8224, time 457.19ms, mfu 0.23%\n",
            "iter 1480: loss 1.9215, time 488.51ms, mfu 0.23%\n",
            "iter 1490: loss 1.8572, time 474.60ms, mfu 0.23%\n",
            "iter 1500: loss 1.8772, time 459.62ms, mfu 0.23%\n",
            "iter 1510: loss 1.8074, time 461.34ms, mfu 0.23%\n",
            "iter 1520: loss 1.8198, time 442.73ms, mfu 0.23%\n",
            "iter 1530: loss 1.8964, time 455.64ms, mfu 0.23%\n",
            "iter 1540: loss 1.8168, time 460.37ms, mfu 0.23%\n",
            "iter 1550: loss 1.8403, time 451.30ms, mfu 0.23%\n",
            "iter 1560: loss 1.7941, time 484.49ms, mfu 0.23%\n",
            "iter 1570: loss 1.8273, time 468.67ms, mfu 0.23%\n",
            "iter 1580: loss 1.8649, time 447.50ms, mfu 0.23%\n",
            "iter 1590: loss 1.9551, time 468.45ms, mfu 0.23%\n",
            "step 1600: train loss 1.7242, val loss 1.8685\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1600: loss 1.7525, time 2176.99ms, mfu 0.22%\n",
            "iter 1610: loss 1.7918, time 443.21ms, mfu 0.22%\n",
            "iter 1620: loss 1.9046, time 465.19ms, mfu 0.22%\n",
            "iter 1630: loss 1.7538, time 454.89ms, mfu 0.22%\n",
            "iter 1640: loss 1.6763, time 456.41ms, mfu 0.22%\n",
            "iter 1650: loss 1.8662, time 458.34ms, mfu 0.23%\n",
            "iter 1660: loss 1.8545, time 451.99ms, mfu 0.23%\n",
            "iter 1670: loss 1.7847, time 463.71ms, mfu 0.23%\n",
            "iter 1680: loss 1.7816, time 454.00ms, mfu 0.23%\n",
            "iter 1690: loss 1.7549, time 456.49ms, mfu 0.23%\n",
            "iter 1700: loss 1.8185, time 461.71ms, mfu 0.23%\n",
            "iter 1710: loss 1.8568, time 458.48ms, mfu 0.23%\n",
            "iter 1720: loss 1.7798, time 453.45ms, mfu 0.23%\n",
            "iter 1730: loss 1.8463, time 457.52ms, mfu 0.23%\n",
            "iter 1740: loss 1.6850, time 466.23ms, mfu 0.23%\n",
            "iter 1750: loss 1.6970, time 456.88ms, mfu 0.23%\n",
            "iter 1760: loss 1.7158, time 457.45ms, mfu 0.23%\n",
            "iter 1770: loss 1.7508, time 453.74ms, mfu 0.23%\n",
            "iter 1780: loss 1.6470, time 472.69ms, mfu 0.23%\n",
            "iter 1790: loss 1.6544, time 450.73ms, mfu 0.24%\n",
            "step 1800: train loss 1.6283, val loss 1.8042\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "iter 1800: loss 1.7356, time 2218.97ms, mfu 0.22%\n",
            "iter 1810: loss 1.6985, time 448.51ms, mfu 0.22%\n",
            "iter 1820: loss 1.6962, time 464.27ms, mfu 0.22%\n",
            "iter 1830: loss 1.6641, time 457.91ms, mfu 0.22%\n",
            "iter 1840: loss 1.7220, time 445.66ms, mfu 0.22%\n",
            "iter 1850: loss 1.7985, time 455.53ms, mfu 0.23%\n",
            "iter 1860: loss 1.7320, time 472.17ms, mfu 0.23%\n",
            "iter 1870: loss 1.6886, time 455.69ms, mfu 0.23%\n",
            "iter 1880: loss 1.7309, time 466.31ms, mfu 0.23%\n",
            "iter 1890: loss 1.6074, time 455.40ms, mfu 0.23%\n",
            "iter 1900: loss 1.6882, time 443.68ms, mfu 0.23%\n",
            "iter 1910: loss 1.7023, time 447.57ms, mfu 0.23%\n",
            "iter 1920: loss 1.8696, time 446.02ms, mfu 0.23%\n",
            "iter 1930: loss 1.6528, time 453.30ms, mfu 0.23%\n",
            "iter 1940: loss 1.8328, time 446.63ms, mfu 0.24%\n",
            "iter 1950: loss 1.6360, time 466.72ms, mfu 0.24%\n",
            "iter 1960: loss 1.6879, time 473.78ms, mfu 0.23%\n",
            "iter 1970: loss 1.6693, time 445.88ms, mfu 0.24%\n",
            "iter 1980: loss 1.6975, time 456.15ms, mfu 0.24%\n",
            "iter 1990: loss 1.6183, time 445.66ms, mfu 0.24%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 20/32: b128_L6_H8_E128_BS8_MI2000_D20_s20 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS8_MI2000_D20_s20.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 20\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1933, val loss 4.1893\n",
            "iter 0: loss 4.2074, time 2507.36ms, mfu -100.00%\n",
            "iter 10: loss 4.1794, time 449.13ms, mfu 0.24%\n",
            "iter 20: loss 4.1523, time 458.97ms, mfu 0.24%\n",
            "iter 30: loss 4.0799, time 467.32ms, mfu 0.24%\n",
            "iter 40: loss 3.9932, time 464.89ms, mfu 0.24%\n",
            "iter 50: loss 3.8942, time 451.16ms, mfu 0.24%\n",
            "iter 60: loss 3.8201, time 446.98ms, mfu 0.24%\n",
            "iter 70: loss 3.7479, time 456.97ms, mfu 0.24%\n",
            "iter 80: loss 3.7152, time 481.93ms, mfu 0.24%\n",
            "iter 90: loss 3.6621, time 455.29ms, mfu 0.24%\n",
            "iter 100: loss 3.6629, time 444.05ms, mfu 0.24%\n",
            "iter 110: loss 3.6293, time 454.93ms, mfu 0.24%\n",
            "iter 120: loss 3.5674, time 453.42ms, mfu 0.24%\n",
            "iter 130: loss 3.5129, time 459.33ms, mfu 0.24%\n",
            "iter 140: loss 3.4713, time 474.25ms, mfu 0.24%\n",
            "iter 150: loss 3.4660, time 444.08ms, mfu 0.24%\n",
            "iter 160: loss 3.4303, time 475.93ms, mfu 0.24%\n",
            "iter 170: loss 3.3865, time 441.98ms, mfu 0.24%\n",
            "iter 180: loss 3.3399, time 469.85ms, mfu 0.24%\n",
            "iter 190: loss 3.2826, time 490.22ms, mfu 0.24%\n",
            "step 200: train loss 3.2431, val loss 3.2522\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 200: loss 3.2943, time 2150.19ms, mfu 0.22%\n",
            "iter 210: loss 3.2180, time 457.56ms, mfu 0.22%\n",
            "iter 220: loss 3.2741, time 437.99ms, mfu 0.22%\n",
            "iter 230: loss 3.2279, time 446.34ms, mfu 0.23%\n",
            "iter 240: loss 3.2099, time 466.76ms, mfu 0.23%\n",
            "iter 250: loss 3.1534, time 455.23ms, mfu 0.23%\n",
            "iter 260: loss 3.1527, time 461.66ms, mfu 0.23%\n",
            "iter 270: loss 3.1200, time 452.94ms, mfu 0.23%\n",
            "iter 280: loss 3.0686, time 476.55ms, mfu 0.23%\n",
            "iter 290: loss 3.0414, time 460.68ms, mfu 0.23%\n",
            "iter 300: loss 3.0295, time 461.37ms, mfu 0.23%\n",
            "iter 310: loss 2.9700, time 450.11ms, mfu 0.23%\n",
            "iter 320: loss 2.9743, time 452.21ms, mfu 0.23%\n",
            "iter 330: loss 2.9079, time 448.72ms, mfu 0.23%\n",
            "iter 340: loss 2.9496, time 447.76ms, mfu 0.24%\n",
            "iter 350: loss 2.8504, time 441.04ms, mfu 0.24%\n",
            "iter 360: loss 2.9090, time 449.72ms, mfu 0.24%\n",
            "iter 370: loss 2.8572, time 446.34ms, mfu 0.24%\n",
            "iter 380: loss 2.8360, time 449.49ms, mfu 0.24%\n",
            "iter 390: loss 2.8615, time 443.31ms, mfu 0.24%\n",
            "step 400: train loss 2.7717, val loss 2.7778\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 400: loss 2.7415, time 2179.70ms, mfu 0.22%\n",
            "iter 410: loss 2.7537, time 455.60ms, mfu 0.22%\n",
            "iter 420: loss 2.7695, time 437.26ms, mfu 0.22%\n",
            "iter 430: loss 2.7366, time 476.17ms, mfu 0.23%\n",
            "iter 440: loss 2.7560, time 441.59ms, mfu 0.23%\n",
            "iter 450: loss 2.6562, time 442.07ms, mfu 0.23%\n",
            "iter 460: loss 2.7147, time 445.88ms, mfu 0.23%\n",
            "iter 470: loss 2.7009, time 445.45ms, mfu 0.23%\n",
            "iter 480: loss 2.6734, time 451.31ms, mfu 0.23%\n",
            "iter 490: loss 2.6786, time 444.94ms, mfu 0.23%\n",
            "iter 500: loss 2.6112, time 459.92ms, mfu 0.23%\n",
            "iter 510: loss 2.6013, time 438.07ms, mfu 0.24%\n",
            "iter 520: loss 2.5937, time 441.97ms, mfu 0.24%\n",
            "iter 530: loss 2.6396, time 445.65ms, mfu 0.24%\n",
            "iter 540: loss 2.5322, time 446.87ms, mfu 0.24%\n",
            "iter 550: loss 2.5638, time 444.43ms, mfu 0.24%\n",
            "iter 560: loss 2.4981, time 455.83ms, mfu 0.24%\n",
            "iter 570: loss 2.5563, time 443.27ms, mfu 0.24%\n",
            "iter 580: loss 2.5472, time 455.39ms, mfu 0.24%\n",
            "iter 590: loss 2.4819, time 455.82ms, mfu 0.24%\n",
            "step 600: train loss 2.4873, val loss 2.4885\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 600: loss 2.5563, time 2164.53ms, mfu 0.22%\n",
            "iter 610: loss 2.4848, time 443.32ms, mfu 0.22%\n",
            "iter 620: loss 2.4829, time 438.06ms, mfu 0.23%\n",
            "iter 630: loss 2.4969, time 448.39ms, mfu 0.23%\n",
            "iter 640: loss 2.4264, time 448.03ms, mfu 0.23%\n",
            "iter 650: loss 2.5030, time 445.02ms, mfu 0.23%\n",
            "iter 660: loss 2.4904, time 461.43ms, mfu 0.23%\n",
            "iter 670: loss 2.5260, time 452.70ms, mfu 0.23%\n",
            "iter 680: loss 2.4701, time 454.64ms, mfu 0.23%\n",
            "iter 690: loss 2.4816, time 454.64ms, mfu 0.23%\n",
            "iter 700: loss 2.4566, time 451.35ms, mfu 0.23%\n",
            "iter 710: loss 2.4767, time 468.37ms, mfu 0.23%\n",
            "iter 720: loss 2.5194, time 458.17ms, mfu 0.24%\n",
            "iter 730: loss 2.4903, time 446.60ms, mfu 0.24%\n",
            "iter 740: loss 2.4516, time 453.25ms, mfu 0.24%\n",
            "iter 750: loss 2.4372, time 436.50ms, mfu 0.24%\n",
            "iter 760: loss 2.4249, time 453.19ms, mfu 0.24%\n",
            "iter 770: loss 2.4514, time 447.60ms, mfu 0.24%\n",
            "iter 780: loss 2.4024, time 446.13ms, mfu 0.24%\n",
            "iter 790: loss 2.4729, time 449.02ms, mfu 0.24%\n",
            "step 800: train loss 2.3384, val loss 2.3488\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 800: loss 2.4096, time 2181.03ms, mfu 0.22%\n",
            "iter 810: loss 2.3851, time 458.55ms, mfu 0.22%\n",
            "iter 820: loss 2.3719, time 461.03ms, mfu 0.22%\n",
            "iter 830: loss 2.3364, time 452.53ms, mfu 0.23%\n",
            "iter 840: loss 2.3448, time 497.44ms, mfu 0.23%\n",
            "iter 850: loss 2.4481, time 476.52ms, mfu 0.23%\n",
            "iter 860: loss 2.4096, time 440.49ms, mfu 0.23%\n",
            "iter 870: loss 2.3318, time 454.16ms, mfu 0.23%\n",
            "iter 880: loss 2.3384, time 445.71ms, mfu 0.23%\n",
            "iter 890: loss 2.3910, time 478.55ms, mfu 0.23%\n",
            "iter 900: loss 2.4057, time 456.57ms, mfu 0.23%\n",
            "iter 910: loss 2.3214, time 460.79ms, mfu 0.23%\n",
            "iter 920: loss 2.3216, time 455.42ms, mfu 0.23%\n",
            "iter 930: loss 2.3469, time 465.47ms, mfu 0.23%\n",
            "iter 940: loss 2.2857, time 439.71ms, mfu 0.23%\n",
            "iter 950: loss 2.3237, time 442.57ms, mfu 0.24%\n",
            "iter 960: loss 2.2931, time 448.55ms, mfu 0.24%\n",
            "iter 970: loss 2.3088, time 448.88ms, mfu 0.24%\n",
            "iter 980: loss 2.3469, time 447.08ms, mfu 0.24%\n",
            "iter 990: loss 2.2688, time 459.94ms, mfu 0.24%\n",
            "step 1000: train loss 2.2022, val loss 2.2337\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1000: loss 2.3627, time 2140.57ms, mfu 0.22%\n",
            "iter 1010: loss 2.2246, time 488.66ms, mfu 0.22%\n",
            "iter 1020: loss 2.2298, time 447.90ms, mfu 0.22%\n",
            "iter 1030: loss 2.3277, time 450.19ms, mfu 0.22%\n",
            "iter 1040: loss 2.2368, time 446.74ms, mfu 0.23%\n",
            "iter 1050: loss 2.2995, time 445.43ms, mfu 0.23%\n",
            "iter 1060: loss 2.2418, time 455.97ms, mfu 0.23%\n",
            "iter 1070: loss 2.2095, time 456.93ms, mfu 0.23%\n",
            "iter 1080: loss 2.3055, time 463.16ms, mfu 0.23%\n",
            "iter 1090: loss 2.2031, time 452.12ms, mfu 0.23%\n",
            "iter 1100: loss 2.2355, time 451.71ms, mfu 0.23%\n",
            "iter 1110: loss 2.2113, time 440.18ms, mfu 0.23%\n",
            "iter 1120: loss 2.1956, time 490.76ms, mfu 0.23%\n",
            "iter 1130: loss 2.2035, time 445.65ms, mfu 0.23%\n",
            "iter 1140: loss 2.1775, time 443.20ms, mfu 0.24%\n",
            "iter 1150: loss 2.2143, time 457.16ms, mfu 0.24%\n",
            "iter 1160: loss 2.2359, time 443.29ms, mfu 0.24%\n",
            "iter 1170: loss 2.1160, time 468.46ms, mfu 0.24%\n",
            "iter 1180: loss 2.1648, time 446.42ms, mfu 0.24%\n",
            "iter 1190: loss 2.2437, time 437.86ms, mfu 0.24%\n",
            "step 1200: train loss 2.0805, val loss 2.1183\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1200: loss 2.2180, time 2155.21ms, mfu 0.22%\n",
            "iter 1210: loss 2.2200, time 444.05ms, mfu 0.22%\n",
            "iter 1220: loss 2.2424, time 445.43ms, mfu 0.22%\n",
            "iter 1230: loss 2.1399, time 451.94ms, mfu 0.23%\n",
            "iter 1240: loss 2.1411, time 443.01ms, mfu 0.23%\n",
            "iter 1250: loss 2.2060, time 445.22ms, mfu 0.23%\n",
            "iter 1260: loss 2.1893, time 439.92ms, mfu 0.23%\n",
            "iter 1270: loss 2.0499, time 456.51ms, mfu 0.23%\n",
            "iter 1280: loss 2.1471, time 458.48ms, mfu 0.23%\n",
            "iter 1290: loss 2.1362, time 453.15ms, mfu 0.23%\n",
            "iter 1300: loss 2.1780, time 446.10ms, mfu 0.24%\n",
            "iter 1310: loss 2.0789, time 460.59ms, mfu 0.24%\n",
            "iter 1320: loss 2.0431, time 445.87ms, mfu 0.24%\n",
            "iter 1330: loss 2.0129, time 445.38ms, mfu 0.24%\n",
            "iter 1340: loss 2.0957, time 467.79ms, mfu 0.24%\n",
            "iter 1350: loss 2.1097, time 448.95ms, mfu 0.24%\n",
            "iter 1360: loss 2.0344, time 480.37ms, mfu 0.24%\n",
            "iter 1370: loss 2.0261, time 459.37ms, mfu 0.24%\n",
            "iter 1380: loss 2.0813, time 471.11ms, mfu 0.24%\n",
            "iter 1390: loss 2.1931, time 469.65ms, mfu 0.24%\n",
            "step 1400: train loss 1.9308, val loss 2.0120\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1400: loss 2.1291, time 2124.01ms, mfu 0.22%\n",
            "iter 1410: loss 2.0479, time 462.71ms, mfu 0.22%\n",
            "iter 1420: loss 2.0967, time 470.73ms, mfu 0.22%\n",
            "iter 1430: loss 2.0831, time 441.44ms, mfu 0.22%\n",
            "iter 1440: loss 2.0177, time 455.89ms, mfu 0.22%\n",
            "iter 1450: loss 1.9517, time 448.97ms, mfu 0.23%\n",
            "iter 1460: loss 2.0035, time 461.78ms, mfu 0.23%\n",
            "iter 1470: loss 1.9562, time 436.77ms, mfu 0.23%\n",
            "iter 1480: loss 2.0272, time 464.41ms, mfu 0.23%\n",
            "iter 1490: loss 1.9781, time 471.94ms, mfu 0.23%\n",
            "iter 1500: loss 1.9974, time 463.73ms, mfu 0.23%\n",
            "iter 1510: loss 1.9695, time 448.49ms, mfu 0.23%\n",
            "iter 1520: loss 1.9171, time 452.00ms, mfu 0.23%\n",
            "iter 1530: loss 1.9869, time 439.34ms, mfu 0.23%\n",
            "iter 1540: loss 1.9255, time 437.11ms, mfu 0.24%\n",
            "iter 1550: loss 1.9336, time 451.23ms, mfu 0.24%\n",
            "iter 1560: loss 1.9264, time 440.35ms, mfu 0.24%\n",
            "iter 1570: loss 1.9571, time 474.59ms, mfu 0.24%\n",
            "iter 1580: loss 1.9796, time 445.80ms, mfu 0.24%\n",
            "iter 1590: loss 2.0397, time 469.25ms, mfu 0.24%\n",
            "step 1600: train loss 1.8255, val loss 1.9416\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1600: loss 1.8824, time 2186.70ms, mfu 0.22%\n",
            "iter 1610: loss 1.9583, time 438.72ms, mfu 0.22%\n",
            "iter 1620: loss 2.0058, time 450.26ms, mfu 0.22%\n",
            "iter 1630: loss 1.8713, time 449.94ms, mfu 0.23%\n",
            "iter 1640: loss 1.7992, time 446.60ms, mfu 0.23%\n",
            "iter 1650: loss 1.9507, time 472.15ms, mfu 0.23%\n",
            "iter 1660: loss 1.9809, time 453.02ms, mfu 0.23%\n",
            "iter 1670: loss 1.9155, time 440.86ms, mfu 0.23%\n",
            "iter 1680: loss 1.9086, time 439.70ms, mfu 0.23%\n",
            "iter 1690: loss 1.8974, time 458.84ms, mfu 0.23%\n",
            "iter 1700: loss 1.9374, time 463.00ms, mfu 0.23%\n",
            "iter 1710: loss 1.9543, time 451.89ms, mfu 0.23%\n",
            "iter 1720: loss 1.8970, time 439.26ms, mfu 0.24%\n",
            "iter 1730: loss 1.9296, time 462.37ms, mfu 0.24%\n",
            "iter 1740: loss 1.8211, time 438.82ms, mfu 0.24%\n",
            "iter 1750: loss 1.8171, time 453.10ms, mfu 0.24%\n",
            "iter 1760: loss 1.8380, time 494.83ms, mfu 0.24%\n",
            "iter 1770: loss 1.8903, time 445.92ms, mfu 0.24%\n",
            "iter 1780: loss 1.8044, time 464.98ms, mfu 0.24%\n",
            "iter 1790: loss 1.7570, time 446.86ms, mfu 0.24%\n",
            "step 1800: train loss 1.7337, val loss 1.8835\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "iter 1800: loss 1.8634, time 2172.68ms, mfu 0.22%\n",
            "iter 1810: loss 1.8233, time 445.65ms, mfu 0.22%\n",
            "iter 1820: loss 1.8357, time 451.44ms, mfu 0.22%\n",
            "iter 1830: loss 1.7983, time 463.47ms, mfu 0.22%\n",
            "iter 1840: loss 1.8455, time 447.72ms, mfu 0.23%\n",
            "iter 1850: loss 1.9214, time 448.17ms, mfu 0.23%\n",
            "iter 1860: loss 1.8358, time 476.43ms, mfu 0.23%\n",
            "iter 1870: loss 1.8179, time 448.20ms, mfu 0.23%\n",
            "iter 1880: loss 1.8710, time 448.51ms, mfu 0.23%\n",
            "iter 1890: loss 1.7302, time 458.07ms, mfu 0.23%\n",
            "iter 1900: loss 1.8141, time 462.88ms, mfu 0.23%\n",
            "iter 1910: loss 1.8237, time 443.26ms, mfu 0.23%\n",
            "iter 1920: loss 2.0110, time 445.38ms, mfu 0.23%\n",
            "iter 1930: loss 1.7865, time 460.37ms, mfu 0.24%\n",
            "iter 1940: loss 1.9434, time 470.87ms, mfu 0.23%\n",
            "iter 1950: loss 1.7587, time 452.37ms, mfu 0.24%\n",
            "iter 1960: loss 1.8139, time 468.30ms, mfu 0.24%\n",
            "iter 1970: loss 1.8150, time 452.70ms, mfu 0.24%\n",
            "iter 1980: loss 1.8060, time 453.01ms, mfu 0.24%\n",
            "iter 1990: loss 1.7516, time 469.48ms, mfu 0.24%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 21/32: b128_L6_H8_E128_BS16_MI1000_D10_s21 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS16_MI1000_D10_s21.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D10_s21\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 21\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1942, val loss 4.1893\n",
            "iter 0: loss 4.1963, time 2616.72ms, mfu -100.00%\n",
            "iter 10: loss 4.1663, time 457.35ms, mfu 0.48%\n",
            "iter 20: loss 4.1328, time 456.97ms, mfu 0.48%\n",
            "iter 30: loss 4.0617, time 467.95ms, mfu 0.48%\n",
            "iter 40: loss 3.9607, time 452.87ms, mfu 0.48%\n",
            "iter 50: loss 3.8711, time 461.07ms, mfu 0.48%\n",
            "iter 60: loss 3.7788, time 476.99ms, mfu 0.47%\n",
            "iter 70: loss 3.7330, time 458.09ms, mfu 0.48%\n",
            "iter 80: loss 3.7121, time 458.44ms, mfu 0.48%\n",
            "iter 90: loss 3.6453, time 453.80ms, mfu 0.48%\n",
            "iter 100: loss 3.6243, time 465.76ms, mfu 0.48%\n",
            "iter 110: loss 3.5666, time 458.18ms, mfu 0.48%\n",
            "iter 120: loss 3.4910, time 461.47ms, mfu 0.48%\n",
            "iter 130: loss 3.4653, time 452.88ms, mfu 0.48%\n",
            "iter 140: loss 3.4136, time 464.73ms, mfu 0.48%\n",
            "iter 150: loss 3.3880, time 464.27ms, mfu 0.47%\n",
            "iter 160: loss 3.3724, time 462.07ms, mfu 0.47%\n",
            "iter 170: loss 3.3335, time 487.14ms, mfu 0.47%\n",
            "iter 180: loss 3.2881, time 486.46ms, mfu 0.47%\n",
            "iter 190: loss 3.2893, time 454.88ms, mfu 0.47%\n",
            "step 200: train loss 3.2260, val loss 3.2344\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 200: loss 3.2422, time 2280.57ms, mfu 0.43%\n",
            "iter 210: loss 3.2230, time 497.65ms, mfu 0.43%\n",
            "iter 220: loss 3.1746, time 460.24ms, mfu 0.44%\n",
            "iter 230: loss 3.1994, time 471.33ms, mfu 0.44%\n",
            "iter 240: loss 3.1291, time 456.27ms, mfu 0.44%\n",
            "iter 250: loss 3.1424, time 454.87ms, mfu 0.45%\n",
            "iter 260: loss 3.0868, time 500.79ms, mfu 0.45%\n",
            "iter 270: loss 3.0735, time 470.05ms, mfu 0.45%\n",
            "iter 280: loss 3.0311, time 455.57ms, mfu 0.45%\n",
            "iter 290: loss 3.0220, time 464.45ms, mfu 0.45%\n",
            "iter 300: loss 3.0049, time 464.09ms, mfu 0.46%\n",
            "iter 310: loss 3.0141, time 464.16ms, mfu 0.46%\n",
            "iter 320: loss 2.9164, time 454.66ms, mfu 0.46%\n",
            "iter 330: loss 2.9075, time 493.75ms, mfu 0.46%\n",
            "iter 340: loss 2.9035, time 470.93ms, mfu 0.46%\n",
            "iter 350: loss 2.8830, time 462.42ms, mfu 0.46%\n",
            "iter 360: loss 2.8366, time 462.84ms, mfu 0.46%\n",
            "iter 370: loss 2.8527, time 466.86ms, mfu 0.46%\n",
            "iter 380: loss 2.8366, time 457.59ms, mfu 0.46%\n",
            "iter 390: loss 2.7429, time 493.02ms, mfu 0.46%\n",
            "step 400: train loss 2.7397, val loss 2.7525\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 400: loss 2.7619, time 2315.56ms, mfu 0.42%\n",
            "iter 410: loss 2.7253, time 496.43ms, mfu 0.43%\n",
            "iter 420: loss 2.7573, time 470.03ms, mfu 0.43%\n",
            "iter 430: loss 2.6820, time 486.01ms, mfu 0.43%\n",
            "iter 440: loss 2.6767, time 481.66ms, mfu 0.43%\n",
            "iter 450: loss 2.6732, time 464.24ms, mfu 0.44%\n",
            "iter 460: loss 2.6799, time 509.79ms, mfu 0.44%\n",
            "iter 470: loss 2.6320, time 482.99ms, mfu 0.44%\n",
            "iter 480: loss 2.6040, time 454.67ms, mfu 0.44%\n",
            "iter 490: loss 2.6357, time 538.63ms, mfu 0.44%\n",
            "iter 500: loss 2.5758, time 480.67ms, mfu 0.44%\n",
            "iter 510: loss 2.5605, time 456.02ms, mfu 0.44%\n",
            "iter 520: loss 2.5790, time 468.61ms, mfu 0.45%\n",
            "iter 530: loss 2.5337, time 457.45ms, mfu 0.45%\n",
            "iter 540: loss 2.5533, time 458.22ms, mfu 0.45%\n",
            "iter 550: loss 2.5570, time 461.41ms, mfu 0.45%\n",
            "iter 560: loss 2.5305, time 454.00ms, mfu 0.46%\n",
            "iter 570: loss 2.4701, time 464.52ms, mfu 0.46%\n",
            "iter 580: loss 2.4868, time 460.58ms, mfu 0.46%\n",
            "iter 590: loss 2.5236, time 462.27ms, mfu 0.46%\n",
            "step 600: train loss 2.4371, val loss 2.4430\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 600: loss 2.4717, time 2256.89ms, mfu 0.42%\n",
            "iter 610: loss 2.4861, time 460.50ms, mfu 0.43%\n",
            "iter 620: loss 2.5253, time 464.77ms, mfu 0.43%\n",
            "iter 630: loss 2.4187, time 447.39ms, mfu 0.44%\n",
            "iter 640: loss 2.4471, time 476.11ms, mfu 0.44%\n",
            "iter 650: loss 2.3939, time 456.34ms, mfu 0.44%\n",
            "iter 660: loss 2.4002, time 468.69ms, mfu 0.45%\n",
            "iter 670: loss 2.4475, time 467.97ms, mfu 0.45%\n",
            "iter 680: loss 2.3994, time 471.33ms, mfu 0.45%\n",
            "iter 690: loss 2.3873, time 452.47ms, mfu 0.45%\n",
            "iter 700: loss 2.3336, time 479.41ms, mfu 0.45%\n",
            "iter 710: loss 2.3718, time 456.11ms, mfu 0.46%\n",
            "iter 720: loss 2.3911, time 516.73ms, mfu 0.45%\n",
            "iter 730: loss 2.3750, time 458.35ms, mfu 0.46%\n",
            "iter 740: loss 2.3232, time 460.79ms, mfu 0.46%\n",
            "iter 750: loss 2.3500, time 453.47ms, mfu 0.46%\n",
            "iter 760: loss 2.2906, time 485.93ms, mfu 0.46%\n",
            "iter 770: loss 2.3268, time 456.27ms, mfu 0.46%\n",
            "iter 780: loss 2.3326, time 503.52ms, mfu 0.46%\n",
            "iter 790: loss 2.2944, time 451.62ms, mfu 0.46%\n",
            "step 800: train loss 2.2681, val loss 2.2900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 800: loss 2.3310, time 2283.28ms, mfu 0.42%\n",
            "iter 810: loss 2.3154, time 458.32ms, mfu 0.43%\n",
            "iter 820: loss 2.2675, time 461.85ms, mfu 0.43%\n",
            "iter 830: loss 2.2839, time 486.21ms, mfu 0.44%\n",
            "iter 840: loss 2.3272, time 468.55ms, mfu 0.44%\n",
            "iter 850: loss 2.3057, time 464.57ms, mfu 0.44%\n",
            "iter 860: loss 2.2997, time 452.40ms, mfu 0.45%\n",
            "iter 870: loss 2.2702, time 465.82ms, mfu 0.45%\n",
            "iter 880: loss 2.2639, time 475.10ms, mfu 0.45%\n",
            "iter 890: loss 2.2744, time 457.13ms, mfu 0.45%\n",
            "iter 900: loss 2.2340, time 488.99ms, mfu 0.45%\n",
            "iter 910: loss 2.2542, time 455.71ms, mfu 0.45%\n",
            "iter 920: loss 2.2717, time 491.38ms, mfu 0.45%\n",
            "iter 930: loss 2.1834, time 466.51ms, mfu 0.45%\n",
            "iter 940: loss 2.2294, time 454.96ms, mfu 0.46%\n",
            "iter 950: loss 2.2038, time 473.16ms, mfu 0.46%\n",
            "iter 960: loss 2.1890, time 468.52ms, mfu 0.46%\n",
            "iter 970: loss 2.1702, time 456.31ms, mfu 0.46%\n",
            "iter 980: loss 2.1814, time 465.03ms, mfu 0.46%\n",
            "iter 990: loss 2.2305, time 450.78ms, mfu 0.46%\n",
            "step 1000: train loss 2.1019, val loss 2.1369\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D10_s21\n",
            "iter 1000: loss 2.2102, time 2247.52ms, mfu 0.43%\n",
            "\n",
            "=== Experiment 22/32: b128_L6_H8_E128_BS16_MI1000_D20_s22 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS16_MI1000_D20_s22.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D20_s22\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 22\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1942, val loss 4.1893\n",
            "iter 0: loss 4.1965, time 2635.13ms, mfu -100.00%\n",
            "iter 10: loss 4.1676, time 482.45ms, mfu 0.45%\n",
            "iter 20: loss 4.1373, time 455.72ms, mfu 0.46%\n",
            "iter 30: loss 4.0793, time 475.38ms, mfu 0.46%\n",
            "iter 40: loss 3.9860, time 464.17ms, mfu 0.46%\n",
            "iter 50: loss 3.9000, time 486.56ms, mfu 0.46%\n",
            "iter 60: loss 3.8019, time 480.85ms, mfu 0.46%\n",
            "iter 70: loss 3.7559, time 480.35ms, mfu 0.46%\n",
            "iter 80: loss 3.7338, time 453.51ms, mfu 0.46%\n",
            "iter 90: loss 3.6720, time 486.15ms, mfu 0.46%\n",
            "iter 100: loss 3.6566, time 489.40ms, mfu 0.46%\n",
            "iter 110: loss 3.6112, time 456.38ms, mfu 0.46%\n",
            "iter 120: loss 3.5360, time 484.57ms, mfu 0.46%\n",
            "iter 130: loss 3.5087, time 471.67ms, mfu 0.46%\n",
            "iter 140: loss 3.4575, time 496.41ms, mfu 0.46%\n",
            "iter 150: loss 3.4307, time 467.95ms, mfu 0.46%\n",
            "iter 160: loss 3.4069, time 470.06ms, mfu 0.46%\n",
            "iter 170: loss 3.3722, time 456.80ms, mfu 0.46%\n",
            "iter 180: loss 3.3251, time 455.60ms, mfu 0.46%\n",
            "iter 190: loss 3.3228, time 483.79ms, mfu 0.46%\n",
            "step 200: train loss 3.2395, val loss 3.2499\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 200: loss 3.2780, time 2301.33ms, mfu 0.42%\n",
            "iter 210: loss 3.2631, time 470.73ms, mfu 0.43%\n",
            "iter 220: loss 3.2080, time 485.65ms, mfu 0.43%\n",
            "iter 230: loss 3.2330, time 457.54ms, mfu 0.44%\n",
            "iter 240: loss 3.1653, time 459.26ms, mfu 0.44%\n",
            "iter 250: loss 3.1693, time 465.28ms, mfu 0.44%\n",
            "iter 260: loss 3.1119, time 484.76ms, mfu 0.44%\n",
            "iter 270: loss 3.1052, time 458.64ms, mfu 0.45%\n",
            "iter 280: loss 3.0565, time 466.40ms, mfu 0.45%\n",
            "iter 290: loss 3.0507, time 466.35ms, mfu 0.45%\n",
            "iter 300: loss 3.0364, time 462.12ms, mfu 0.45%\n",
            "iter 310: loss 3.0421, time 491.85ms, mfu 0.45%\n",
            "iter 320: loss 2.9398, time 460.54ms, mfu 0.45%\n",
            "iter 330: loss 2.9277, time 451.48ms, mfu 0.46%\n",
            "iter 340: loss 2.9291, time 473.98ms, mfu 0.46%\n",
            "iter 350: loss 2.9058, time 462.99ms, mfu 0.46%\n",
            "iter 360: loss 2.8648, time 462.39ms, mfu 0.46%\n",
            "iter 370: loss 2.8792, time 490.01ms, mfu 0.46%\n",
            "iter 380: loss 2.8653, time 462.94ms, mfu 0.46%\n",
            "iter 390: loss 2.7643, time 458.67ms, mfu 0.46%\n",
            "step 400: train loss 2.7593, val loss 2.7705\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 400: loss 2.7923, time 2259.86ms, mfu 0.43%\n",
            "iter 410: loss 2.7525, time 456.19ms, mfu 0.43%\n",
            "iter 420: loss 2.7782, time 459.61ms, mfu 0.43%\n",
            "iter 430: loss 2.7097, time 462.51ms, mfu 0.44%\n",
            "iter 440: loss 2.7068, time 457.60ms, mfu 0.44%\n",
            "iter 450: loss 2.6969, time 462.56ms, mfu 0.45%\n",
            "iter 460: loss 2.7120, time 471.58ms, mfu 0.45%\n",
            "iter 470: loss 2.6585, time 471.03ms, mfu 0.45%\n",
            "iter 480: loss 2.6356, time 474.07ms, mfu 0.45%\n",
            "iter 490: loss 2.6707, time 491.89ms, mfu 0.45%\n",
            "iter 500: loss 2.6089, time 460.68ms, mfu 0.45%\n",
            "iter 510: loss 2.5872, time 468.68ms, mfu 0.45%\n",
            "iter 520: loss 2.6046, time 458.41ms, mfu 0.46%\n",
            "iter 530: loss 2.5667, time 465.49ms, mfu 0.46%\n",
            "iter 540: loss 2.5829, time 475.22ms, mfu 0.46%\n",
            "iter 550: loss 2.5851, time 458.45ms, mfu 0.46%\n",
            "iter 560: loss 2.5669, time 460.03ms, mfu 0.46%\n",
            "iter 570: loss 2.5081, time 471.95ms, mfu 0.46%\n",
            "iter 580: loss 2.5159, time 454.93ms, mfu 0.46%\n",
            "iter 590: loss 2.5642, time 490.93ms, mfu 0.46%\n",
            "step 600: train loss 2.4678, val loss 2.4706\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 600: loss 2.5062, time 2270.81ms, mfu 0.42%\n",
            "iter 610: loss 2.5091, time 464.00ms, mfu 0.43%\n",
            "iter 620: loss 2.5468, time 473.18ms, mfu 0.43%\n",
            "iter 630: loss 2.4617, time 468.28ms, mfu 0.44%\n",
            "iter 640: loss 2.4799, time 464.05ms, mfu 0.44%\n",
            "iter 650: loss 2.4321, time 456.55ms, mfu 0.44%\n",
            "iter 660: loss 2.4378, time 453.24ms, mfu 0.45%\n",
            "iter 670: loss 2.4813, time 472.49ms, mfu 0.45%\n",
            "iter 680: loss 2.4368, time 471.60ms, mfu 0.45%\n",
            "iter 690: loss 2.4325, time 459.19ms, mfu 0.45%\n",
            "iter 700: loss 2.3721, time 492.14ms, mfu 0.45%\n",
            "iter 710: loss 2.4054, time 468.86ms, mfu 0.45%\n",
            "iter 720: loss 2.4242, time 500.69ms, mfu 0.45%\n",
            "iter 730: loss 2.4077, time 457.62ms, mfu 0.45%\n",
            "iter 740: loss 2.3627, time 458.44ms, mfu 0.46%\n",
            "iter 750: loss 2.3979, time 478.89ms, mfu 0.46%\n",
            "iter 760: loss 2.3260, time 478.35ms, mfu 0.46%\n",
            "iter 770: loss 2.3699, time 464.84ms, mfu 0.46%\n",
            "iter 780: loss 2.3763, time 459.13ms, mfu 0.46%\n",
            "iter 790: loss 2.3340, time 467.81ms, mfu 0.46%\n",
            "step 800: train loss 2.2987, val loss 2.3141\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 800: loss 2.3655, time 2312.50ms, mfu 0.42%\n",
            "iter 810: loss 2.3718, time 463.06ms, mfu 0.43%\n",
            "iter 820: loss 2.2987, time 474.88ms, mfu 0.43%\n",
            "iter 830: loss 2.3364, time 464.74ms, mfu 0.44%\n",
            "iter 840: loss 2.3795, time 462.66ms, mfu 0.44%\n",
            "iter 850: loss 2.3394, time 463.77ms, mfu 0.44%\n",
            "iter 860: loss 2.3437, time 535.52ms, mfu 0.44%\n",
            "iter 870: loss 2.3370, time 466.61ms, mfu 0.44%\n",
            "iter 880: loss 2.3273, time 461.51ms, mfu 0.44%\n",
            "iter 890: loss 2.3269, time 460.64ms, mfu 0.45%\n",
            "iter 900: loss 2.2886, time 483.10ms, mfu 0.45%\n",
            "iter 910: loss 2.2998, time 456.32ms, mfu 0.45%\n",
            "iter 920: loss 2.3453, time 457.66ms, mfu 0.45%\n",
            "iter 930: loss 2.2310, time 495.54ms, mfu 0.45%\n",
            "iter 940: loss 2.2793, time 469.74ms, mfu 0.45%\n",
            "iter 950: loss 2.2824, time 468.97ms, mfu 0.45%\n",
            "iter 960: loss 2.2615, time 484.44ms, mfu 0.45%\n",
            "iter 970: loss 2.2535, time 460.99ms, mfu 0.46%\n",
            "iter 980: loss 2.2419, time 452.34ms, mfu 0.46%\n",
            "iter 990: loss 2.3124, time 472.89ms, mfu 0.46%\n",
            "step 1000: train loss 2.1573, val loss 2.1817\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI1000_D20_s22\n",
            "iter 1000: loss 2.2724, time 2305.39ms, mfu 0.42%\n",
            "\n",
            "=== Experiment 23/32: b128_L6_H8_E128_BS16_MI2000_D10_s23 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS16_MI2000_D10_s23.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 23\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1942, val loss 4.1893\n",
            "iter 0: loss 4.1963, time 2631.03ms, mfu -100.00%\n",
            "iter 10: loss 4.1663, time 484.64ms, mfu 0.45%\n",
            "iter 20: loss 4.1328, time 484.55ms, mfu 0.45%\n",
            "iter 30: loss 4.0617, time 458.57ms, mfu 0.45%\n",
            "iter 40: loss 3.9607, time 469.84ms, mfu 0.45%\n",
            "iter 50: loss 3.8711, time 469.60ms, mfu 0.46%\n",
            "iter 60: loss 3.7788, time 484.79ms, mfu 0.45%\n",
            "iter 70: loss 3.7330, time 465.97ms, mfu 0.46%\n",
            "iter 80: loss 3.7121, time 466.71ms, mfu 0.46%\n",
            "iter 90: loss 3.6453, time 480.33ms, mfu 0.46%\n",
            "iter 100: loss 3.6243, time 460.78ms, mfu 0.46%\n",
            "iter 110: loss 3.5666, time 455.24ms, mfu 0.46%\n",
            "iter 120: loss 3.4910, time 480.39ms, mfu 0.46%\n",
            "iter 130: loss 3.4653, time 493.92ms, mfu 0.46%\n",
            "iter 140: loss 3.4136, time 472.32ms, mfu 0.46%\n",
            "iter 150: loss 3.3880, time 459.81ms, mfu 0.46%\n",
            "iter 160: loss 3.3724, time 482.15ms, mfu 0.46%\n",
            "iter 170: loss 3.3335, time 458.35ms, mfu 0.46%\n",
            "iter 180: loss 3.2881, time 462.83ms, mfu 0.46%\n",
            "iter 190: loss 3.2893, time 478.17ms, mfu 0.46%\n",
            "step 200: train loss 3.2260, val loss 3.2344\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 200: loss 3.2422, time 2271.43ms, mfu 0.43%\n",
            "iter 210: loss 3.2230, time 475.37ms, mfu 0.43%\n",
            "iter 220: loss 3.1746, time 487.17ms, mfu 0.43%\n",
            "iter 230: loss 3.1994, time 466.26ms, mfu 0.43%\n",
            "iter 240: loss 3.1291, time 466.04ms, mfu 0.44%\n",
            "iter 250: loss 3.1424, time 466.15ms, mfu 0.44%\n",
            "iter 260: loss 3.0868, time 458.27ms, mfu 0.44%\n",
            "iter 270: loss 3.0735, time 472.74ms, mfu 0.45%\n",
            "iter 280: loss 3.0311, time 497.84ms, mfu 0.45%\n",
            "iter 290: loss 3.0220, time 485.61ms, mfu 0.45%\n",
            "iter 300: loss 3.0049, time 456.14ms, mfu 0.45%\n",
            "iter 310: loss 3.0141, time 460.34ms, mfu 0.45%\n",
            "iter 320: loss 2.9164, time 478.44ms, mfu 0.45%\n",
            "iter 330: loss 2.9075, time 463.66ms, mfu 0.45%\n",
            "iter 340: loss 2.9035, time 499.84ms, mfu 0.45%\n",
            "iter 350: loss 2.8830, time 500.83ms, mfu 0.45%\n",
            "iter 360: loss 2.8366, time 459.19ms, mfu 0.45%\n",
            "iter 370: loss 2.8527, time 464.01ms, mfu 0.45%\n",
            "iter 380: loss 2.8366, time 463.98ms, mfu 0.46%\n",
            "iter 390: loss 2.7429, time 468.00ms, mfu 0.46%\n",
            "step 400: train loss 2.7397, val loss 2.7525\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 400: loss 2.7619, time 2327.18ms, mfu 0.42%\n",
            "iter 410: loss 2.7253, time 498.51ms, mfu 0.42%\n",
            "iter 420: loss 2.7573, time 471.27ms, mfu 0.43%\n",
            "iter 430: loss 2.6820, time 481.69ms, mfu 0.43%\n",
            "iter 440: loss 2.6767, time 482.64ms, mfu 0.43%\n",
            "iter 450: loss 2.6732, time 474.83ms, mfu 0.43%\n",
            "iter 460: loss 2.6799, time 462.84ms, mfu 0.44%\n",
            "iter 470: loss 2.6320, time 484.88ms, mfu 0.44%\n",
            "iter 480: loss 2.6040, time 475.90ms, mfu 0.44%\n",
            "iter 490: loss 2.6357, time 495.84ms, mfu 0.44%\n",
            "iter 500: loss 2.5758, time 466.61ms, mfu 0.44%\n",
            "iter 510: loss 2.5605, time 486.28ms, mfu 0.44%\n",
            "iter 520: loss 2.5790, time 474.02ms, mfu 0.45%\n",
            "iter 530: loss 2.5337, time 454.84ms, mfu 0.45%\n",
            "iter 540: loss 2.5533, time 481.61ms, mfu 0.45%\n",
            "iter 550: loss 2.5570, time 485.91ms, mfu 0.45%\n",
            "iter 560: loss 2.5305, time 456.63ms, mfu 0.45%\n",
            "iter 570: loss 2.4701, time 471.62ms, mfu 0.45%\n",
            "iter 580: loss 2.4868, time 459.23ms, mfu 0.46%\n",
            "iter 590: loss 2.5236, time 459.32ms, mfu 0.46%\n",
            "step 600: train loss 2.4371, val loss 2.4430\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 600: loss 2.4717, time 2270.66ms, mfu 0.42%\n",
            "iter 610: loss 2.4861, time 456.78ms, mfu 0.43%\n",
            "iter 620: loss 2.5253, time 472.10ms, mfu 0.43%\n",
            "iter 630: loss 2.4187, time 471.28ms, mfu 0.43%\n",
            "iter 640: loss 2.4471, time 476.35ms, mfu 0.44%\n",
            "iter 650: loss 2.3939, time 457.21ms, mfu 0.44%\n",
            "iter 660: loss 2.4002, time 483.30ms, mfu 0.44%\n",
            "iter 670: loss 2.4475, time 471.97ms, mfu 0.44%\n",
            "iter 680: loss 2.3994, time 462.56ms, mfu 0.45%\n",
            "iter 690: loss 2.3873, time 459.54ms, mfu 0.45%\n",
            "iter 700: loss 2.3336, time 474.72ms, mfu 0.45%\n",
            "iter 710: loss 2.3718, time 459.20ms, mfu 0.45%\n",
            "iter 720: loss 2.3911, time 472.83ms, mfu 0.45%\n",
            "iter 730: loss 2.3750, time 474.78ms, mfu 0.45%\n",
            "iter 740: loss 2.3232, time 461.14ms, mfu 0.46%\n",
            "iter 750: loss 2.3500, time 462.84ms, mfu 0.46%\n",
            "iter 760: loss 2.2906, time 457.90ms, mfu 0.46%\n",
            "iter 770: loss 2.3268, time 459.51ms, mfu 0.46%\n",
            "iter 780: loss 2.3326, time 470.55ms, mfu 0.46%\n",
            "iter 790: loss 2.2944, time 459.93ms, mfu 0.46%\n",
            "step 800: train loss 2.2681, val loss 2.2900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 800: loss 2.3310, time 2262.99ms, mfu 0.43%\n",
            "iter 810: loss 2.3154, time 473.97ms, mfu 0.43%\n",
            "iter 820: loss 2.2675, time 472.46ms, mfu 0.43%\n",
            "iter 830: loss 2.2839, time 473.65ms, mfu 0.44%\n",
            "iter 840: loss 2.3272, time 463.83ms, mfu 0.44%\n",
            "iter 850: loss 2.3057, time 472.98ms, mfu 0.44%\n",
            "iter 860: loss 2.2997, time 459.88ms, mfu 0.44%\n",
            "iter 870: loss 2.2702, time 492.01ms, mfu 0.44%\n",
            "iter 880: loss 2.2639, time 464.69ms, mfu 0.45%\n",
            "iter 890: loss 2.2744, time 459.61ms, mfu 0.45%\n",
            "iter 900: loss 2.2340, time 487.95ms, mfu 0.45%\n",
            "iter 910: loss 2.2542, time 496.46ms, mfu 0.45%\n",
            "iter 920: loss 2.2717, time 478.15ms, mfu 0.45%\n",
            "iter 930: loss 2.1834, time 466.16ms, mfu 0.45%\n",
            "iter 940: loss 2.2294, time 456.68ms, mfu 0.45%\n",
            "iter 950: loss 2.2038, time 507.97ms, mfu 0.45%\n",
            "iter 960: loss 2.1890, time 463.13ms, mfu 0.45%\n",
            "iter 970: loss 2.1702, time 462.05ms, mfu 0.46%\n",
            "iter 980: loss 2.1814, time 468.52ms, mfu 0.46%\n",
            "iter 990: loss 2.2305, time 500.17ms, mfu 0.45%\n",
            "step 1000: train loss 2.1019, val loss 2.1369\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1000: loss 2.2102, time 2315.49ms, mfu 0.42%\n",
            "iter 1010: loss 2.1756, time 495.84ms, mfu 0.42%\n",
            "iter 1020: loss 2.1764, time 492.47ms, mfu 0.42%\n",
            "iter 1030: loss 2.1953, time 476.45ms, mfu 0.43%\n",
            "iter 1040: loss 2.0871, time 467.92ms, mfu 0.43%\n",
            "iter 1050: loss 2.1289, time 492.70ms, mfu 0.43%\n",
            "iter 1060: loss 2.1592, time 466.32ms, mfu 0.44%\n",
            "iter 1070: loss 2.0971, time 472.82ms, mfu 0.44%\n",
            "iter 1080: loss 2.1481, time 455.72ms, mfu 0.44%\n",
            "iter 1090: loss 2.1267, time 468.91ms, mfu 0.44%\n",
            "iter 1100: loss 2.0799, time 475.03ms, mfu 0.45%\n",
            "iter 1110: loss 2.0611, time 458.65ms, mfu 0.45%\n",
            "iter 1120: loss 2.0834, time 475.05ms, mfu 0.45%\n",
            "iter 1130: loss 2.1052, time 457.81ms, mfu 0.45%\n",
            "iter 1140: loss 2.0321, time 469.06ms, mfu 0.45%\n",
            "iter 1150: loss 2.0510, time 463.98ms, mfu 0.46%\n",
            "iter 1160: loss 2.0857, time 455.51ms, mfu 0.46%\n",
            "iter 1170: loss 2.0592, time 464.25ms, mfu 0.46%\n",
            "iter 1180: loss 2.0621, time 473.40ms, mfu 0.46%\n",
            "iter 1190: loss 2.0027, time 499.12ms, mfu 0.46%\n",
            "step 1200: train loss 1.9109, val loss 1.9952\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1200: loss 1.9707, time 2272.73ms, mfu 0.42%\n",
            "iter 1210: loss 1.9875, time 461.18ms, mfu 0.43%\n",
            "iter 1220: loss 1.9430, time 492.76ms, mfu 0.43%\n",
            "iter 1230: loss 1.9846, time 461.92ms, mfu 0.43%\n",
            "iter 1240: loss 2.0185, time 463.29ms, mfu 0.44%\n",
            "iter 1250: loss 1.9520, time 469.32ms, mfu 0.44%\n",
            "iter 1260: loss 1.9841, time 465.47ms, mfu 0.44%\n",
            "iter 1270: loss 1.9423, time 462.03ms, mfu 0.45%\n",
            "iter 1280: loss 1.9123, time 474.08ms, mfu 0.45%\n",
            "iter 1290: loss 1.9416, time 465.09ms, mfu 0.45%\n",
            "iter 1300: loss 1.8754, time 491.25ms, mfu 0.45%\n",
            "iter 1310: loss 1.8981, time 474.03ms, mfu 0.45%\n",
            "iter 1320: loss 1.9490, time 459.20ms, mfu 0.45%\n",
            "iter 1330: loss 1.9576, time 469.76ms, mfu 0.45%\n",
            "iter 1340: loss 1.9295, time 462.51ms, mfu 0.46%\n",
            "iter 1350: loss 1.8753, time 480.85ms, mfu 0.46%\n",
            "iter 1360: loss 1.8521, time 458.09ms, mfu 0.46%\n",
            "iter 1370: loss 1.8640, time 453.87ms, mfu 0.46%\n",
            "iter 1380: loss 1.9233, time 485.49ms, mfu 0.46%\n",
            "iter 1390: loss 1.8912, time 461.69ms, mfu 0.46%\n",
            "step 1400: train loss 1.7611, val loss 1.8937\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1400: loss 1.8548, time 2355.57ms, mfu 0.42%\n",
            "iter 1410: loss 1.9179, time 463.97ms, mfu 0.43%\n",
            "iter 1420: loss 1.8324, time 471.62ms, mfu 0.43%\n",
            "iter 1430: loss 1.7950, time 466.15ms, mfu 0.44%\n",
            "iter 1440: loss 1.8437, time 466.05ms, mfu 0.44%\n",
            "iter 1450: loss 1.7726, time 464.40ms, mfu 0.44%\n",
            "iter 1460: loss 1.8144, time 454.67ms, mfu 0.45%\n",
            "iter 1470: loss 1.7943, time 462.72ms, mfu 0.45%\n",
            "iter 1480: loss 1.7657, time 458.26ms, mfu 0.45%\n",
            "iter 1490: loss 1.8390, time 457.57ms, mfu 0.45%\n",
            "iter 1500: loss 1.7642, time 484.33ms, mfu 0.45%\n",
            "iter 1510: loss 1.8317, time 470.33ms, mfu 0.45%\n",
            "iter 1520: loss 1.8102, time 463.45ms, mfu 0.46%\n",
            "iter 1530: loss 1.8214, time 532.20ms, mfu 0.45%\n",
            "iter 1540: loss 1.7690, time 469.72ms, mfu 0.45%\n",
            "iter 1550: loss 1.7477, time 463.87ms, mfu 0.45%\n",
            "iter 1560: loss 1.7290, time 466.28ms, mfu 0.46%\n",
            "iter 1570: loss 1.7323, time 469.82ms, mfu 0.46%\n",
            "iter 1580: loss 1.7737, time 488.56ms, mfu 0.46%\n",
            "iter 1590: loss 1.7937, time 463.98ms, mfu 0.46%\n",
            "step 1600: train loss 1.6492, val loss 1.8094\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1600: loss 1.7940, time 2389.79ms, mfu 0.42%\n",
            "iter 1610: loss 1.7731, time 494.37ms, mfu 0.42%\n",
            "iter 1620: loss 1.7775, time 476.42ms, mfu 0.43%\n",
            "iter 1630: loss 1.7531, time 458.84ms, mfu 0.43%\n",
            "iter 1640: loss 1.7793, time 472.28ms, mfu 0.43%\n",
            "iter 1650: loss 1.7018, time 478.14ms, mfu 0.44%\n",
            "iter 1660: loss 1.6997, time 463.11ms, mfu 0.44%\n",
            "iter 1670: loss 1.6700, time 462.75ms, mfu 0.44%\n",
            "iter 1680: loss 1.7345, time 492.90ms, mfu 0.44%\n",
            "iter 1690: loss 1.7015, time 494.18ms, mfu 0.44%\n",
            "iter 1700: loss 1.6321, time 452.55ms, mfu 0.45%\n",
            "iter 1710: loss 1.7065, time 464.14ms, mfu 0.45%\n",
            "iter 1720: loss 1.7132, time 467.55ms, mfu 0.45%\n",
            "iter 1730: loss 1.6944, time 477.44ms, mfu 0.45%\n",
            "iter 1740: loss 1.7267, time 494.81ms, mfu 0.45%\n",
            "iter 1750: loss 1.6790, time 466.59ms, mfu 0.45%\n",
            "iter 1760: loss 1.7208, time 469.53ms, mfu 0.45%\n",
            "iter 1770: loss 1.7171, time 460.96ms, mfu 0.46%\n",
            "iter 1780: loss 1.7553, time 487.62ms, mfu 0.46%\n",
            "iter 1790: loss 1.6995, time 463.69ms, mfu 0.46%\n",
            "step 1800: train loss 1.5632, val loss 1.7436\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "iter 1800: loss 1.6538, time 2295.53ms, mfu 0.42%\n",
            "iter 1810: loss 1.6304, time 481.50ms, mfu 0.42%\n",
            "iter 1820: loss 1.6127, time 460.38ms, mfu 0.43%\n",
            "iter 1830: loss 1.5953, time 474.17ms, mfu 0.43%\n",
            "iter 1840: loss 1.6373, time 463.19ms, mfu 0.44%\n",
            "iter 1850: loss 1.6079, time 467.14ms, mfu 0.44%\n",
            "iter 1860: loss 1.6304, time 470.02ms, mfu 0.44%\n",
            "iter 1870: loss 1.5415, time 466.90ms, mfu 0.44%\n",
            "iter 1880: loss 1.6934, time 475.78ms, mfu 0.45%\n",
            "iter 1890: loss 1.6989, time 486.77ms, mfu 0.45%\n",
            "iter 1900: loss 1.6329, time 469.63ms, mfu 0.45%\n",
            "iter 1910: loss 1.6058, time 486.14ms, mfu 0.45%\n",
            "iter 1920: loss 1.5932, time 477.11ms, mfu 0.45%\n",
            "iter 1930: loss 1.5745, time 479.11ms, mfu 0.45%\n",
            "iter 1940: loss 1.5938, time 463.13ms, mfu 0.45%\n",
            "iter 1950: loss 1.6602, time 467.19ms, mfu 0.45%\n",
            "iter 1960: loss 1.6396, time 463.58ms, mfu 0.46%\n",
            "iter 1970: loss 1.6484, time 492.56ms, mfu 0.45%\n",
            "iter 1980: loss 1.5980, time 482.53ms, mfu 0.45%\n",
            "iter 1990: loss 1.6624, time 536.39ms, mfu 0.45%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 24/32: b128_L6_H8_E128_BS16_MI2000_D20_s24 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E128_BS16_MI2000_D20_s24.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 128\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 24\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.19M\n",
            "num decayed parameter tensors: 26, with 1,204,352 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,664 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.1942, val loss 4.1893\n",
            "iter 0: loss 4.1965, time 2680.26ms, mfu -100.00%\n",
            "iter 10: loss 4.1676, time 462.74ms, mfu 0.47%\n",
            "iter 20: loss 4.1373, time 487.37ms, mfu 0.47%\n",
            "iter 30: loss 4.0793, time 489.56ms, mfu 0.47%\n",
            "iter 40: loss 3.9860, time 479.73ms, mfu 0.47%\n",
            "iter 50: loss 3.9000, time 469.71ms, mfu 0.47%\n",
            "iter 60: loss 3.8019, time 461.10ms, mfu 0.47%\n",
            "iter 70: loss 3.7559, time 473.49ms, mfu 0.47%\n",
            "iter 80: loss 3.7338, time 476.39ms, mfu 0.47%\n",
            "iter 90: loss 3.6720, time 465.81ms, mfu 0.47%\n",
            "iter 100: loss 3.6566, time 492.59ms, mfu 0.46%\n",
            "iter 110: loss 3.6112, time 468.40ms, mfu 0.46%\n",
            "iter 120: loss 3.5360, time 473.28ms, mfu 0.46%\n",
            "iter 130: loss 3.5087, time 482.16ms, mfu 0.46%\n",
            "iter 140: loss 3.4575, time 475.09ms, mfu 0.46%\n",
            "iter 150: loss 3.4307, time 466.27ms, mfu 0.46%\n",
            "iter 160: loss 3.4069, time 456.02ms, mfu 0.46%\n",
            "iter 170: loss 3.3722, time 463.83ms, mfu 0.47%\n",
            "iter 180: loss 3.3251, time 462.27ms, mfu 0.47%\n",
            "iter 190: loss 3.3228, time 460.70ms, mfu 0.47%\n",
            "step 200: train loss 3.2395, val loss 3.2499\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 200: loss 3.2780, time 2269.36ms, mfu 0.43%\n",
            "iter 210: loss 3.2631, time 475.82ms, mfu 0.43%\n",
            "iter 220: loss 3.2080, time 468.89ms, mfu 0.44%\n",
            "iter 230: loss 3.2330, time 485.25ms, mfu 0.44%\n",
            "iter 240: loss 3.1653, time 464.09ms, mfu 0.44%\n",
            "iter 250: loss 3.1693, time 474.18ms, mfu 0.44%\n",
            "iter 260: loss 3.1119, time 469.70ms, mfu 0.44%\n",
            "iter 270: loss 3.1052, time 494.20ms, mfu 0.44%\n",
            "iter 280: loss 3.0565, time 461.73ms, mfu 0.45%\n",
            "iter 290: loss 3.0507, time 458.19ms, mfu 0.45%\n",
            "iter 300: loss 3.0364, time 483.22ms, mfu 0.45%\n",
            "iter 310: loss 3.0421, time 456.43ms, mfu 0.45%\n",
            "iter 320: loss 2.9398, time 465.26ms, mfu 0.45%\n",
            "iter 330: loss 2.9277, time 451.88ms, mfu 0.46%\n",
            "iter 340: loss 2.9291, time 457.82ms, mfu 0.46%\n",
            "iter 350: loss 2.9058, time 484.72ms, mfu 0.46%\n",
            "iter 360: loss 2.8648, time 458.94ms, mfu 0.46%\n",
            "iter 370: loss 2.8792, time 455.09ms, mfu 0.46%\n",
            "iter 380: loss 2.8653, time 498.51ms, mfu 0.46%\n",
            "iter 390: loss 2.7643, time 468.33ms, mfu 0.46%\n",
            "step 400: train loss 2.7593, val loss 2.7705\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 400: loss 2.7923, time 2325.25ms, mfu 0.42%\n",
            "iter 410: loss 2.7525, time 477.87ms, mfu 0.43%\n",
            "iter 420: loss 2.7782, time 470.65ms, mfu 0.43%\n",
            "iter 430: loss 2.7097, time 479.19ms, mfu 0.43%\n",
            "iter 440: loss 2.7068, time 467.52ms, mfu 0.44%\n",
            "iter 450: loss 2.6969, time 484.14ms, mfu 0.44%\n",
            "iter 460: loss 2.7120, time 459.21ms, mfu 0.44%\n",
            "iter 470: loss 2.6585, time 507.31ms, mfu 0.44%\n",
            "iter 480: loss 2.6356, time 470.89ms, mfu 0.44%\n",
            "iter 490: loss 2.6707, time 490.76ms, mfu 0.44%\n",
            "iter 500: loss 2.6089, time 468.28ms, mfu 0.45%\n",
            "iter 510: loss 2.5872, time 488.32ms, mfu 0.45%\n",
            "iter 520: loss 2.6046, time 462.75ms, mfu 0.45%\n",
            "iter 530: loss 2.5667, time 477.99ms, mfu 0.45%\n",
            "iter 540: loss 2.5829, time 461.37ms, mfu 0.45%\n",
            "iter 550: loss 2.5851, time 475.85ms, mfu 0.45%\n",
            "iter 560: loss 2.5669, time 472.33ms, mfu 0.45%\n",
            "iter 570: loss 2.5081, time 459.79ms, mfu 0.46%\n",
            "iter 580: loss 2.5159, time 463.06ms, mfu 0.46%\n",
            "iter 590: loss 2.5642, time 503.86ms, mfu 0.45%\n",
            "step 600: train loss 2.4678, val loss 2.4706\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 600: loss 2.5062, time 2334.20ms, mfu 0.42%\n",
            "iter 610: loss 2.5091, time 492.44ms, mfu 0.42%\n",
            "iter 620: loss 2.5468, time 460.24ms, mfu 0.43%\n",
            "iter 630: loss 2.4617, time 462.20ms, mfu 0.43%\n",
            "iter 640: loss 2.4799, time 466.80ms, mfu 0.43%\n",
            "iter 650: loss 2.4321, time 470.64ms, mfu 0.44%\n",
            "iter 660: loss 2.4378, time 480.23ms, mfu 0.44%\n",
            "iter 670: loss 2.4813, time 478.54ms, mfu 0.44%\n",
            "iter 680: loss 2.4368, time 459.00ms, mfu 0.44%\n",
            "iter 690: loss 2.4325, time 468.49ms, mfu 0.45%\n",
            "iter 700: loss 2.3721, time 476.25ms, mfu 0.45%\n",
            "iter 710: loss 2.4054, time 469.87ms, mfu 0.45%\n",
            "iter 720: loss 2.4242, time 461.20ms, mfu 0.45%\n",
            "iter 730: loss 2.4077, time 481.31ms, mfu 0.45%\n",
            "iter 740: loss 2.3627, time 467.74ms, mfu 0.45%\n",
            "iter 750: loss 2.3979, time 479.03ms, mfu 0.45%\n",
            "iter 760: loss 2.3260, time 493.44ms, mfu 0.45%\n",
            "iter 770: loss 2.3699, time 467.51ms, mfu 0.45%\n",
            "iter 780: loss 2.3763, time 458.19ms, mfu 0.46%\n",
            "iter 790: loss 2.3340, time 472.18ms, mfu 0.46%\n",
            "step 800: train loss 2.2987, val loss 2.3141\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 800: loss 2.3655, time 2301.54ms, mfu 0.42%\n",
            "iter 810: loss 2.3718, time 471.45ms, mfu 0.43%\n",
            "iter 820: loss 2.2987, time 487.71ms, mfu 0.43%\n",
            "iter 830: loss 2.3364, time 457.14ms, mfu 0.43%\n",
            "iter 840: loss 2.3795, time 460.29ms, mfu 0.44%\n",
            "iter 850: loss 2.3394, time 479.34ms, mfu 0.44%\n",
            "iter 860: loss 2.3437, time 462.18ms, mfu 0.44%\n",
            "iter 870: loss 2.3370, time 458.07ms, mfu 0.45%\n",
            "iter 880: loss 2.3273, time 469.88ms, mfu 0.45%\n",
            "iter 890: loss 2.3269, time 482.60ms, mfu 0.45%\n",
            "iter 900: loss 2.2886, time 478.32ms, mfu 0.45%\n",
            "iter 910: loss 2.2998, time 481.25ms, mfu 0.45%\n",
            "iter 920: loss 2.3453, time 475.48ms, mfu 0.45%\n",
            "iter 930: loss 2.2310, time 473.33ms, mfu 0.45%\n",
            "iter 940: loss 2.2793, time 465.82ms, mfu 0.45%\n",
            "iter 950: loss 2.2824, time 481.72ms, mfu 0.45%\n",
            "iter 960: loss 2.2615, time 464.26ms, mfu 0.45%\n",
            "iter 970: loss 2.2535, time 466.47ms, mfu 0.46%\n",
            "iter 980: loss 2.2419, time 485.60ms, mfu 0.46%\n",
            "iter 990: loss 2.3124, time 464.86ms, mfu 0.46%\n",
            "step 1000: train loss 2.1573, val loss 2.1817\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1000: loss 2.2724, time 2289.85ms, mfu 0.42%\n",
            "iter 1010: loss 2.2346, time 459.44ms, mfu 0.43%\n",
            "iter 1020: loss 2.2692, time 471.33ms, mfu 0.43%\n",
            "iter 1030: loss 2.2687, time 495.88ms, mfu 0.43%\n",
            "iter 1040: loss 2.1690, time 461.11ms, mfu 0.44%\n",
            "iter 1050: loss 2.2119, time 471.42ms, mfu 0.44%\n",
            "iter 1060: loss 2.2443, time 468.74ms, mfu 0.44%\n",
            "iter 1070: loss 2.1981, time 455.70ms, mfu 0.44%\n",
            "iter 1080: loss 2.2251, time 461.82ms, mfu 0.45%\n",
            "iter 1090: loss 2.2212, time 479.51ms, mfu 0.45%\n",
            "iter 1100: loss 2.1833, time 462.47ms, mfu 0.45%\n",
            "iter 1110: loss 2.1572, time 457.40ms, mfu 0.45%\n",
            "iter 1120: loss 2.1647, time 458.34ms, mfu 0.46%\n",
            "iter 1130: loss 2.1920, time 469.83ms, mfu 0.46%\n",
            "iter 1140: loss 2.1292, time 470.05ms, mfu 0.46%\n",
            "iter 1150: loss 2.1509, time 470.61ms, mfu 0.46%\n",
            "iter 1160: loss 2.1799, time 462.94ms, mfu 0.46%\n",
            "iter 1170: loss 2.1460, time 486.56ms, mfu 0.46%\n",
            "iter 1180: loss 2.1603, time 455.41ms, mfu 0.46%\n",
            "iter 1190: loss 2.1108, time 462.62ms, mfu 0.46%\n",
            "step 1200: train loss 1.9976, val loss 2.0570\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1200: loss 2.0922, time 2311.41ms, mfu 0.42%\n",
            "iter 1210: loss 2.1066, time 462.03ms, mfu 0.43%\n",
            "iter 1220: loss 2.0616, time 461.10ms, mfu 0.43%\n",
            "iter 1230: loss 2.0853, time 469.05ms, mfu 0.44%\n",
            "iter 1240: loss 2.1085, time 466.10ms, mfu 0.44%\n",
            "iter 1250: loss 2.0768, time 485.34ms, mfu 0.44%\n",
            "iter 1260: loss 2.0998, time 470.73ms, mfu 0.44%\n",
            "iter 1270: loss 2.0554, time 468.24ms, mfu 0.45%\n",
            "iter 1280: loss 2.0357, time 478.54ms, mfu 0.45%\n",
            "iter 1290: loss 2.0500, time 455.59ms, mfu 0.45%\n",
            "iter 1300: loss 1.9944, time 457.98ms, mfu 0.45%\n",
            "iter 1310: loss 2.0091, time 462.37ms, mfu 0.45%\n",
            "iter 1320: loss 2.0567, time 461.83ms, mfu 0.46%\n",
            "iter 1330: loss 2.0436, time 491.48ms, mfu 0.46%\n",
            "iter 1340: loss 2.0534, time 454.71ms, mfu 0.46%\n",
            "iter 1350: loss 1.9901, time 479.39ms, mfu 0.46%\n",
            "iter 1360: loss 1.9644, time 465.56ms, mfu 0.46%\n",
            "iter 1370: loss 1.9762, time 467.04ms, mfu 0.46%\n",
            "iter 1380: loss 2.0303, time 470.35ms, mfu 0.46%\n",
            "iter 1390: loss 2.0159, time 471.36ms, mfu 0.46%\n",
            "step 1400: train loss 1.8670, val loss 1.9710\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1400: loss 1.9818, time 2279.85ms, mfu 0.42%\n",
            "iter 1410: loss 2.0069, time 463.32ms, mfu 0.43%\n",
            "iter 1420: loss 1.9520, time 465.68ms, mfu 0.43%\n",
            "iter 1430: loss 1.8940, time 485.41ms, mfu 0.43%\n",
            "iter 1440: loss 1.9490, time 500.11ms, mfu 0.43%\n",
            "iter 1450: loss 1.9023, time 465.02ms, mfu 0.44%\n",
            "iter 1460: loss 1.9309, time 476.22ms, mfu 0.44%\n",
            "iter 1470: loss 1.9030, time 480.31ms, mfu 0.44%\n",
            "iter 1480: loss 1.8841, time 458.68ms, mfu 0.45%\n",
            "iter 1490: loss 1.9385, time 462.81ms, mfu 0.45%\n",
            "iter 1500: loss 1.8840, time 461.10ms, mfu 0.45%\n",
            "iter 1510: loss 1.9386, time 482.53ms, mfu 0.45%\n",
            "iter 1520: loss 1.9151, time 465.94ms, mfu 0.45%\n",
            "iter 1530: loss 1.9514, time 470.27ms, mfu 0.45%\n",
            "iter 1540: loss 1.8836, time 461.03ms, mfu 0.46%\n",
            "iter 1550: loss 1.8855, time 457.82ms, mfu 0.46%\n",
            "iter 1560: loss 1.8547, time 461.36ms, mfu 0.46%\n",
            "iter 1570: loss 1.8596, time 475.03ms, mfu 0.46%\n",
            "iter 1580: loss 1.8990, time 501.16ms, mfu 0.46%\n",
            "iter 1590: loss 1.9364, time 458.90ms, mfu 0.46%\n",
            "step 1600: train loss 1.7561, val loss 1.8917\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1600: loss 1.9041, time 2297.14ms, mfu 0.42%\n",
            "iter 1610: loss 1.9143, time 473.32ms, mfu 0.43%\n",
            "iter 1620: loss 1.8908, time 455.11ms, mfu 0.43%\n",
            "iter 1630: loss 1.8685, time 478.29ms, mfu 0.43%\n",
            "iter 1640: loss 1.8975, time 478.91ms, mfu 0.44%\n",
            "iter 1650: loss 1.8341, time 455.68ms, mfu 0.44%\n",
            "iter 1660: loss 1.7960, time 455.73ms, mfu 0.44%\n",
            "iter 1670: loss 1.8020, time 456.65ms, mfu 0.45%\n",
            "iter 1680: loss 1.8527, time 466.21ms, mfu 0.45%\n",
            "iter 1690: loss 1.8241, time 465.25ms, mfu 0.45%\n",
            "iter 1700: loss 1.7441, time 477.57ms, mfu 0.45%\n",
            "iter 1710: loss 1.8376, time 472.38ms, mfu 0.45%\n",
            "iter 1720: loss 1.8345, time 462.48ms, mfu 0.46%\n",
            "iter 1730: loss 1.8098, time 494.46ms, mfu 0.45%\n",
            "iter 1740: loss 1.8461, time 470.11ms, mfu 0.46%\n",
            "iter 1750: loss 1.8000, time 470.64ms, mfu 0.46%\n",
            "iter 1760: loss 1.8359, time 469.55ms, mfu 0.46%\n",
            "iter 1770: loss 1.8307, time 469.89ms, mfu 0.46%\n",
            "iter 1780: loss 1.8964, time 461.18ms, mfu 0.46%\n",
            "iter 1790: loss 1.8236, time 475.86ms, mfu 0.46%\n",
            "step 1800: train loss 1.6641, val loss 1.8311\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "iter 1800: loss 1.7688, time 2279.68ms, mfu 0.42%\n",
            "iter 1810: loss 1.7496, time 455.22ms, mfu 0.43%\n",
            "iter 1820: loss 1.7375, time 472.22ms, mfu 0.43%\n",
            "iter 1830: loss 1.7441, time 468.95ms, mfu 0.44%\n",
            "iter 1840: loss 1.7544, time 474.85ms, mfu 0.44%\n",
            "iter 1850: loss 1.7378, time 456.90ms, mfu 0.44%\n",
            "iter 1860: loss 1.7396, time 472.62ms, mfu 0.44%\n",
            "iter 1870: loss 1.6619, time 462.39ms, mfu 0.45%\n",
            "iter 1880: loss 1.8392, time 495.03ms, mfu 0.45%\n",
            "iter 1890: loss 1.8113, time 463.96ms, mfu 0.45%\n",
            "iter 1900: loss 1.7609, time 470.91ms, mfu 0.45%\n",
            "iter 1910: loss 1.7335, time 493.07ms, mfu 0.45%\n",
            "iter 1920: loss 1.7157, time 463.15ms, mfu 0.45%\n",
            "iter 1930: loss 1.7141, time 462.04ms, mfu 0.45%\n",
            "iter 1940: loss 1.7050, time 464.75ms, mfu 0.46%\n",
            "iter 1950: loss 1.7887, time 461.10ms, mfu 0.46%\n",
            "iter 1960: loss 1.7705, time 494.64ms, mfu 0.46%\n",
            "iter 1970: loss 1.7766, time 465.03ms, mfu 0.46%\n",
            "iter 1980: loss 1.7247, time 498.49ms, mfu 0.46%\n",
            "iter 1990: loss 1.7725, time 454.51ms, mfu 0.46%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 25/32: b128_L6_H8_E256_BS8_MI1000_D10_s25 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS8_MI1000_D10_s25.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D10_s25\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 25\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2260, val loss 4.2231\n",
            "iter 0: loss 4.2147, time 2465.37ms, mfu -100.00%\n",
            "iter 10: loss 4.1496, time 428.68ms, mfu 0.94%\n",
            "iter 20: loss 3.9719, time 461.90ms, mfu 0.94%\n",
            "iter 30: loss 3.7181, time 434.69ms, mfu 0.94%\n",
            "iter 40: loss 3.5588, time 468.88ms, mfu 0.93%\n",
            "iter 50: loss 3.4732, time 432.65ms, mfu 0.93%\n",
            "iter 60: loss 3.3534, time 457.40ms, mfu 0.92%\n",
            "iter 70: loss 3.2476, time 453.73ms, mfu 0.92%\n",
            "iter 80: loss 3.1905, time 481.92ms, mfu 0.91%\n",
            "iter 90: loss 3.0684, time 447.86ms, mfu 0.91%\n",
            "iter 100: loss 3.0625, time 498.08ms, mfu 0.90%\n",
            "iter 110: loss 2.8881, time 443.38ms, mfu 0.90%\n",
            "iter 120: loss 2.9419, time 432.35ms, mfu 0.91%\n",
            "iter 130: loss 2.8662, time 435.41ms, mfu 0.91%\n",
            "iter 140: loss 2.8905, time 434.57ms, mfu 0.91%\n",
            "iter 150: loss 2.7984, time 449.30ms, mfu 0.91%\n",
            "iter 160: loss 2.7452, time 441.02ms, mfu 0.91%\n",
            "iter 170: loss 2.7682, time 425.49ms, mfu 0.91%\n",
            "iter 180: loss 2.7099, time 428.03ms, mfu 0.92%\n",
            "iter 190: loss 2.7181, time 452.62ms, mfu 0.91%\n",
            "step 200: train loss 2.6788, val loss 2.6906\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 200: loss 2.6659, time 2195.55ms, mfu 0.84%\n",
            "iter 210: loss 2.6600, time 451.73ms, mfu 0.85%\n",
            "iter 220: loss 2.6373, time 432.06ms, mfu 0.86%\n",
            "iter 230: loss 2.6569, time 439.61ms, mfu 0.86%\n",
            "iter 240: loss 2.6447, time 443.59ms, mfu 0.87%\n",
            "iter 250: loss 2.7117, time 428.47ms, mfu 0.87%\n",
            "iter 260: loss 2.4923, time 452.71ms, mfu 0.88%\n",
            "iter 270: loss 2.5878, time 442.47ms, mfu 0.88%\n",
            "iter 280: loss 2.5091, time 429.86ms, mfu 0.89%\n",
            "iter 290: loss 2.5105, time 432.67ms, mfu 0.89%\n",
            "iter 300: loss 2.5753, time 429.34ms, mfu 0.90%\n",
            "iter 310: loss 2.5778, time 435.68ms, mfu 0.90%\n",
            "iter 320: loss 2.5029, time 441.00ms, mfu 0.90%\n",
            "iter 330: loss 2.4995, time 437.50ms, mfu 0.90%\n",
            "iter 340: loss 2.5045, time 432.65ms, mfu 0.91%\n",
            "iter 350: loss 2.4490, time 466.74ms, mfu 0.90%\n",
            "iter 360: loss 2.4879, time 429.55ms, mfu 0.91%\n",
            "iter 370: loss 2.4770, time 428.41ms, mfu 0.91%\n",
            "iter 380: loss 2.4210, time 446.24ms, mfu 0.91%\n",
            "iter 390: loss 2.5165, time 449.24ms, mfu 0.91%\n",
            "step 400: train loss 2.3990, val loss 2.4061\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 400: loss 2.3608, time 2185.82ms, mfu 0.84%\n",
            "iter 410: loss 2.3829, time 474.92ms, mfu 0.84%\n",
            "iter 420: loss 2.3968, time 431.74ms, mfu 0.85%\n",
            "iter 430: loss 2.4169, time 441.51ms, mfu 0.85%\n",
            "iter 440: loss 2.3438, time 430.91ms, mfu 0.86%\n",
            "iter 450: loss 2.4540, time 435.34ms, mfu 0.87%\n",
            "iter 460: loss 2.3041, time 436.90ms, mfu 0.87%\n",
            "iter 470: loss 2.3312, time 434.29ms, mfu 0.88%\n",
            "iter 480: loss 2.4423, time 439.06ms, mfu 0.88%\n",
            "iter 490: loss 2.3576, time 432.27ms, mfu 0.89%\n",
            "iter 500: loss 2.3247, time 460.18ms, mfu 0.89%\n",
            "iter 510: loss 2.3047, time 451.30ms, mfu 0.89%\n",
            "iter 520: loss 2.3071, time 431.15ms, mfu 0.89%\n",
            "iter 530: loss 2.2831, time 432.01ms, mfu 0.90%\n",
            "iter 540: loss 2.3201, time 442.35ms, mfu 0.90%\n",
            "iter 550: loss 2.2853, time 445.65ms, mfu 0.90%\n",
            "iter 560: loss 2.2486, time 447.92ms, mfu 0.90%\n",
            "iter 570: loss 2.2110, time 454.64ms, mfu 0.90%\n",
            "iter 580: loss 2.2365, time 432.77ms, mfu 0.90%\n",
            "iter 590: loss 2.3362, time 460.43ms, mfu 0.90%\n",
            "step 600: train loss 2.1771, val loss 2.2031\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 600: loss 2.2426, time 2216.06ms, mfu 0.83%\n",
            "iter 610: loss 2.2379, time 434.15ms, mfu 0.84%\n",
            "iter 620: loss 2.1915, time 462.05ms, mfu 0.84%\n",
            "iter 630: loss 2.1905, time 437.53ms, mfu 0.85%\n",
            "iter 640: loss 2.1509, time 482.74ms, mfu 0.85%\n",
            "iter 650: loss 2.1547, time 434.57ms, mfu 0.86%\n",
            "iter 660: loss 2.1717, time 443.70ms, mfu 0.86%\n",
            "iter 670: loss 2.1928, time 472.30ms, mfu 0.86%\n",
            "iter 680: loss 2.1196, time 439.70ms, mfu 0.87%\n",
            "iter 690: loss 2.1271, time 434.05ms, mfu 0.87%\n",
            "iter 700: loss 2.1149, time 442.10ms, mfu 0.88%\n",
            "iter 710: loss 2.1808, time 462.06ms, mfu 0.88%\n",
            "iter 720: loss 2.0693, time 433.03ms, mfu 0.88%\n",
            "iter 730: loss 2.1063, time 437.85ms, mfu 0.89%\n",
            "iter 740: loss 2.0644, time 437.92ms, mfu 0.89%\n",
            "iter 750: loss 2.1530, time 430.57ms, mfu 0.90%\n",
            "iter 760: loss 2.0390, time 430.08ms, mfu 0.90%\n",
            "iter 770: loss 2.0164, time 442.52ms, mfu 0.90%\n",
            "iter 780: loss 2.0080, time 441.61ms, mfu 0.90%\n",
            "iter 790: loss 2.1100, time 437.71ms, mfu 0.90%\n",
            "step 800: train loss 1.9336, val loss 2.0171\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 800: loss 1.9302, time 2183.34ms, mfu 0.83%\n",
            "iter 810: loss 1.9754, time 441.21ms, mfu 0.84%\n",
            "iter 820: loss 1.9846, time 439.03ms, mfu 0.85%\n",
            "iter 830: loss 1.9337, time 465.62ms, mfu 0.85%\n",
            "iter 840: loss 1.9940, time 449.75ms, mfu 0.86%\n",
            "iter 850: loss 1.9440, time 429.33ms, mfu 0.86%\n",
            "iter 860: loss 1.9382, time 451.72ms, mfu 0.87%\n",
            "iter 870: loss 1.8332, time 439.47ms, mfu 0.87%\n",
            "iter 880: loss 1.8541, time 428.37ms, mfu 0.88%\n",
            "iter 890: loss 1.8839, time 460.77ms, mfu 0.88%\n",
            "iter 900: loss 1.9164, time 426.03ms, mfu 0.89%\n",
            "iter 910: loss 1.9468, time 425.54ms, mfu 0.89%\n",
            "iter 920: loss 1.7695, time 433.35ms, mfu 0.90%\n",
            "iter 930: loss 1.8089, time 429.97ms, mfu 0.90%\n",
            "iter 940: loss 1.8363, time 428.30ms, mfu 0.91%\n",
            "iter 950: loss 1.7945, time 434.63ms, mfu 0.91%\n",
            "iter 960: loss 1.8611, time 430.51ms, mfu 0.91%\n",
            "iter 970: loss 1.7733, time 445.20ms, mfu 0.91%\n",
            "iter 980: loss 1.9330, time 429.66ms, mfu 0.91%\n",
            "iter 990: loss 1.7392, time 430.83ms, mfu 0.92%\n",
            "step 1000: train loss 1.7093, val loss 1.8496\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D10_s25\n",
            "iter 1000: loss 1.8217, time 2253.40ms, mfu 0.84%\n",
            "\n",
            "=== Experiment 26/32: b128_L6_H8_E256_BS8_MI1000_D20_s26 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS8_MI1000_D20_s26.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D20_s26\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 26\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2260, val loss 4.2231\n",
            "iter 0: loss 4.2067, time 2450.48ms, mfu -100.00%\n",
            "iter 10: loss 4.1564, time 457.93ms, mfu 0.88%\n",
            "iter 20: loss 4.0041, time 432.99ms, mfu 0.89%\n",
            "iter 30: loss 3.7738, time 441.13ms, mfu 0.89%\n",
            "iter 40: loss 3.6066, time 453.59ms, mfu 0.89%\n",
            "iter 50: loss 3.5076, time 441.52ms, mfu 0.89%\n",
            "iter 60: loss 3.3996, time 458.47ms, mfu 0.89%\n",
            "iter 70: loss 3.3276, time 447.29ms, mfu 0.89%\n",
            "iter 80: loss 3.2603, time 432.92ms, mfu 0.90%\n",
            "iter 90: loss 3.1352, time 458.07ms, mfu 0.90%\n",
            "iter 100: loss 3.1197, time 466.14ms, mfu 0.89%\n",
            "iter 110: loss 2.9443, time 448.07ms, mfu 0.89%\n",
            "iter 120: loss 3.0136, time 452.14ms, mfu 0.89%\n",
            "iter 130: loss 2.9150, time 440.66ms, mfu 0.90%\n",
            "iter 140: loss 2.9373, time 436.08ms, mfu 0.90%\n",
            "iter 150: loss 2.8511, time 439.47ms, mfu 0.90%\n",
            "iter 160: loss 2.7800, time 441.86ms, mfu 0.90%\n",
            "iter 170: loss 2.8038, time 453.24ms, mfu 0.90%\n",
            "iter 180: loss 2.7565, time 453.26ms, mfu 0.90%\n",
            "iter 190: loss 2.7534, time 434.16ms, mfu 0.90%\n",
            "step 200: train loss 2.6946, val loss 2.7016\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 200: loss 2.7132, time 2179.79ms, mfu 0.83%\n",
            "iter 210: loss 2.6955, time 450.72ms, mfu 0.84%\n",
            "iter 220: loss 2.6706, time 439.43ms, mfu 0.85%\n",
            "iter 230: loss 2.6838, time 432.84ms, mfu 0.86%\n",
            "iter 240: loss 2.6783, time 436.50ms, mfu 0.86%\n",
            "iter 250: loss 2.7472, time 470.34ms, mfu 0.86%\n",
            "iter 260: loss 2.5251, time 463.27ms, mfu 0.86%\n",
            "iter 270: loss 2.6096, time 456.09ms, mfu 0.87%\n",
            "iter 280: loss 2.5373, time 437.56ms, mfu 0.87%\n",
            "iter 290: loss 2.5382, time 476.49ms, mfu 0.87%\n",
            "iter 300: loss 2.5930, time 442.75ms, mfu 0.87%\n",
            "iter 310: loss 2.6060, time 476.52ms, mfu 0.87%\n",
            "iter 320: loss 2.5433, time 427.58ms, mfu 0.88%\n",
            "iter 330: loss 2.5416, time 435.56ms, mfu 0.88%\n",
            "iter 340: loss 2.5412, time 437.56ms, mfu 0.89%\n",
            "iter 350: loss 2.4786, time 463.80ms, mfu 0.89%\n",
            "iter 360: loss 2.5276, time 495.97ms, mfu 0.88%\n",
            "iter 370: loss 2.5131, time 431.18ms, mfu 0.88%\n",
            "iter 380: loss 2.4676, time 428.40ms, mfu 0.89%\n",
            "iter 390: loss 2.5662, time 428.68ms, mfu 0.90%\n",
            "step 400: train loss 2.4392, val loss 2.4430\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 400: loss 2.4114, time 2206.26ms, mfu 0.82%\n",
            "iter 410: loss 2.4276, time 437.83ms, mfu 0.83%\n",
            "iter 420: loss 2.4509, time 445.15ms, mfu 0.84%\n",
            "iter 430: loss 2.4537, time 462.57ms, mfu 0.84%\n",
            "iter 440: loss 2.3909, time 433.41ms, mfu 0.85%\n",
            "iter 450: loss 2.4895, time 433.84ms, mfu 0.86%\n",
            "iter 460: loss 2.3472, time 461.81ms, mfu 0.86%\n",
            "iter 470: loss 2.3821, time 439.37ms, mfu 0.87%\n",
            "iter 480: loss 2.4781, time 432.65ms, mfu 0.88%\n",
            "iter 490: loss 2.3982, time 452.34ms, mfu 0.88%\n",
            "iter 500: loss 2.3846, time 449.29ms, mfu 0.88%\n",
            "iter 510: loss 2.3425, time 429.29ms, mfu 0.89%\n",
            "iter 520: loss 2.3600, time 460.53ms, mfu 0.88%\n",
            "iter 530: loss 2.3385, time 436.01ms, mfu 0.89%\n",
            "iter 540: loss 2.3745, time 431.96ms, mfu 0.89%\n",
            "iter 550: loss 2.3243, time 446.91ms, mfu 0.89%\n",
            "iter 560: loss 2.3017, time 434.70ms, mfu 0.90%\n",
            "iter 570: loss 2.2687, time 446.52ms, mfu 0.90%\n",
            "iter 580: loss 2.2840, time 429.98ms, mfu 0.90%\n",
            "iter 590: loss 2.3822, time 428.88ms, mfu 0.91%\n",
            "step 600: train loss 2.2176, val loss 2.2396\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 600: loss 2.3021, time 2182.94ms, mfu 0.83%\n",
            "iter 610: loss 2.2824, time 432.39ms, mfu 0.84%\n",
            "iter 620: loss 2.2579, time 428.67ms, mfu 0.85%\n",
            "iter 630: loss 2.2439, time 446.90ms, mfu 0.86%\n",
            "iter 640: loss 2.2378, time 429.80ms, mfu 0.87%\n",
            "iter 650: loss 2.2124, time 441.42ms, mfu 0.87%\n",
            "iter 660: loss 2.2454, time 460.45ms, mfu 0.87%\n",
            "iter 670: loss 2.2598, time 465.11ms, mfu 0.87%\n",
            "iter 680: loss 2.1977, time 473.59ms, mfu 0.87%\n",
            "iter 690: loss 2.2245, time 433.28ms, mfu 0.88%\n",
            "iter 700: loss 2.2005, time 464.22ms, mfu 0.88%\n",
            "iter 710: loss 2.2315, time 437.17ms, mfu 0.88%\n",
            "iter 720: loss 2.1748, time 436.50ms, mfu 0.89%\n",
            "iter 730: loss 2.2128, time 462.73ms, mfu 0.88%\n",
            "iter 740: loss 2.1504, time 443.67ms, mfu 0.89%\n",
            "iter 750: loss 2.2266, time 450.69ms, mfu 0.89%\n",
            "iter 760: loss 2.1404, time 453.95ms, mfu 0.89%\n",
            "iter 770: loss 2.1315, time 432.56ms, mfu 0.89%\n",
            "iter 780: loss 2.1089, time 436.16ms, mfu 0.90%\n",
            "iter 790: loss 2.1994, time 445.35ms, mfu 0.90%\n",
            "step 800: train loss 2.0129, val loss 2.0748\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 800: loss 2.0234, time 2164.66ms, mfu 0.83%\n",
            "iter 810: loss 2.0859, time 438.22ms, mfu 0.84%\n",
            "iter 820: loss 2.0833, time 439.16ms, mfu 0.84%\n",
            "iter 830: loss 2.0215, time 442.70ms, mfu 0.85%\n",
            "iter 840: loss 2.1022, time 442.78ms, mfu 0.86%\n",
            "iter 850: loss 2.0536, time 448.39ms, mfu 0.86%\n",
            "iter 860: loss 2.0390, time 453.40ms, mfu 0.86%\n",
            "iter 870: loss 1.9454, time 441.68ms, mfu 0.87%\n",
            "iter 880: loss 1.9555, time 441.74ms, mfu 0.87%\n",
            "iter 890: loss 2.0041, time 450.37ms, mfu 0.88%\n",
            "iter 900: loss 2.0316, time 437.96ms, mfu 0.88%\n",
            "iter 910: loss 2.0477, time 434.78ms, mfu 0.89%\n",
            "iter 920: loss 1.8795, time 437.77ms, mfu 0.89%\n",
            "iter 930: loss 1.9106, time 438.73ms, mfu 0.89%\n",
            "iter 940: loss 1.9487, time 431.84ms, mfu 0.90%\n",
            "iter 950: loss 1.9071, time 474.68ms, mfu 0.89%\n",
            "iter 960: loss 1.9743, time 440.24ms, mfu 0.90%\n",
            "iter 970: loss 1.8809, time 433.14ms, mfu 0.90%\n",
            "iter 980: loss 2.0536, time 433.10ms, mfu 0.90%\n",
            "iter 990: loss 1.8670, time 432.71ms, mfu 0.91%\n",
            "step 1000: train loss 1.8118, val loss 1.9266\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI1000_D20_s26\n",
            "iter 1000: loss 1.9500, time 2267.94ms, mfu 0.83%\n",
            "\n",
            "=== Experiment 27/32: b128_L6_H8_E256_BS8_MI2000_D10_s27 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS8_MI2000_D10_s27.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 27\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2260, val loss 4.2231\n",
            "iter 0: loss 4.2147, time 2475.38ms, mfu -100.00%\n",
            "iter 10: loss 4.1496, time 460.02ms, mfu 0.88%\n",
            "iter 20: loss 3.9719, time 439.68ms, mfu 0.88%\n",
            "iter 30: loss 3.7181, time 446.62ms, mfu 0.89%\n",
            "iter 40: loss 3.5588, time 456.36ms, mfu 0.89%\n",
            "iter 50: loss 3.4732, time 443.88ms, mfu 0.89%\n",
            "iter 60: loss 3.3534, time 452.04ms, mfu 0.89%\n",
            "iter 70: loss 3.2476, time 437.24ms, mfu 0.89%\n",
            "iter 80: loss 3.1905, time 446.36ms, mfu 0.89%\n",
            "iter 90: loss 3.0684, time 444.70ms, mfu 0.89%\n",
            "iter 100: loss 3.0625, time 452.78ms, mfu 0.89%\n",
            "iter 110: loss 2.8881, time 447.91ms, mfu 0.90%\n",
            "iter 120: loss 2.9419, time 463.48ms, mfu 0.89%\n",
            "iter 130: loss 2.8662, time 436.57ms, mfu 0.90%\n",
            "iter 140: loss 2.8905, time 436.89ms, mfu 0.90%\n",
            "iter 150: loss 2.7984, time 462.62ms, mfu 0.90%\n",
            "iter 160: loss 2.7452, time 435.43ms, mfu 0.90%\n",
            "iter 170: loss 2.7682, time 436.62ms, mfu 0.90%\n",
            "iter 180: loss 2.7099, time 453.03ms, mfu 0.90%\n",
            "iter 190: loss 2.7181, time 440.18ms, mfu 0.90%\n",
            "step 200: train loss 2.6788, val loss 2.6906\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 200: loss 2.6659, time 2245.46ms, mfu 0.83%\n",
            "iter 210: loss 2.6600, time 464.08ms, mfu 0.83%\n",
            "iter 220: loss 2.6373, time 448.62ms, mfu 0.84%\n",
            "iter 230: loss 2.6569, time 431.40ms, mfu 0.85%\n",
            "iter 240: loss 2.6447, time 446.07ms, mfu 0.86%\n",
            "iter 250: loss 2.7117, time 447.64ms, mfu 0.86%\n",
            "iter 260: loss 2.4923, time 449.88ms, mfu 0.86%\n",
            "iter 270: loss 2.5878, time 458.46ms, mfu 0.87%\n",
            "iter 280: loss 2.5091, time 458.25ms, mfu 0.87%\n",
            "iter 290: loss 2.5105, time 458.56ms, mfu 0.87%\n",
            "iter 300: loss 2.5753, time 491.72ms, mfu 0.86%\n",
            "iter 310: loss 2.5778, time 460.49ms, mfu 0.87%\n",
            "iter 320: loss 2.5029, time 455.14ms, mfu 0.87%\n",
            "iter 330: loss 2.4995, time 469.00ms, mfu 0.87%\n",
            "iter 340: loss 2.5045, time 438.35ms, mfu 0.87%\n",
            "iter 350: loss 2.4490, time 442.28ms, mfu 0.88%\n",
            "iter 360: loss 2.4879, time 441.01ms, mfu 0.88%\n",
            "iter 370: loss 2.4770, time 484.29ms, mfu 0.88%\n",
            "iter 380: loss 2.4210, time 452.51ms, mfu 0.88%\n",
            "iter 390: loss 2.5165, time 441.71ms, mfu 0.88%\n",
            "step 400: train loss 2.3990, val loss 2.4061\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 400: loss 2.3608, time 2273.08ms, mfu 0.81%\n",
            "iter 410: loss 2.3829, time 467.79ms, mfu 0.82%\n",
            "iter 420: loss 2.3968, time 446.26ms, mfu 0.83%\n",
            "iter 430: loss 2.4169, time 452.01ms, mfu 0.83%\n",
            "iter 440: loss 2.3438, time 443.84ms, mfu 0.84%\n",
            "iter 450: loss 2.4540, time 444.34ms, mfu 0.85%\n",
            "iter 460: loss 2.3041, time 454.46ms, mfu 0.85%\n",
            "iter 470: loss 2.3312, time 460.06ms, mfu 0.85%\n",
            "iter 480: loss 2.4423, time 440.82ms, mfu 0.86%\n",
            "iter 490: loss 2.3576, time 453.44ms, mfu 0.86%\n",
            "iter 500: loss 2.3247, time 447.73ms, mfu 0.87%\n",
            "iter 510: loss 2.3047, time 464.40ms, mfu 0.87%\n",
            "iter 520: loss 2.3071, time 441.87ms, mfu 0.87%\n",
            "iter 530: loss 2.2831, time 439.41ms, mfu 0.88%\n",
            "iter 540: loss 2.3201, time 454.68ms, mfu 0.88%\n",
            "iter 550: loss 2.2853, time 444.81ms, mfu 0.88%\n",
            "iter 560: loss 2.2486, time 444.46ms, mfu 0.88%\n",
            "iter 570: loss 2.2110, time 463.56ms, mfu 0.88%\n",
            "iter 580: loss 2.2365, time 441.12ms, mfu 0.89%\n",
            "iter 590: loss 2.3362, time 440.40ms, mfu 0.89%\n",
            "step 600: train loss 2.1771, val loss 2.2031\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 600: loss 2.2426, time 2240.26ms, mfu 0.82%\n",
            "iter 610: loss 2.2379, time 460.44ms, mfu 0.82%\n",
            "iter 620: loss 2.1915, time 463.78ms, mfu 0.83%\n",
            "iter 630: loss 2.1905, time 453.73ms, mfu 0.84%\n",
            "iter 640: loss 2.1509, time 462.94ms, mfu 0.84%\n",
            "iter 650: loss 2.1547, time 468.22ms, mfu 0.84%\n",
            "iter 660: loss 2.1717, time 459.78ms, mfu 0.85%\n",
            "iter 670: loss 2.1928, time 469.96ms, mfu 0.85%\n",
            "iter 680: loss 2.1196, time 454.04ms, mfu 0.85%\n",
            "iter 690: loss 2.1271, time 454.75ms, mfu 0.85%\n",
            "iter 700: loss 2.1149, time 480.60ms, mfu 0.85%\n",
            "iter 710: loss 2.1808, time 461.64ms, mfu 0.86%\n",
            "iter 720: loss 2.0693, time 467.40ms, mfu 0.86%\n",
            "iter 730: loss 2.1063, time 449.81ms, mfu 0.86%\n",
            "iter 740: loss 2.0644, time 461.58ms, mfu 0.86%\n",
            "iter 750: loss 2.1530, time 496.42ms, mfu 0.86%\n",
            "iter 760: loss 2.0390, time 462.13ms, mfu 0.86%\n",
            "iter 770: loss 2.0164, time 452.86ms, mfu 0.86%\n",
            "iter 780: loss 2.0080, time 474.61ms, mfu 0.86%\n",
            "iter 790: loss 2.1100, time 450.93ms, mfu 0.87%\n",
            "step 800: train loss 1.9336, val loss 2.0171\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 800: loss 1.9302, time 2341.92ms, mfu 0.80%\n",
            "iter 810: loss 1.9754, time 496.00ms, mfu 0.80%\n",
            "iter 820: loss 1.9846, time 469.47ms, mfu 0.80%\n",
            "iter 830: loss 1.9337, time 454.88ms, mfu 0.81%\n",
            "iter 840: loss 1.9940, time 444.89ms, mfu 0.82%\n",
            "iter 850: loss 1.9440, time 456.86ms, mfu 0.83%\n",
            "iter 860: loss 1.9382, time 452.12ms, mfu 0.83%\n",
            "iter 870: loss 1.8332, time 445.71ms, mfu 0.84%\n",
            "iter 880: loss 1.8541, time 470.36ms, mfu 0.84%\n",
            "iter 890: loss 1.8839, time 449.56ms, mfu 0.85%\n",
            "iter 900: loss 1.9164, time 483.48ms, mfu 0.85%\n",
            "iter 910: loss 1.9468, time 481.43ms, mfu 0.85%\n",
            "iter 920: loss 1.7695, time 460.65ms, mfu 0.85%\n",
            "iter 930: loss 1.8089, time 468.86ms, mfu 0.85%\n",
            "iter 940: loss 1.8363, time 452.37ms, mfu 0.86%\n",
            "iter 950: loss 1.7945, time 478.83ms, mfu 0.85%\n",
            "iter 960: loss 1.8611, time 449.05ms, mfu 0.86%\n",
            "iter 970: loss 1.7733, time 442.97ms, mfu 0.86%\n",
            "iter 980: loss 1.9330, time 446.61ms, mfu 0.87%\n",
            "iter 990: loss 1.7392, time 438.37ms, mfu 0.87%\n",
            "step 1000: train loss 1.7093, val loss 1.8496\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1000: loss 1.8217, time 2225.61ms, mfu 0.80%\n",
            "iter 1010: loss 1.8889, time 454.80ms, mfu 0.81%\n",
            "iter 1020: loss 1.7722, time 448.58ms, mfu 0.82%\n",
            "iter 1030: loss 1.7446, time 465.20ms, mfu 0.83%\n",
            "iter 1040: loss 1.7335, time 447.76ms, mfu 0.83%\n",
            "iter 1050: loss 1.7604, time 450.27ms, mfu 0.84%\n",
            "iter 1060: loss 1.8282, time 463.49ms, mfu 0.84%\n",
            "iter 1070: loss 1.7037, time 444.42ms, mfu 0.85%\n",
            "iter 1080: loss 1.6630, time 445.70ms, mfu 0.86%\n",
            "iter 1090: loss 1.6666, time 437.28ms, mfu 0.86%\n",
            "iter 1100: loss 1.7349, time 447.99ms, mfu 0.87%\n",
            "iter 1110: loss 1.7838, time 457.24ms, mfu 0.87%\n",
            "iter 1120: loss 1.6659, time 434.15ms, mfu 0.87%\n",
            "iter 1130: loss 1.5966, time 437.42ms, mfu 0.88%\n",
            "iter 1140: loss 1.7021, time 440.46ms, mfu 0.88%\n",
            "iter 1150: loss 1.6886, time 453.83ms, mfu 0.88%\n",
            "iter 1160: loss 1.6947, time 438.85ms, mfu 0.89%\n",
            "iter 1170: loss 1.6271, time 461.96ms, mfu 0.89%\n",
            "iter 1180: loss 1.7114, time 448.99ms, mfu 0.89%\n",
            "iter 1190: loss 1.5913, time 447.22ms, mfu 0.89%\n",
            "step 1200: train loss 1.5539, val loss 1.7482\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1200: loss 1.6175, time 2235.58ms, mfu 0.82%\n",
            "iter 1210: loss 1.7466, time 441.94ms, mfu 0.83%\n",
            "iter 1220: loss 1.5475, time 448.29ms, mfu 0.84%\n",
            "iter 1230: loss 1.5149, time 467.88ms, mfu 0.84%\n",
            "iter 1240: loss 1.6024, time 450.75ms, mfu 0.84%\n",
            "iter 1250: loss 1.6550, time 451.89ms, mfu 0.85%\n",
            "iter 1260: loss 1.5692, time 448.50ms, mfu 0.85%\n",
            "iter 1270: loss 1.5932, time 454.06ms, mfu 0.86%\n",
            "iter 1280: loss 1.5708, time 451.77ms, mfu 0.86%\n",
            "iter 1290: loss 1.5699, time 444.21ms, mfu 0.87%\n",
            "iter 1300: loss 1.6023, time 457.96ms, mfu 0.87%\n",
            "iter 1310: loss 1.4697, time 450.53ms, mfu 0.87%\n",
            "iter 1320: loss 1.5239, time 457.58ms, mfu 0.87%\n",
            "iter 1330: loss 1.6467, time 457.42ms, mfu 0.87%\n",
            "iter 1340: loss 1.5882, time 452.73ms, mfu 0.88%\n",
            "iter 1350: loss 1.6240, time 441.63ms, mfu 0.88%\n",
            "iter 1360: loss 1.5778, time 445.40ms, mfu 0.88%\n",
            "iter 1370: loss 1.5557, time 441.33ms, mfu 0.89%\n",
            "iter 1380: loss 1.5054, time 461.52ms, mfu 0.88%\n",
            "iter 1390: loss 1.5947, time 440.99ms, mfu 0.89%\n",
            "step 1400: train loss 1.4759, val loss 1.6713\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1400: loss 1.4260, time 2223.29ms, mfu 0.82%\n",
            "iter 1410: loss 1.5793, time 443.48ms, mfu 0.83%\n",
            "iter 1420: loss 1.6449, time 444.59ms, mfu 0.83%\n",
            "iter 1430: loss 1.5423, time 477.25ms, mfu 0.84%\n",
            "iter 1440: loss 1.4879, time 464.85ms, mfu 0.84%\n",
            "iter 1450: loss 1.4396, time 451.75ms, mfu 0.84%\n",
            "iter 1460: loss 1.6186, time 475.21ms, mfu 0.85%\n",
            "iter 1470: loss 1.5508, time 452.12ms, mfu 0.85%\n",
            "iter 1480: loss 1.4516, time 460.71ms, mfu 0.85%\n",
            "iter 1490: loss 1.5874, time 442.70ms, mfu 0.86%\n",
            "iter 1500: loss 1.4578, time 444.82ms, mfu 0.86%\n",
            "iter 1510: loss 1.4752, time 441.19ms, mfu 0.87%\n",
            "iter 1520: loss 1.3782, time 446.75ms, mfu 0.87%\n",
            "iter 1530: loss 1.5265, time 450.77ms, mfu 0.88%\n",
            "iter 1540: loss 1.5432, time 452.68ms, mfu 0.88%\n",
            "iter 1550: loss 1.4876, time 437.47ms, mfu 0.88%\n",
            "iter 1560: loss 1.4801, time 449.33ms, mfu 0.88%\n",
            "iter 1570: loss 1.4550, time 442.11ms, mfu 0.89%\n",
            "iter 1580: loss 1.4496, time 438.74ms, mfu 0.89%\n",
            "iter 1590: loss 1.5264, time 463.25ms, mfu 0.89%\n",
            "step 1600: train loss 1.3760, val loss 1.5988\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1600: loss 1.5286, time 2249.41ms, mfu 0.82%\n",
            "iter 1610: loss 1.4261, time 449.82ms, mfu 0.83%\n",
            "iter 1620: loss 1.4303, time 448.75ms, mfu 0.83%\n",
            "iter 1630: loss 1.3743, time 454.90ms, mfu 0.84%\n",
            "iter 1640: loss 1.3798, time 455.58ms, mfu 0.84%\n",
            "iter 1650: loss 1.4487, time 448.20ms, mfu 0.85%\n",
            "iter 1660: loss 1.3322, time 448.61ms, mfu 0.85%\n",
            "iter 1670: loss 1.4874, time 450.90ms, mfu 0.86%\n",
            "iter 1680: loss 1.4305, time 437.57ms, mfu 0.87%\n",
            "iter 1690: loss 1.3978, time 464.22ms, mfu 0.87%\n",
            "iter 1700: loss 1.4597, time 443.43ms, mfu 0.87%\n",
            "iter 1710: loss 1.4459, time 438.15ms, mfu 0.88%\n",
            "iter 1720: loss 1.5114, time 445.17ms, mfu 0.88%\n",
            "iter 1730: loss 1.4224, time 444.85ms, mfu 0.88%\n",
            "iter 1740: loss 1.5674, time 442.48ms, mfu 0.88%\n",
            "iter 1750: loss 1.4683, time 455.59ms, mfu 0.89%\n",
            "iter 1760: loss 1.4889, time 461.39ms, mfu 0.88%\n",
            "iter 1770: loss 1.6163, time 472.22ms, mfu 0.88%\n",
            "iter 1780: loss 1.4208, time 453.22ms, mfu 0.88%\n",
            "iter 1790: loss 1.4213, time 450.76ms, mfu 0.88%\n",
            "step 1800: train loss 1.3319, val loss 1.5599\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "iter 1800: loss 1.3943, time 2266.57ms, mfu 0.81%\n",
            "iter 1810: loss 1.5424, time 450.06ms, mfu 0.82%\n",
            "iter 1820: loss 1.3663, time 443.76ms, mfu 0.83%\n",
            "iter 1830: loss 1.4898, time 451.13ms, mfu 0.84%\n",
            "iter 1840: loss 1.3160, time 435.38ms, mfu 0.85%\n",
            "iter 1850: loss 1.3608, time 461.52ms, mfu 0.85%\n",
            "iter 1860: loss 1.5268, time 466.91ms, mfu 0.85%\n",
            "iter 1870: loss 1.3792, time 444.02ms, mfu 0.86%\n",
            "iter 1880: loss 1.3307, time 450.72ms, mfu 0.86%\n",
            "iter 1890: loss 1.3814, time 449.51ms, mfu 0.86%\n",
            "iter 1900: loss 1.4298, time 443.86ms, mfu 0.87%\n",
            "iter 1910: loss 1.2561, time 443.35ms, mfu 0.87%\n",
            "iter 1920: loss 1.3517, time 441.50ms, mfu 0.88%\n",
            "iter 1930: loss 1.2383, time 450.07ms, mfu 0.88%\n",
            "iter 1940: loss 1.3163, time 450.44ms, mfu 0.88%\n",
            "iter 1950: loss 1.4474, time 452.37ms, mfu 0.88%\n",
            "iter 1960: loss 1.3996, time 448.40ms, mfu 0.88%\n",
            "iter 1970: loss 1.4096, time 460.61ms, mfu 0.88%\n",
            "iter 1980: loss 1.4397, time 450.67ms, mfu 0.89%\n",
            "iter 1990: loss 1.4234, time 451.27ms, mfu 0.89%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 28/32: b128_L6_H8_E256_BS8_MI2000_D20_s28 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS8_MI2000_D20_s28.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 8\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 28\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 40,960\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2260, val loss 4.2231\n",
            "iter 0: loss 4.2067, time 2480.74ms, mfu -100.00%\n",
            "iter 10: loss 4.1564, time 442.10ms, mfu 0.91%\n",
            "iter 20: loss 4.0041, time 444.66ms, mfu 0.91%\n",
            "iter 30: loss 3.7738, time 473.38ms, mfu 0.91%\n",
            "iter 40: loss 3.6066, time 444.99ms, mfu 0.91%\n",
            "iter 50: loss 3.5076, time 461.89ms, mfu 0.90%\n",
            "iter 60: loss 3.3996, time 445.04ms, mfu 0.90%\n",
            "iter 70: loss 3.3276, time 439.04ms, mfu 0.91%\n",
            "iter 80: loss 3.2603, time 443.46ms, mfu 0.91%\n",
            "iter 90: loss 3.1352, time 443.55ms, mfu 0.91%\n",
            "iter 100: loss 3.1197, time 445.91ms, mfu 0.91%\n",
            "iter 110: loss 2.9443, time 450.25ms, mfu 0.91%\n",
            "iter 120: loss 3.0136, time 440.91ms, mfu 0.91%\n",
            "iter 130: loss 2.9150, time 436.64ms, mfu 0.91%\n",
            "iter 140: loss 2.9373, time 441.81ms, mfu 0.91%\n",
            "iter 150: loss 2.8511, time 438.04ms, mfu 0.91%\n",
            "iter 160: loss 2.7800, time 443.42ms, mfu 0.91%\n",
            "iter 170: loss 2.8038, time 447.02ms, mfu 0.91%\n",
            "iter 180: loss 2.7565, time 438.86ms, mfu 0.91%\n",
            "iter 190: loss 2.7534, time 467.74ms, mfu 0.91%\n",
            "step 200: train loss 2.6946, val loss 2.7016\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 200: loss 2.7132, time 2198.93ms, mfu 0.83%\n",
            "iter 210: loss 2.6955, time 439.68ms, mfu 0.84%\n",
            "iter 220: loss 2.6706, time 457.30ms, mfu 0.85%\n",
            "iter 230: loss 2.6838, time 446.99ms, mfu 0.85%\n",
            "iter 240: loss 2.6783, time 449.75ms, mfu 0.86%\n",
            "iter 250: loss 2.7472, time 433.48ms, mfu 0.86%\n",
            "iter 260: loss 2.5251, time 438.36ms, mfu 0.87%\n",
            "iter 270: loss 2.6096, time 441.81ms, mfu 0.88%\n",
            "iter 280: loss 2.5373, time 442.09ms, mfu 0.88%\n",
            "iter 290: loss 2.5382, time 450.40ms, mfu 0.88%\n",
            "iter 300: loss 2.5930, time 442.74ms, mfu 0.88%\n",
            "iter 310: loss 2.6060, time 441.91ms, mfu 0.89%\n",
            "iter 320: loss 2.5433, time 439.57ms, mfu 0.89%\n",
            "iter 330: loss 2.5416, time 443.42ms, mfu 0.89%\n",
            "iter 340: loss 2.5412, time 440.13ms, mfu 0.90%\n",
            "iter 350: loss 2.4786, time 451.75ms, mfu 0.90%\n",
            "iter 360: loss 2.5276, time 442.72ms, mfu 0.90%\n",
            "iter 370: loss 2.5131, time 435.26ms, mfu 0.90%\n",
            "iter 380: loss 2.4676, time 453.01ms, mfu 0.90%\n",
            "iter 390: loss 2.5662, time 463.34ms, mfu 0.90%\n",
            "step 400: train loss 2.4392, val loss 2.4430\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 400: loss 2.4114, time 2252.66ms, mfu 0.82%\n",
            "iter 410: loss 2.4276, time 451.30ms, mfu 0.83%\n",
            "iter 420: loss 2.4509, time 448.82ms, mfu 0.84%\n",
            "iter 430: loss 2.4537, time 480.00ms, mfu 0.84%\n",
            "iter 440: loss 2.3909, time 443.56ms, mfu 0.85%\n",
            "iter 450: loss 2.4895, time 440.84ms, mfu 0.85%\n",
            "iter 460: loss 2.3472, time 449.65ms, mfu 0.86%\n",
            "iter 470: loss 2.3821, time 441.25ms, mfu 0.86%\n",
            "iter 480: loss 2.4781, time 453.07ms, mfu 0.87%\n",
            "iter 490: loss 2.3982, time 435.82ms, mfu 0.87%\n",
            "iter 500: loss 2.3846, time 447.60ms, mfu 0.88%\n",
            "iter 510: loss 2.3425, time 440.19ms, mfu 0.88%\n",
            "iter 520: loss 2.3600, time 461.13ms, mfu 0.88%\n",
            "iter 530: loss 2.3385, time 447.24ms, mfu 0.88%\n",
            "iter 540: loss 2.3745, time 451.58ms, mfu 0.88%\n",
            "iter 550: loss 2.3243, time 457.61ms, mfu 0.88%\n",
            "iter 560: loss 2.3017, time 466.47ms, mfu 0.88%\n",
            "iter 570: loss 2.2687, time 436.87ms, mfu 0.89%\n",
            "iter 580: loss 2.2840, time 450.13ms, mfu 0.89%\n",
            "iter 590: loss 2.3822, time 442.76ms, mfu 0.89%\n",
            "step 600: train loss 2.2176, val loss 2.2396\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 600: loss 2.3021, time 2218.23ms, mfu 0.82%\n",
            "iter 610: loss 2.2824, time 449.44ms, mfu 0.83%\n",
            "iter 620: loss 2.2579, time 456.41ms, mfu 0.83%\n",
            "iter 630: loss 2.2439, time 466.43ms, mfu 0.84%\n",
            "iter 640: loss 2.2378, time 472.92ms, mfu 0.84%\n",
            "iter 650: loss 2.2124, time 441.42ms, mfu 0.85%\n",
            "iter 660: loss 2.2454, time 438.87ms, mfu 0.85%\n",
            "iter 670: loss 2.2598, time 443.56ms, mfu 0.86%\n",
            "iter 680: loss 2.1977, time 437.46ms, mfu 0.87%\n",
            "iter 690: loss 2.2245, time 435.87ms, mfu 0.87%\n",
            "iter 700: loss 2.2005, time 442.18ms, mfu 0.88%\n",
            "iter 710: loss 2.2315, time 451.15ms, mfu 0.88%\n",
            "iter 720: loss 2.1748, time 453.16ms, mfu 0.88%\n",
            "iter 730: loss 2.2128, time 437.43ms, mfu 0.88%\n",
            "iter 740: loss 2.1504, time 451.32ms, mfu 0.89%\n",
            "iter 750: loss 2.2266, time 444.75ms, mfu 0.89%\n",
            "iter 760: loss 2.1404, time 447.83ms, mfu 0.89%\n",
            "iter 770: loss 2.1315, time 442.48ms, mfu 0.89%\n",
            "iter 780: loss 2.1089, time 447.22ms, mfu 0.89%\n",
            "iter 790: loss 2.1994, time 438.38ms, mfu 0.90%\n",
            "step 800: train loss 2.0129, val loss 2.0748\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 800: loss 2.0234, time 2240.80ms, mfu 0.82%\n",
            "iter 810: loss 2.0859, time 448.35ms, mfu 0.83%\n",
            "iter 820: loss 2.0833, time 451.48ms, mfu 0.84%\n",
            "iter 830: loss 2.0215, time 443.91ms, mfu 0.85%\n",
            "iter 840: loss 2.1022, time 444.42ms, mfu 0.85%\n",
            "iter 850: loss 2.0536, time 443.87ms, mfu 0.86%\n",
            "iter 860: loss 2.0390, time 445.35ms, mfu 0.86%\n",
            "iter 870: loss 1.9454, time 453.41ms, mfu 0.87%\n",
            "iter 880: loss 1.9555, time 443.81ms, mfu 0.87%\n",
            "iter 890: loss 2.0041, time 470.21ms, mfu 0.87%\n",
            "iter 900: loss 2.0316, time 443.90ms, mfu 0.87%\n",
            "iter 910: loss 2.0477, time 458.51ms, mfu 0.87%\n",
            "iter 920: loss 1.8795, time 439.89ms, mfu 0.88%\n",
            "iter 930: loss 1.9106, time 446.47ms, mfu 0.88%\n",
            "iter 940: loss 1.9487, time 444.45ms, mfu 0.88%\n",
            "iter 950: loss 1.9071, time 442.31ms, mfu 0.89%\n",
            "iter 960: loss 1.9743, time 443.75ms, mfu 0.89%\n",
            "iter 970: loss 1.8809, time 439.73ms, mfu 0.89%\n",
            "iter 980: loss 2.0536, time 456.35ms, mfu 0.89%\n",
            "iter 990: loss 1.8670, time 446.08ms, mfu 0.89%\n",
            "step 1000: train loss 1.8118, val loss 1.9266\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1000: loss 1.9500, time 2222.20ms, mfu 0.82%\n",
            "iter 1010: loss 2.0040, time 438.11ms, mfu 0.83%\n",
            "iter 1020: loss 1.8485, time 443.02ms, mfu 0.84%\n",
            "iter 1030: loss 1.8631, time 440.78ms, mfu 0.85%\n",
            "iter 1040: loss 1.8460, time 450.48ms, mfu 0.85%\n",
            "iter 1050: loss 1.8895, time 448.04ms, mfu 0.86%\n",
            "iter 1060: loss 1.9463, time 433.50ms, mfu 0.87%\n",
            "iter 1070: loss 1.8506, time 450.85ms, mfu 0.87%\n",
            "iter 1080: loss 1.7785, time 449.74ms, mfu 0.87%\n",
            "iter 1090: loss 1.7948, time 437.13ms, mfu 0.88%\n",
            "iter 1100: loss 1.8458, time 450.26ms, mfu 0.88%\n",
            "iter 1110: loss 1.8839, time 459.79ms, mfu 0.88%\n",
            "iter 1120: loss 1.8020, time 453.14ms, mfu 0.88%\n",
            "iter 1130: loss 1.7579, time 444.90ms, mfu 0.88%\n",
            "iter 1140: loss 1.8420, time 456.34ms, mfu 0.88%\n",
            "iter 1150: loss 1.7910, time 447.70ms, mfu 0.89%\n",
            "iter 1160: loss 1.8003, time 436.83ms, mfu 0.89%\n",
            "iter 1170: loss 1.7357, time 439.77ms, mfu 0.89%\n",
            "iter 1180: loss 1.8453, time 443.07ms, mfu 0.89%\n",
            "iter 1190: loss 1.7100, time 449.06ms, mfu 0.89%\n",
            "step 1200: train loss 1.6441, val loss 1.8205\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1200: loss 1.7506, time 2248.22ms, mfu 0.82%\n",
            "iter 1210: loss 1.8426, time 453.45ms, mfu 0.83%\n",
            "iter 1220: loss 1.7004, time 438.14ms, mfu 0.84%\n",
            "iter 1230: loss 1.6052, time 477.87ms, mfu 0.84%\n",
            "iter 1240: loss 1.7162, time 451.75ms, mfu 0.85%\n",
            "iter 1250: loss 1.7774, time 455.34ms, mfu 0.85%\n",
            "iter 1260: loss 1.6691, time 435.60ms, mfu 0.86%\n",
            "iter 1270: loss 1.7300, time 449.45ms, mfu 0.86%\n",
            "iter 1280: loss 1.6944, time 444.79ms, mfu 0.87%\n",
            "iter 1290: loss 1.6958, time 450.97ms, mfu 0.87%\n",
            "iter 1300: loss 1.7414, time 440.68ms, mfu 0.87%\n",
            "iter 1310: loss 1.5741, time 450.07ms, mfu 0.88%\n",
            "iter 1320: loss 1.6671, time 460.02ms, mfu 0.88%\n",
            "iter 1330: loss 1.7682, time 439.19ms, mfu 0.88%\n",
            "iter 1340: loss 1.6897, time 441.96ms, mfu 0.88%\n",
            "iter 1350: loss 1.7582, time 432.01ms, mfu 0.89%\n",
            "iter 1360: loss 1.6901, time 432.63ms, mfu 0.89%\n",
            "iter 1370: loss 1.6645, time 436.04ms, mfu 0.90%\n",
            "iter 1380: loss 1.5892, time 441.95ms, mfu 0.90%\n",
            "iter 1390: loss 1.7073, time 454.96ms, mfu 0.90%\n",
            "step 1400: train loss 1.5601, val loss 1.7394\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1400: loss 1.5237, time 2268.04ms, mfu 0.83%\n",
            "iter 1410: loss 1.6948, time 445.47ms, mfu 0.83%\n",
            "iter 1420: loss 1.7421, time 437.10ms, mfu 0.84%\n",
            "iter 1430: loss 1.6136, time 450.17ms, mfu 0.85%\n",
            "iter 1440: loss 1.6204, time 452.55ms, mfu 0.85%\n",
            "iter 1450: loss 1.5635, time 447.82ms, mfu 0.86%\n",
            "iter 1460: loss 1.7147, time 438.88ms, mfu 0.86%\n",
            "iter 1470: loss 1.6544, time 455.31ms, mfu 0.87%\n",
            "iter 1480: loss 1.5739, time 449.23ms, mfu 0.87%\n",
            "iter 1490: loss 1.6808, time 455.47ms, mfu 0.87%\n",
            "iter 1500: loss 1.5544, time 448.07ms, mfu 0.87%\n",
            "iter 1510: loss 1.5874, time 455.48ms, mfu 0.88%\n",
            "iter 1520: loss 1.4661, time 453.38ms, mfu 0.88%\n",
            "iter 1530: loss 1.6069, time 438.37ms, mfu 0.88%\n",
            "iter 1540: loss 1.6290, time 447.98ms, mfu 0.88%\n",
            "iter 1550: loss 1.5904, time 470.80ms, mfu 0.88%\n",
            "iter 1560: loss 1.5903, time 452.37ms, mfu 0.88%\n",
            "iter 1570: loss 1.5571, time 466.33ms, mfu 0.88%\n",
            "iter 1580: loss 1.5635, time 454.03ms, mfu 0.88%\n",
            "iter 1590: loss 1.6221, time 449.28ms, mfu 0.88%\n",
            "step 1600: train loss 1.4568, val loss 1.6687\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1600: loss 1.6427, time 2258.92ms, mfu 0.81%\n",
            "iter 1610: loss 1.5274, time 451.02ms, mfu 0.82%\n",
            "iter 1620: loss 1.5289, time 461.72ms, mfu 0.83%\n",
            "iter 1630: loss 1.4638, time 449.58ms, mfu 0.83%\n",
            "iter 1640: loss 1.4852, time 444.88ms, mfu 0.84%\n",
            "iter 1650: loss 1.5413, time 446.46ms, mfu 0.85%\n",
            "iter 1660: loss 1.4144, time 450.18ms, mfu 0.85%\n",
            "iter 1670: loss 1.5795, time 440.53ms, mfu 0.86%\n",
            "iter 1680: loss 1.5342, time 459.68ms, mfu 0.86%\n",
            "iter 1690: loss 1.5066, time 438.15ms, mfu 0.87%\n",
            "iter 1700: loss 1.5753, time 439.36ms, mfu 0.87%\n",
            "iter 1710: loss 1.5478, time 456.08ms, mfu 0.87%\n",
            "iter 1720: loss 1.6363, time 458.35ms, mfu 0.87%\n",
            "iter 1730: loss 1.5042, time 444.41ms, mfu 0.88%\n",
            "iter 1740: loss 1.6362, time 448.38ms, mfu 0.88%\n",
            "iter 1750: loss 1.5692, time 440.93ms, mfu 0.88%\n",
            "iter 1760: loss 1.5921, time 452.22ms, mfu 0.89%\n",
            "iter 1770: loss 1.6932, time 438.70ms, mfu 0.89%\n",
            "iter 1780: loss 1.5056, time 438.41ms, mfu 0.89%\n",
            "iter 1790: loss 1.4975, time 448.97ms, mfu 0.89%\n",
            "step 1800: train loss 1.4052, val loss 1.6147\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            "iter 1800: loss 1.4786, time 2247.34ms, mfu 0.82%\n",
            "iter 1810: loss 1.6378, time 458.27ms, mfu 0.83%\n",
            "iter 1820: loss 1.4506, time 438.43ms, mfu 0.84%\n",
            "iter 1830: loss 1.6115, time 446.27ms, mfu 0.84%\n",
            "iter 1840: loss 1.3999, time 443.79ms, mfu 0.85%\n",
            "iter 1850: loss 1.4434, time 442.50ms, mfu 0.86%\n",
            "iter 1860: loss 1.6046, time 448.02ms, mfu 0.86%\n",
            "iter 1870: loss 1.4397, time 442.91ms, mfu 0.87%\n",
            "iter 1880: loss 1.4110, time 441.03ms, mfu 0.87%\n",
            "iter 1890: loss 1.4896, time 438.42ms, mfu 0.88%\n",
            "iter 1900: loss 1.5393, time 452.55ms, mfu 0.88%\n",
            "iter 1910: loss 1.3779, time 442.43ms, mfu 0.88%\n",
            "iter 1920: loss 1.4076, time 448.97ms, mfu 0.88%\n",
            "iter 1930: loss 1.3135, time 442.41ms, mfu 0.89%\n",
            "iter 1940: loss 1.4282, time 438.00ms, mfu 0.89%\n",
            "iter 1950: loss 1.5763, time 463.06ms, mfu 0.89%\n",
            "iter 1960: loss 1.5176, time 441.77ms, mfu 0.89%\n",
            "iter 1970: loss 1.5022, time 446.18ms, mfu 0.89%\n",
            "iter 1980: loss 1.5074, time 442.89ms, mfu 0.89%\n",
            "iter 1990: loss 1.5149, time 433.97ms, mfu 0.90%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 29/32: b128_L6_H8_E256_BS16_MI1000_D10_s29 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS16_MI1000_D10_s29.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D10_s29\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 29\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2258, val loss 4.2227\n",
            "iter 0: loss 4.2236, time 2654.97ms, mfu -100.00%\n",
            "iter 10: loss 4.1539, time 468.74ms, mfu 1.72%\n",
            "iter 20: loss 3.9758, time 483.14ms, mfu 1.72%\n",
            "iter 30: loss 3.7703, time 476.56ms, mfu 1.72%\n",
            "iter 40: loss 3.5797, time 483.75ms, mfu 1.71%\n",
            "iter 50: loss 3.4437, time 466.34ms, mfu 1.71%\n",
            "iter 60: loss 3.3992, time 473.12ms, mfu 1.71%\n",
            "iter 70: loss 3.2798, time 479.41ms, mfu 1.71%\n",
            "iter 80: loss 3.1633, time 472.20ms, mfu 1.71%\n",
            "iter 90: loss 3.0991, time 482.32ms, mfu 1.71%\n",
            "iter 100: loss 2.9810, time 468.09ms, mfu 1.71%\n",
            "iter 110: loss 2.9981, time 462.78ms, mfu 1.71%\n",
            "iter 120: loss 2.8665, time 483.05ms, mfu 1.71%\n",
            "iter 130: loss 2.8587, time 471.75ms, mfu 1.71%\n",
            "iter 140: loss 2.8386, time 461.52ms, mfu 1.71%\n",
            "iter 150: loss 2.7843, time 471.00ms, mfu 1.71%\n",
            "iter 160: loss 2.7764, time 469.12ms, mfu 1.72%\n",
            "iter 170: loss 2.7711, time 473.21ms, mfu 1.71%\n",
            "iter 180: loss 2.7299, time 469.07ms, mfu 1.72%\n",
            "iter 190: loss 2.7459, time 470.00ms, mfu 1.72%\n",
            "step 200: train loss 2.6691, val loss 2.6777\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 200: loss 2.7051, time 2408.14ms, mfu 1.58%\n",
            "iter 210: loss 2.6594, time 465.63ms, mfu 1.59%\n",
            "iter 220: loss 2.6100, time 462.46ms, mfu 1.61%\n",
            "iter 230: loss 2.6332, time 469.51ms, mfu 1.62%\n",
            "iter 240: loss 2.6644, time 462.15ms, mfu 1.63%\n",
            "iter 250: loss 2.5444, time 464.67ms, mfu 1.64%\n",
            "iter 260: loss 2.5912, time 473.17ms, mfu 1.65%\n",
            "iter 270: loss 2.5172, time 485.82ms, mfu 1.65%\n",
            "iter 280: loss 2.5337, time 468.36ms, mfu 1.66%\n",
            "iter 290: loss 2.5517, time 460.90ms, mfu 1.67%\n",
            "iter 300: loss 2.4984, time 468.46ms, mfu 1.67%\n",
            "iter 310: loss 2.4909, time 462.63ms, mfu 1.68%\n",
            "iter 320: loss 2.4861, time 484.09ms, mfu 1.68%\n",
            "iter 330: loss 2.4585, time 473.64ms, mfu 1.68%\n",
            "iter 340: loss 2.4199, time 483.77ms, mfu 1.68%\n",
            "iter 350: loss 2.5089, time 461.64ms, mfu 1.69%\n",
            "iter 360: loss 2.4118, time 465.72ms, mfu 1.69%\n",
            "iter 370: loss 2.4847, time 484.48ms, mfu 1.69%\n",
            "iter 380: loss 2.4196, time 459.04ms, mfu 1.70%\n",
            "iter 390: loss 2.4302, time 469.80ms, mfu 1.70%\n",
            "step 400: train loss 2.3548, val loss 2.3647\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 400: loss 2.4338, time 2396.96ms, mfu 1.56%\n",
            "iter 410: loss 2.3303, time 467.60ms, mfu 1.58%\n",
            "iter 420: loss 2.3628, time 489.42ms, mfu 1.59%\n",
            "iter 430: loss 2.4260, time 457.04ms, mfu 1.61%\n",
            "iter 440: loss 2.4105, time 481.97ms, mfu 1.61%\n",
            "iter 450: loss 2.3441, time 469.31ms, mfu 1.62%\n",
            "iter 460: loss 2.4073, time 459.48ms, mfu 1.64%\n",
            "iter 470: loss 2.3027, time 467.94ms, mfu 1.65%\n",
            "iter 480: loss 2.2531, time 461.44ms, mfu 1.66%\n",
            "iter 490: loss 2.2665, time 475.12ms, mfu 1.66%\n",
            "iter 500: loss 2.2752, time 470.30ms, mfu 1.67%\n",
            "iter 510: loss 2.2724, time 475.47ms, mfu 1.67%\n",
            "iter 520: loss 2.2784, time 484.68ms, mfu 1.67%\n",
            "iter 530: loss 2.3221, time 477.76ms, mfu 1.67%\n",
            "iter 540: loss 2.1724, time 461.77ms, mfu 1.68%\n",
            "iter 550: loss 2.2345, time 480.54ms, mfu 1.68%\n",
            "iter 560: loss 2.2670, time 477.15ms, mfu 1.68%\n",
            "iter 570: loss 2.2341, time 471.30ms, mfu 1.69%\n",
            "iter 580: loss 2.2426, time 473.24ms, mfu 1.69%\n",
            "iter 590: loss 2.1611, time 467.72ms, mfu 1.69%\n",
            "step 600: train loss 2.1114, val loss 2.1511\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 600: loss 2.1144, time 2361.21ms, mfu 1.56%\n",
            "iter 610: loss 2.1436, time 464.50ms, mfu 1.58%\n",
            "iter 620: loss 2.1412, time 467.14ms, mfu 1.59%\n",
            "iter 630: loss 2.1855, time 468.66ms, mfu 1.60%\n",
            "iter 640: loss 2.1020, time 463.98ms, mfu 1.62%\n",
            "iter 650: loss 2.0914, time 472.37ms, mfu 1.63%\n",
            "iter 660: loss 2.0965, time 474.45ms, mfu 1.63%\n",
            "iter 670: loss 2.1001, time 489.82ms, mfu 1.64%\n",
            "iter 680: loss 2.0961, time 462.67ms, mfu 1.65%\n",
            "iter 690: loss 2.0446, time 470.94ms, mfu 1.65%\n",
            "iter 700: loss 2.0273, time 483.47ms, mfu 1.66%\n",
            "iter 710: loss 2.0817, time 468.26ms, mfu 1.66%\n",
            "iter 720: loss 2.0621, time 478.09ms, mfu 1.67%\n",
            "iter 730: loss 2.0090, time 472.27ms, mfu 1.67%\n",
            "iter 740: loss 2.0568, time 463.20ms, mfu 1.68%\n",
            "iter 750: loss 2.0223, time 473.84ms, mfu 1.68%\n",
            "iter 760: loss 1.9908, time 469.45ms, mfu 1.69%\n",
            "iter 770: loss 1.9602, time 476.59ms, mfu 1.69%\n",
            "iter 780: loss 1.9234, time 465.89ms, mfu 1.69%\n",
            "iter 790: loss 1.9869, time 463.54ms, mfu 1.70%\n",
            "step 800: train loss 1.8384, val loss 1.9421\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 800: loss 1.9017, time 2400.30ms, mfu 1.56%\n",
            "iter 810: loss 1.8821, time 465.42ms, mfu 1.58%\n",
            "iter 820: loss 1.9211, time 468.76ms, mfu 1.59%\n",
            "iter 830: loss 1.9188, time 467.91ms, mfu 1.61%\n",
            "iter 840: loss 1.9129, time 455.78ms, mfu 1.62%\n",
            "iter 850: loss 1.8629, time 477.52ms, mfu 1.63%\n",
            "iter 860: loss 1.9437, time 464.99ms, mfu 1.64%\n",
            "iter 870: loss 1.8802, time 457.09ms, mfu 1.65%\n",
            "iter 880: loss 1.7552, time 471.68ms, mfu 1.66%\n",
            "iter 890: loss 1.7776, time 474.95ms, mfu 1.66%\n",
            "iter 900: loss 1.8331, time 473.46ms, mfu 1.67%\n",
            "iter 910: loss 1.8010, time 474.28ms, mfu 1.67%\n",
            "iter 920: loss 1.8018, time 476.78ms, mfu 1.67%\n",
            "iter 930: loss 1.7867, time 469.62ms, mfu 1.68%\n",
            "iter 940: loss 1.7621, time 473.05ms, mfu 1.68%\n",
            "iter 950: loss 1.8660, time 487.98ms, mfu 1.68%\n",
            "iter 960: loss 1.8099, time 484.65ms, mfu 1.68%\n",
            "iter 970: loss 1.6689, time 462.56ms, mfu 1.69%\n",
            "iter 980: loss 1.7966, time 465.87ms, mfu 1.69%\n",
            "iter 990: loss 1.7461, time 459.18ms, mfu 1.70%\n",
            "step 1000: train loss 1.6307, val loss 1.7989\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D10_s29\n",
            "iter 1000: loss 1.7430, time 2403.77ms, mfu 1.56%\n",
            "\n",
            "=== Experiment 30/32: b128_L6_H8_E256_BS16_MI1000_D20_s30 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS16_MI1000_D20_s30.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D20_s30\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 1000\n",
            "lr_decay_iters = 1000\n",
            "\n",
            "seed = 30\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2258, val loss 4.2227\n",
            "iter 0: loss 4.2227, time 2643.71ms, mfu -100.00%\n",
            "iter 10: loss 4.1669, time 483.97ms, mfu 1.67%\n",
            "iter 20: loss 4.0145, time 466.13ms, mfu 1.68%\n",
            "iter 30: loss 3.8159, time 463.66ms, mfu 1.68%\n",
            "iter 40: loss 3.6206, time 470.58ms, mfu 1.69%\n",
            "iter 50: loss 3.4798, time 476.26ms, mfu 1.69%\n",
            "iter 60: loss 3.4465, time 488.03ms, mfu 1.68%\n",
            "iter 70: loss 3.3517, time 461.74ms, mfu 1.69%\n",
            "iter 80: loss 3.2321, time 464.18ms, mfu 1.70%\n",
            "iter 90: loss 3.1633, time 480.54ms, mfu 1.70%\n",
            "iter 100: loss 3.0379, time 468.70ms, mfu 1.70%\n",
            "iter 110: loss 3.0553, time 463.13ms, mfu 1.70%\n",
            "iter 120: loss 2.9152, time 491.27ms, mfu 1.70%\n",
            "iter 130: loss 2.9047, time 468.78ms, mfu 1.70%\n",
            "iter 140: loss 2.8847, time 468.90ms, mfu 1.70%\n",
            "iter 150: loss 2.8315, time 482.67ms, mfu 1.70%\n",
            "iter 160: loss 2.8152, time 475.50ms, mfu 1.70%\n",
            "iter 170: loss 2.8206, time 493.16ms, mfu 1.69%\n",
            "iter 180: loss 2.7650, time 471.08ms, mfu 1.70%\n",
            "iter 190: loss 2.7791, time 472.19ms, mfu 1.70%\n",
            "step 200: train loss 2.6861, val loss 2.6900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 200: loss 2.7433, time 2369.29ms, mfu 1.56%\n",
            "iter 210: loss 2.6892, time 470.36ms, mfu 1.58%\n",
            "iter 220: loss 2.6454, time 464.71ms, mfu 1.59%\n",
            "iter 230: loss 2.6681, time 466.45ms, mfu 1.61%\n",
            "iter 240: loss 2.7008, time 486.32ms, mfu 1.61%\n",
            "iter 250: loss 2.5769, time 466.40ms, mfu 1.63%\n",
            "iter 260: loss 2.6252, time 460.87ms, mfu 1.64%\n",
            "iter 270: loss 2.5501, time 464.91ms, mfu 1.65%\n",
            "iter 280: loss 2.5747, time 454.18ms, mfu 1.66%\n",
            "iter 290: loss 2.5843, time 472.47ms, mfu 1.67%\n",
            "iter 300: loss 2.5351, time 493.92ms, mfu 1.66%\n",
            "iter 310: loss 2.5251, time 479.06ms, mfu 1.67%\n",
            "iter 320: loss 2.5243, time 488.16ms, mfu 1.66%\n",
            "iter 330: loss 2.4861, time 470.33ms, mfu 1.67%\n",
            "iter 340: loss 2.4665, time 485.19ms, mfu 1.67%\n",
            "iter 350: loss 2.5387, time 456.85ms, mfu 1.68%\n",
            "iter 360: loss 2.4524, time 464.38ms, mfu 1.69%\n",
            "iter 370: loss 2.5176, time 464.57ms, mfu 1.69%\n",
            "iter 380: loss 2.4620, time 458.79ms, mfu 1.70%\n",
            "iter 390: loss 2.4737, time 472.79ms, mfu 1.70%\n",
            "step 400: train loss 2.3964, val loss 2.4033\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 400: loss 2.4753, time 2375.08ms, mfu 1.56%\n",
            "iter 410: loss 2.3730, time 457.61ms, mfu 1.58%\n",
            "iter 420: loss 2.4129, time 474.17ms, mfu 1.60%\n",
            "iter 430: loss 2.4636, time 465.09ms, mfu 1.61%\n",
            "iter 440: loss 2.4625, time 477.66ms, mfu 1.62%\n",
            "iter 450: loss 2.3897, time 465.82ms, mfu 1.63%\n",
            "iter 460: loss 2.4520, time 469.10ms, mfu 1.64%\n",
            "iter 470: loss 2.3395, time 475.17ms, mfu 1.65%\n",
            "iter 480: loss 2.3121, time 462.80ms, mfu 1.66%\n",
            "iter 490: loss 2.3343, time 482.20ms, mfu 1.66%\n",
            "iter 500: loss 2.3285, time 462.59ms, mfu 1.67%\n",
            "iter 510: loss 2.3324, time 461.22ms, mfu 1.68%\n",
            "iter 520: loss 2.3469, time 465.84ms, mfu 1.68%\n",
            "iter 530: loss 2.3834, time 471.21ms, mfu 1.68%\n",
            "iter 540: loss 2.2313, time 473.54ms, mfu 1.69%\n",
            "iter 550: loss 2.3022, time 460.73ms, mfu 1.69%\n",
            "iter 560: loss 2.3199, time 466.11ms, mfu 1.70%\n",
            "iter 570: loss 2.2938, time 472.61ms, mfu 1.70%\n",
            "iter 580: loss 2.2958, time 462.47ms, mfu 1.70%\n",
            "iter 590: loss 2.2337, time 465.64ms, mfu 1.71%\n",
            "step 600: train loss 2.1652, val loss 2.1971\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 600: loss 2.1887, time 2386.58ms, mfu 1.57%\n",
            "iter 610: loss 2.2157, time 461.98ms, mfu 1.59%\n",
            "iter 620: loss 2.2118, time 472.02ms, mfu 1.60%\n",
            "iter 630: loss 2.2432, time 460.84ms, mfu 1.62%\n",
            "iter 640: loss 2.1667, time 466.72ms, mfu 1.63%\n",
            "iter 650: loss 2.1739, time 461.20ms, mfu 1.64%\n",
            "iter 660: loss 2.1814, time 461.47ms, mfu 1.65%\n",
            "iter 670: loss 2.1739, time 464.73ms, mfu 1.66%\n",
            "iter 680: loss 2.1863, time 464.53ms, mfu 1.67%\n",
            "iter 690: loss 2.1107, time 471.05ms, mfu 1.67%\n",
            "iter 700: loss 2.1201, time 456.37ms, mfu 1.68%\n",
            "iter 710: loss 2.1601, time 455.39ms, mfu 1.69%\n",
            "iter 720: loss 2.1378, time 465.23ms, mfu 1.70%\n",
            "iter 730: loss 2.0837, time 464.12ms, mfu 1.70%\n",
            "iter 740: loss 2.1306, time 460.59ms, mfu 1.71%\n",
            "iter 750: loss 2.0954, time 457.53ms, mfu 1.71%\n",
            "iter 760: loss 2.0927, time 457.44ms, mfu 1.72%\n",
            "iter 770: loss 2.0368, time 457.70ms, mfu 1.72%\n",
            "iter 780: loss 2.0211, time 458.17ms, mfu 1.73%\n",
            "iter 790: loss 2.0707, time 467.56ms, mfu 1.73%\n",
            "step 800: train loss 1.9201, val loss 2.0066\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 800: loss 1.9936, time 2356.12ms, mfu 1.59%\n",
            "iter 810: loss 1.9743, time 459.37ms, mfu 1.61%\n",
            "iter 820: loss 2.0296, time 478.03ms, mfu 1.61%\n",
            "iter 830: loss 2.0007, time 459.73ms, mfu 1.63%\n",
            "iter 840: loss 2.0100, time 466.28ms, mfu 1.64%\n",
            "iter 850: loss 1.9532, time 472.87ms, mfu 1.65%\n",
            "iter 860: loss 2.0312, time 465.55ms, mfu 1.66%\n",
            "iter 870: loss 1.9624, time 458.76ms, mfu 1.67%\n",
            "iter 880: loss 1.8524, time 466.97ms, mfu 1.67%\n",
            "iter 890: loss 1.8881, time 479.80ms, mfu 1.67%\n",
            "iter 900: loss 1.9291, time 459.59ms, mfu 1.68%\n",
            "iter 910: loss 1.8958, time 458.50ms, mfu 1.69%\n",
            "iter 920: loss 1.9011, time 462.50ms, mfu 1.70%\n",
            "iter 930: loss 1.8779, time 471.41ms, mfu 1.70%\n",
            "iter 940: loss 1.8457, time 458.46ms, mfu 1.70%\n",
            "iter 950: loss 1.9564, time 471.13ms, mfu 1.71%\n",
            "iter 960: loss 1.9139, time 476.82ms, mfu 1.70%\n",
            "iter 970: loss 1.8041, time 468.92ms, mfu 1.71%\n",
            "iter 980: loss 1.9006, time 462.55ms, mfu 1.71%\n",
            "iter 990: loss 1.8531, time 461.84ms, mfu 1.71%\n",
            "step 1000: train loss 1.7168, val loss 1.8723\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI1000_D20_s30\n",
            "iter 1000: loss 1.8738, time 2378.45ms, mfu 1.58%\n",
            "\n",
            "=== Experiment 31/32: b128_L6_H8_E256_BS16_MI2000_D10_s31 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS16_MI2000_D10_s31.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.1\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 31\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2258, val loss 4.2227\n",
            "iter 0: loss 4.2236, time 2642.44ms, mfu -100.00%\n",
            "iter 10: loss 4.1539, time 463.90ms, mfu 1.74%\n",
            "iter 20: loss 3.9758, time 476.35ms, mfu 1.74%\n",
            "iter 30: loss 3.7703, time 466.78ms, mfu 1.74%\n",
            "iter 40: loss 3.5797, time 468.15ms, mfu 1.74%\n",
            "iter 50: loss 3.4437, time 470.56ms, mfu 1.73%\n",
            "iter 60: loss 3.3992, time 468.85ms, mfu 1.73%\n",
            "iter 70: loss 3.2798, time 474.23ms, mfu 1.73%\n",
            "iter 80: loss 3.1633, time 458.47ms, mfu 1.73%\n",
            "iter 90: loss 3.0991, time 482.60ms, mfu 1.73%\n",
            "iter 100: loss 2.9810, time 473.82ms, mfu 1.73%\n",
            "iter 110: loss 2.9981, time 460.19ms, mfu 1.73%\n",
            "iter 120: loss 2.8665, time 460.83ms, mfu 1.73%\n",
            "iter 130: loss 2.8587, time 483.41ms, mfu 1.73%\n",
            "iter 140: loss 2.8386, time 470.91ms, mfu 1.72%\n",
            "iter 150: loss 2.7843, time 460.05ms, mfu 1.73%\n",
            "iter 160: loss 2.7764, time 463.00ms, mfu 1.73%\n",
            "iter 170: loss 2.7711, time 467.42ms, mfu 1.73%\n",
            "iter 180: loss 2.7299, time 462.14ms, mfu 1.73%\n",
            "iter 190: loss 2.7459, time 470.60ms, mfu 1.73%\n",
            "step 200: train loss 2.6691, val loss 2.6777\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 200: loss 2.7051, time 2362.52ms, mfu 1.59%\n",
            "iter 210: loss 2.6594, time 460.87ms, mfu 1.61%\n",
            "iter 220: loss 2.6100, time 475.57ms, mfu 1.62%\n",
            "iter 230: loss 2.6332, time 459.87ms, mfu 1.63%\n",
            "iter 240: loss 2.6644, time 458.41ms, mfu 1.64%\n",
            "iter 250: loss 2.5444, time 473.68ms, mfu 1.65%\n",
            "iter 260: loss 2.5912, time 463.78ms, mfu 1.66%\n",
            "iter 270: loss 2.5172, time 460.52ms, mfu 1.67%\n",
            "iter 280: loss 2.5337, time 470.87ms, mfu 1.67%\n",
            "iter 290: loss 2.5517, time 465.16ms, mfu 1.68%\n",
            "iter 300: loss 2.4984, time 490.26ms, mfu 1.68%\n",
            "iter 310: loss 2.4909, time 450.63ms, mfu 1.69%\n",
            "iter 320: loss 2.4861, time 483.24ms, mfu 1.69%\n",
            "iter 330: loss 2.4585, time 459.96ms, mfu 1.69%\n",
            "iter 340: loss 2.4199, time 457.19ms, mfu 1.70%\n",
            "iter 350: loss 2.5089, time 460.64ms, mfu 1.71%\n",
            "iter 360: loss 2.4118, time 461.27ms, mfu 1.71%\n",
            "iter 370: loss 2.4847, time 480.40ms, mfu 1.71%\n",
            "iter 380: loss 2.4196, time 458.93ms, mfu 1.71%\n",
            "iter 390: loss 2.4302, time 479.28ms, mfu 1.71%\n",
            "step 400: train loss 2.3548, val loss 2.3647\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 400: loss 2.4338, time 2382.84ms, mfu 1.57%\n",
            "iter 410: loss 2.3303, time 463.29ms, mfu 1.59%\n",
            "iter 420: loss 2.3628, time 480.58ms, mfu 1.60%\n",
            "iter 430: loss 2.4260, time 477.42ms, mfu 1.61%\n",
            "iter 440: loss 2.4105, time 471.60ms, mfu 1.62%\n",
            "iter 450: loss 2.3441, time 456.36ms, mfu 1.64%\n",
            "iter 460: loss 2.4073, time 472.93ms, mfu 1.64%\n",
            "iter 470: loss 2.3027, time 471.46ms, mfu 1.65%\n",
            "iter 480: loss 2.2531, time 454.50ms, mfu 1.66%\n",
            "iter 490: loss 2.2665, time 458.09ms, mfu 1.67%\n",
            "iter 500: loss 2.2752, time 462.35ms, mfu 1.68%\n",
            "iter 510: loss 2.2724, time 457.16ms, mfu 1.69%\n",
            "iter 520: loss 2.2784, time 477.97ms, mfu 1.69%\n",
            "iter 530: loss 2.3221, time 460.98ms, mfu 1.70%\n",
            "iter 540: loss 2.1724, time 458.69ms, mfu 1.70%\n",
            "iter 550: loss 2.2345, time 470.58ms, mfu 1.70%\n",
            "iter 560: loss 2.2670, time 493.37ms, mfu 1.70%\n",
            "iter 570: loss 2.2341, time 459.95ms, mfu 1.70%\n",
            "iter 580: loss 2.2426, time 468.26ms, mfu 1.71%\n",
            "iter 590: loss 2.1611, time 454.02ms, mfu 1.71%\n",
            "step 600: train loss 2.1114, val loss 2.1511\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 600: loss 2.1144, time 2412.48ms, mfu 1.58%\n",
            "iter 610: loss 2.1436, time 464.48ms, mfu 1.59%\n",
            "iter 620: loss 2.1412, time 472.98ms, mfu 1.60%\n",
            "iter 630: loss 2.1855, time 504.85ms, mfu 1.60%\n",
            "iter 640: loss 2.1020, time 487.07ms, mfu 1.61%\n",
            "iter 650: loss 2.0914, time 460.44ms, mfu 1.62%\n",
            "iter 660: loss 2.0965, time 455.17ms, mfu 1.64%\n",
            "iter 670: loss 2.1001, time 463.79ms, mfu 1.65%\n",
            "iter 680: loss 2.0961, time 457.54ms, mfu 1.66%\n",
            "iter 690: loss 2.0446, time 452.72ms, mfu 1.67%\n",
            "iter 700: loss 2.0273, time 483.32ms, mfu 1.67%\n",
            "iter 710: loss 2.0817, time 453.33ms, mfu 1.68%\n",
            "iter 720: loss 2.0621, time 471.48ms, mfu 1.69%\n",
            "iter 730: loss 2.0090, time 459.81ms, mfu 1.69%\n",
            "iter 740: loss 2.0568, time 466.97ms, mfu 1.70%\n",
            "iter 750: loss 2.0223, time 482.55ms, mfu 1.70%\n",
            "iter 760: loss 1.9908, time 457.19ms, mfu 1.70%\n",
            "iter 770: loss 1.9602, time 463.02ms, mfu 1.71%\n",
            "iter 780: loss 1.9234, time 458.08ms, mfu 1.71%\n",
            "iter 790: loss 1.9869, time 476.69ms, mfu 1.71%\n",
            "step 800: train loss 1.8384, val loss 1.9421\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 800: loss 1.9017, time 2428.26ms, mfu 1.57%\n",
            "iter 810: loss 1.8821, time 458.45ms, mfu 1.59%\n",
            "iter 820: loss 1.9211, time 458.34ms, mfu 1.61%\n",
            "iter 830: loss 1.9188, time 454.74ms, mfu 1.63%\n",
            "iter 840: loss 1.9129, time 452.65ms, mfu 1.64%\n",
            "iter 850: loss 1.8629, time 480.33ms, mfu 1.65%\n",
            "iter 860: loss 1.9437, time 451.37ms, mfu 1.66%\n",
            "iter 870: loss 1.8802, time 458.15ms, mfu 1.67%\n",
            "iter 880: loss 1.7552, time 460.61ms, mfu 1.68%\n",
            "iter 890: loss 1.7776, time 454.17ms, mfu 1.69%\n",
            "iter 900: loss 1.8331, time 462.32ms, mfu 1.70%\n",
            "iter 910: loss 1.8010, time 488.86ms, mfu 1.69%\n",
            "iter 920: loss 1.8018, time 447.72ms, mfu 1.70%\n",
            "iter 930: loss 1.7867, time 468.34ms, mfu 1.71%\n",
            "iter 940: loss 1.7621, time 496.90ms, mfu 1.70%\n",
            "iter 950: loss 1.8660, time 466.44ms, mfu 1.70%\n",
            "iter 960: loss 1.8099, time 462.32ms, mfu 1.71%\n",
            "iter 970: loss 1.6689, time 474.92ms, mfu 1.71%\n",
            "iter 980: loss 1.7966, time 495.99ms, mfu 1.70%\n",
            "iter 990: loss 1.7461, time 458.57ms, mfu 1.70%\n",
            "step 1000: train loss 1.6307, val loss 1.7989\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1000: loss 1.7430, time 2402.29ms, mfu 1.57%\n",
            "iter 1010: loss 1.6925, time 458.20ms, mfu 1.59%\n",
            "iter 1020: loss 1.7292, time 460.62ms, mfu 1.60%\n",
            "iter 1030: loss 1.6625, time 508.38ms, mfu 1.60%\n",
            "iter 1040: loss 1.7479, time 459.78ms, mfu 1.62%\n",
            "iter 1050: loss 1.7051, time 471.47ms, mfu 1.63%\n",
            "iter 1060: loss 1.8049, time 502.19ms, mfu 1.63%\n",
            "iter 1070: loss 1.7309, time 458.66ms, mfu 1.64%\n",
            "iter 1080: loss 1.6086, time 459.89ms, mfu 1.65%\n",
            "iter 1090: loss 1.6213, time 460.25ms, mfu 1.66%\n",
            "iter 1100: loss 1.6299, time 463.26ms, mfu 1.67%\n",
            "iter 1110: loss 1.5979, time 464.17ms, mfu 1.68%\n",
            "iter 1120: loss 1.6165, time 476.35ms, mfu 1.68%\n",
            "iter 1130: loss 1.6250, time 460.91ms, mfu 1.69%\n",
            "iter 1140: loss 1.6620, time 463.22ms, mfu 1.69%\n",
            "iter 1150: loss 1.6447, time 475.01ms, mfu 1.69%\n",
            "iter 1160: loss 1.6315, time 464.30ms, mfu 1.70%\n",
            "iter 1170: loss 1.6157, time 453.64ms, mfu 1.71%\n",
            "iter 1180: loss 1.5501, time 479.47ms, mfu 1.70%\n",
            "iter 1190: loss 1.5493, time 451.47ms, mfu 1.71%\n",
            "step 1200: train loss 1.4825, val loss 1.6803\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1200: loss 1.5498, time 2356.56ms, mfu 1.58%\n",
            "iter 1210: loss 1.5388, time 478.99ms, mfu 1.59%\n",
            "iter 1220: loss 1.5601, time 462.71ms, mfu 1.60%\n",
            "iter 1230: loss 1.5390, time 479.17ms, mfu 1.61%\n",
            "iter 1240: loss 1.6310, time 464.36ms, mfu 1.62%\n",
            "iter 1250: loss 1.5724, time 463.54ms, mfu 1.64%\n",
            "iter 1260: loss 1.5361, time 464.27ms, mfu 1.65%\n",
            "iter 1270: loss 1.5508, time 454.86ms, mfu 1.66%\n",
            "iter 1280: loss 1.5770, time 451.57ms, mfu 1.67%\n",
            "iter 1290: loss 1.5794, time 457.61ms, mfu 1.68%\n",
            "iter 1300: loss 1.5097, time 471.94ms, mfu 1.69%\n",
            "iter 1310: loss 1.6086, time 466.67ms, mfu 1.69%\n",
            "iter 1320: loss 1.4780, time 465.94ms, mfu 1.69%\n",
            "iter 1330: loss 1.4867, time 487.89ms, mfu 1.69%\n",
            "iter 1340: loss 1.4738, time 457.94ms, mfu 1.70%\n",
            "iter 1350: loss 1.5274, time 460.27ms, mfu 1.70%\n",
            "iter 1360: loss 1.5009, time 472.34ms, mfu 1.70%\n",
            "iter 1370: loss 1.4738, time 465.86ms, mfu 1.71%\n",
            "iter 1380: loss 1.5035, time 468.79ms, mfu 1.71%\n",
            "iter 1390: loss 1.5120, time 474.78ms, mfu 1.71%\n",
            "step 1400: train loss 1.3867, val loss 1.6005\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1400: loss 1.5084, time 2398.48ms, mfu 1.57%\n",
            "iter 1410: loss 1.4485, time 485.03ms, mfu 1.58%\n",
            "iter 1420: loss 1.5129, time 458.85ms, mfu 1.60%\n",
            "iter 1430: loss 1.4443, time 455.70ms, mfu 1.62%\n",
            "iter 1440: loss 1.5316, time 457.76ms, mfu 1.63%\n",
            "iter 1450: loss 1.5028, time 460.25ms, mfu 1.64%\n",
            "iter 1460: loss 1.4646, time 468.11ms, mfu 1.65%\n",
            "iter 1470: loss 1.4800, time 466.52ms, mfu 1.66%\n",
            "iter 1480: loss 1.3958, time 452.98ms, mfu 1.67%\n",
            "iter 1490: loss 1.4015, time 463.38ms, mfu 1.68%\n",
            "iter 1500: loss 1.3846, time 456.16ms, mfu 1.69%\n",
            "iter 1510: loss 1.3767, time 469.20ms, mfu 1.69%\n",
            "iter 1520: loss 1.4585, time 456.90ms, mfu 1.70%\n",
            "iter 1530: loss 1.3606, time 480.43ms, mfu 1.70%\n",
            "iter 1540: loss 1.4162, time 526.98ms, mfu 1.68%\n",
            "iter 1550: loss 1.4279, time 449.82ms, mfu 1.69%\n",
            "iter 1560: loss 1.3899, time 463.36ms, mfu 1.70%\n",
            "iter 1570: loss 1.4559, time 451.01ms, mfu 1.71%\n",
            "iter 1580: loss 1.3330, time 452.45ms, mfu 1.72%\n",
            "iter 1590: loss 1.3415, time 457.45ms, mfu 1.72%\n",
            "step 1600: train loss 1.3200, val loss 1.5550\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1600: loss 1.4192, time 2419.76ms, mfu 1.58%\n",
            "iter 1610: loss 1.3410, time 458.80ms, mfu 1.60%\n",
            "iter 1620: loss 1.3835, time 478.78ms, mfu 1.61%\n",
            "iter 1630: loss 1.3439, time 461.04ms, mfu 1.62%\n",
            "iter 1640: loss 1.4236, time 459.88ms, mfu 1.64%\n",
            "iter 1650: loss 1.4011, time 452.00ms, mfu 1.65%\n",
            "iter 1660: loss 1.3505, time 454.10ms, mfu 1.67%\n",
            "iter 1670: loss 1.3838, time 465.24ms, mfu 1.67%\n",
            "iter 1680: loss 1.4113, time 455.50ms, mfu 1.68%\n",
            "iter 1690: loss 1.3243, time 475.63ms, mfu 1.68%\n",
            "iter 1700: loss 1.2812, time 478.79ms, mfu 1.68%\n",
            "iter 1710: loss 1.3545, time 468.74ms, mfu 1.69%\n",
            "iter 1720: loss 1.3293, time 466.63ms, mfu 1.69%\n",
            "iter 1730: loss 1.3220, time 478.09ms, mfu 1.69%\n",
            "iter 1740: loss 1.3835, time 470.64ms, mfu 1.70%\n",
            "iter 1750: loss 1.4707, time 457.98ms, mfu 1.70%\n",
            "iter 1760: loss 1.3539, time 460.22ms, mfu 1.71%\n",
            "iter 1770: loss 1.3346, time 470.47ms, mfu 1.71%\n",
            "iter 1780: loss 1.3074, time 477.42ms, mfu 1.71%\n",
            "iter 1790: loss 1.3388, time 464.56ms, mfu 1.71%\n",
            "step 1800: train loss 1.2579, val loss 1.5084\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "iter 1800: loss 1.3682, time 2426.68ms, mfu 1.57%\n",
            "iter 1810: loss 1.3603, time 466.03ms, mfu 1.59%\n",
            "iter 1820: loss 1.2976, time 477.09ms, mfu 1.60%\n",
            "iter 1830: loss 1.3216, time 451.27ms, mfu 1.62%\n",
            "iter 1840: loss 1.3304, time 465.63ms, mfu 1.63%\n",
            "iter 1850: loss 1.3083, time 454.96ms, mfu 1.65%\n",
            "iter 1860: loss 1.3031, time 456.84ms, mfu 1.66%\n",
            "iter 1870: loss 1.2866, time 462.95ms, mfu 1.67%\n",
            "iter 1880: loss 1.3676, time 460.44ms, mfu 1.68%\n",
            "iter 1890: loss 1.3481, time 466.87ms, mfu 1.68%\n",
            "iter 1900: loss 1.2597, time 467.16ms, mfu 1.69%\n",
            "iter 1910: loss 1.2574, time 467.74ms, mfu 1.69%\n",
            "iter 1920: loss 1.3016, time 478.35ms, mfu 1.69%\n",
            "iter 1930: loss 1.3091, time 467.38ms, mfu 1.69%\n",
            "iter 1940: loss 1.3869, time 458.90ms, mfu 1.70%\n",
            "iter 1950: loss 1.3357, time 482.94ms, mfu 1.70%\n",
            "iter 1960: loss 1.3260, time 472.59ms, mfu 1.70%\n",
            "iter 1970: loss 1.3708, time 452.93ms, mfu 1.71%\n",
            "iter 1980: loss 1.3207, time 459.74ms, mfu 1.71%\n",
            "iter 1990: loss 1.2834, time 457.89ms, mfu 1.72%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n",
            "\n",
            "=== Experiment 32/32: b128_L6_H8_E256_BS16_MI2000_D20_s32 ===\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
            "Overriding config with b128_L6_H8_E256_BS16_MI2000_D20_s32.py:\n",
            "\n",
            "out_dir = \"/content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\"\n",
            "dataset = \"shakespeare_char\"\n",
            "eval_interval = 200\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "\n",
            "batch_size = 16\n",
            "block_size = 128\n",
            "n_layer = 6\n",
            "n_head = 8\n",
            "n_embd = 256\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 3e-4\n",
            "max_iters = 2000\n",
            "lr_decay_iters = 2000\n",
            "\n",
            "seed = 32\n",
            "device = \"cuda\"\n",
            "\n",
            "num_workers = 0\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 81,920\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 4.74M\n",
            "num decayed parameter tensors: 26, with 4,768,000 parameters\n",
            "num non-decayed parameter tensors: 13, with 3,328 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.2258, val loss 4.2227\n",
            "iter 0: loss 4.2227, time 2611.68ms, mfu -100.00%\n",
            "iter 10: loss 4.1669, time 462.17ms, mfu 1.75%\n",
            "iter 20: loss 4.0145, time 451.48ms, mfu 1.75%\n",
            "iter 30: loss 3.8159, time 469.39ms, mfu 1.75%\n",
            "iter 40: loss 3.6206, time 455.94ms, mfu 1.75%\n",
            "iter 50: loss 3.4798, time 451.63ms, mfu 1.76%\n",
            "iter 60: loss 3.4465, time 452.16ms, mfu 1.76%\n",
            "iter 70: loss 3.3517, time 466.48ms, mfu 1.76%\n",
            "iter 80: loss 3.2321, time 465.48ms, mfu 1.75%\n",
            "iter 90: loss 3.1633, time 450.82ms, mfu 1.76%\n",
            "iter 100: loss 3.0379, time 452.31ms, mfu 1.76%\n",
            "iter 110: loss 3.0553, time 473.81ms, mfu 1.76%\n",
            "iter 120: loss 2.9152, time 453.69ms, mfu 1.76%\n",
            "iter 130: loss 2.9047, time 472.21ms, mfu 1.75%\n",
            "iter 140: loss 2.8847, time 455.18ms, mfu 1.76%\n",
            "iter 150: loss 2.8315, time 452.19ms, mfu 1.76%\n",
            "iter 160: loss 2.8152, time 453.33ms, mfu 1.76%\n",
            "iter 170: loss 2.8206, time 464.27ms, mfu 1.76%\n",
            "iter 180: loss 2.7650, time 463.67ms, mfu 1.76%\n",
            "iter 190: loss 2.7791, time 476.38ms, mfu 1.75%\n",
            "step 200: train loss 2.6861, val loss 2.6900\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 200: loss 2.7433, time 2342.64ms, mfu 1.61%\n",
            "iter 210: loss 2.6892, time 468.73ms, mfu 1.62%\n",
            "iter 220: loss 2.6454, time 479.70ms, mfu 1.63%\n",
            "iter 230: loss 2.6681, time 460.11ms, mfu 1.64%\n",
            "iter 240: loss 2.7008, time 460.10ms, mfu 1.65%\n",
            "iter 250: loss 2.5769, time 454.93ms, mfu 1.67%\n",
            "iter 260: loss 2.6252, time 473.20ms, mfu 1.67%\n",
            "iter 270: loss 2.5501, time 458.26ms, mfu 1.68%\n",
            "iter 280: loss 2.5747, time 450.33ms, mfu 1.69%\n",
            "iter 290: loss 2.5843, time 460.62ms, mfu 1.70%\n",
            "iter 300: loss 2.5351, time 481.46ms, mfu 1.70%\n",
            "iter 310: loss 2.5251, time 451.43ms, mfu 1.71%\n",
            "iter 320: loss 2.5243, time 468.77ms, mfu 1.71%\n",
            "iter 330: loss 2.4861, time 480.74ms, mfu 1.70%\n",
            "iter 340: loss 2.4665, time 472.25ms, mfu 1.71%\n",
            "iter 350: loss 2.5387, time 470.40ms, mfu 1.71%\n",
            "iter 360: loss 2.4524, time 458.02ms, mfu 1.71%\n",
            "iter 370: loss 2.5176, time 456.26ms, mfu 1.72%\n",
            "iter 380: loss 2.4620, time 453.56ms, mfu 1.72%\n",
            "iter 390: loss 2.4737, time 450.77ms, mfu 1.73%\n",
            "step 400: train loss 2.3964, val loss 2.4033\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 400: loss 2.4753, time 2380.07ms, mfu 1.59%\n",
            "iter 410: loss 2.3730, time 453.52ms, mfu 1.61%\n",
            "iter 420: loss 2.4129, time 458.54ms, mfu 1.63%\n",
            "iter 430: loss 2.4636, time 459.19ms, mfu 1.64%\n",
            "iter 440: loss 2.4625, time 456.80ms, mfu 1.65%\n",
            "iter 450: loss 2.3897, time 473.27ms, mfu 1.66%\n",
            "iter 460: loss 2.4520, time 453.82ms, mfu 1.67%\n",
            "iter 470: loss 2.3395, time 465.09ms, mfu 1.68%\n",
            "iter 480: loss 2.3121, time 463.92ms, mfu 1.68%\n",
            "iter 490: loss 2.3343, time 486.45ms, mfu 1.68%\n",
            "iter 500: loss 2.3285, time 460.38ms, mfu 1.69%\n",
            "iter 510: loss 2.3324, time 470.38ms, mfu 1.69%\n",
            "iter 520: loss 2.3469, time 459.88ms, mfu 1.70%\n",
            "iter 530: loss 2.3834, time 460.31ms, mfu 1.70%\n",
            "iter 540: loss 2.2313, time 481.87ms, mfu 1.70%\n",
            "iter 550: loss 2.3022, time 457.86ms, mfu 1.71%\n",
            "iter 560: loss 2.3199, time 449.05ms, mfu 1.72%\n",
            "iter 570: loss 2.2938, time 453.40ms, mfu 1.72%\n",
            "iter 580: loss 2.2958, time 453.50ms, mfu 1.73%\n",
            "iter 590: loss 2.2337, time 451.38ms, mfu 1.74%\n",
            "step 600: train loss 2.1652, val loss 2.1971\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 600: loss 2.1887, time 2354.76ms, mfu 1.60%\n",
            "iter 610: loss 2.2157, time 463.64ms, mfu 1.61%\n",
            "iter 620: loss 2.2118, time 469.29ms, mfu 1.62%\n",
            "iter 630: loss 2.2432, time 460.89ms, mfu 1.64%\n",
            "iter 640: loss 2.1667, time 467.32ms, mfu 1.65%\n",
            "iter 650: loss 2.1739, time 473.75ms, mfu 1.65%\n",
            "iter 660: loss 2.1814, time 463.77ms, mfu 1.66%\n",
            "iter 670: loss 2.1739, time 472.27ms, mfu 1.67%\n",
            "iter 680: loss 2.1863, time 458.52ms, mfu 1.68%\n",
            "iter 690: loss 2.1107, time 468.40ms, mfu 1.68%\n",
            "iter 700: loss 2.1201, time 465.50ms, mfu 1.69%\n",
            "iter 710: loss 2.1601, time 463.51ms, mfu 1.69%\n",
            "iter 720: loss 2.1378, time 468.51ms, mfu 1.70%\n",
            "iter 730: loss 2.0837, time 472.05ms, mfu 1.70%\n",
            "iter 740: loss 2.1306, time 454.55ms, mfu 1.71%\n",
            "iter 750: loss 2.0954, time 456.23ms, mfu 1.71%\n",
            "iter 760: loss 2.0927, time 467.85ms, mfu 1.71%\n",
            "iter 770: loss 2.0368, time 460.39ms, mfu 1.72%\n",
            "iter 780: loss 2.0211, time 466.73ms, mfu 1.72%\n",
            "iter 790: loss 2.0707, time 454.25ms, mfu 1.73%\n",
            "step 800: train loss 1.9201, val loss 2.0066\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 800: loss 1.9936, time 2334.16ms, mfu 1.59%\n",
            "iter 810: loss 1.9743, time 455.01ms, mfu 1.61%\n",
            "iter 820: loss 2.0296, time 457.66ms, mfu 1.62%\n",
            "iter 830: loss 2.0007, time 478.47ms, mfu 1.63%\n",
            "iter 840: loss 2.0100, time 450.41ms, mfu 1.65%\n",
            "iter 850: loss 1.9532, time 467.18ms, mfu 1.65%\n",
            "iter 860: loss 2.0312, time 467.53ms, mfu 1.66%\n",
            "iter 870: loss 1.9624, time 461.37ms, mfu 1.67%\n",
            "iter 880: loss 1.8524, time 475.88ms, mfu 1.67%\n",
            "iter 890: loss 1.8881, time 471.70ms, mfu 1.68%\n",
            "iter 900: loss 1.9291, time 464.01ms, mfu 1.68%\n",
            "iter 910: loss 1.8958, time 466.40ms, mfu 1.69%\n",
            "iter 920: loss 1.9011, time 495.50ms, mfu 1.68%\n",
            "iter 930: loss 1.8779, time 459.36ms, mfu 1.69%\n",
            "iter 940: loss 1.8457, time 488.64ms, mfu 1.69%\n",
            "iter 950: loss 1.9564, time 467.81ms, mfu 1.69%\n",
            "iter 960: loss 1.9139, time 452.47ms, mfu 1.70%\n",
            "iter 970: loss 1.8041, time 456.96ms, mfu 1.71%\n",
            "iter 980: loss 1.9006, time 460.69ms, mfu 1.71%\n",
            "iter 990: loss 1.8531, time 462.32ms, mfu 1.72%\n",
            "step 1000: train loss 1.7168, val loss 1.8723\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1000: loss 1.8738, time 2407.92ms, mfu 1.58%\n",
            "iter 1010: loss 1.7951, time 467.63ms, mfu 1.59%\n",
            "iter 1020: loss 1.8460, time 463.44ms, mfu 1.61%\n",
            "iter 1030: loss 1.7767, time 464.54ms, mfu 1.62%\n",
            "iter 1040: loss 1.8393, time 466.29ms, mfu 1.63%\n",
            "iter 1050: loss 1.8064, time 463.75ms, mfu 1.64%\n",
            "iter 1060: loss 1.8997, time 456.60ms, mfu 1.66%\n",
            "iter 1070: loss 1.8522, time 453.42ms, mfu 1.67%\n",
            "iter 1080: loss 1.7390, time 456.84ms, mfu 1.68%\n",
            "iter 1090: loss 1.7346, time 470.48ms, mfu 1.68%\n",
            "iter 1100: loss 1.7557, time 456.98ms, mfu 1.69%\n",
            "iter 1110: loss 1.7098, time 453.94ms, mfu 1.70%\n",
            "iter 1120: loss 1.7175, time 464.80ms, mfu 1.70%\n",
            "iter 1130: loss 1.7511, time 461.99ms, mfu 1.71%\n",
            "iter 1140: loss 1.7508, time 461.48ms, mfu 1.71%\n",
            "iter 1150: loss 1.7553, time 466.39ms, mfu 1.72%\n",
            "iter 1160: loss 1.7510, time 463.05ms, mfu 1.72%\n",
            "iter 1170: loss 1.7149, time 463.09ms, mfu 1.72%\n",
            "iter 1180: loss 1.6485, time 488.63ms, mfu 1.71%\n",
            "iter 1190: loss 1.6501, time 467.74ms, mfu 1.72%\n",
            "step 1200: train loss 1.5665, val loss 1.7536\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1200: loss 1.6431, time 2349.68ms, mfu 1.58%\n",
            "iter 1210: loss 1.6628, time 452.61ms, mfu 1.60%\n",
            "iter 1220: loss 1.6466, time 464.90ms, mfu 1.61%\n",
            "iter 1230: loss 1.6305, time 470.70ms, mfu 1.62%\n",
            "iter 1240: loss 1.7300, time 463.10ms, mfu 1.64%\n",
            "iter 1250: loss 1.6857, time 462.42ms, mfu 1.65%\n",
            "iter 1260: loss 1.6354, time 477.41ms, mfu 1.65%\n",
            "iter 1270: loss 1.6594, time 485.18ms, mfu 1.65%\n",
            "iter 1280: loss 1.6690, time 459.42ms, mfu 1.66%\n",
            "iter 1290: loss 1.6924, time 479.01ms, mfu 1.67%\n",
            "iter 1300: loss 1.6183, time 463.38ms, mfu 1.67%\n",
            "iter 1310: loss 1.6986, time 463.29ms, mfu 1.68%\n",
            "iter 1320: loss 1.5924, time 469.58ms, mfu 1.69%\n",
            "iter 1330: loss 1.6116, time 462.35ms, mfu 1.69%\n",
            "iter 1340: loss 1.5998, time 457.56ms, mfu 1.70%\n",
            "iter 1350: loss 1.6186, time 458.31ms, mfu 1.71%\n",
            "iter 1360: loss 1.6004, time 450.57ms, mfu 1.71%\n",
            "iter 1370: loss 1.5795, time 477.00ms, mfu 1.71%\n",
            "iter 1380: loss 1.6207, time 464.25ms, mfu 1.72%\n",
            "iter 1390: loss 1.6168, time 451.64ms, mfu 1.72%\n",
            "step 1400: train loss 1.4697, val loss 1.6704\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1400: loss 1.6173, time 2358.65ms, mfu 1.58%\n",
            "iter 1410: loss 1.5627, time 459.41ms, mfu 1.60%\n",
            "iter 1420: loss 1.6136, time 450.54ms, mfu 1.62%\n",
            "iter 1430: loss 1.5425, time 470.93ms, mfu 1.63%\n",
            "iter 1440: loss 1.6379, time 457.57ms, mfu 1.64%\n",
            "iter 1450: loss 1.5881, time 479.93ms, mfu 1.65%\n",
            "iter 1460: loss 1.5736, time 469.53ms, mfu 1.66%\n",
            "iter 1470: loss 1.5783, time 466.63ms, mfu 1.66%\n",
            "iter 1480: loss 1.5061, time 490.80ms, mfu 1.66%\n",
            "iter 1490: loss 1.5169, time 458.49ms, mfu 1.67%\n",
            "iter 1500: loss 1.4920, time 462.68ms, mfu 1.68%\n",
            "iter 1510: loss 1.4668, time 469.76ms, mfu 1.68%\n",
            "iter 1520: loss 1.5839, time 468.18ms, mfu 1.69%\n",
            "iter 1530: loss 1.4757, time 454.27ms, mfu 1.70%\n",
            "iter 1540: loss 1.5023, time 474.15ms, mfu 1.70%\n",
            "iter 1550: loss 1.5179, time 481.43ms, mfu 1.70%\n",
            "iter 1560: loss 1.5350, time 463.62ms, mfu 1.70%\n",
            "iter 1570: loss 1.5598, time 459.97ms, mfu 1.71%\n",
            "iter 1580: loss 1.4512, time 464.49ms, mfu 1.71%\n",
            "iter 1590: loss 1.4495, time 454.76ms, mfu 1.72%\n",
            "step 1600: train loss 1.4038, val loss 1.6174\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1600: loss 1.4926, time 2335.32ms, mfu 1.58%\n",
            "iter 1610: loss 1.4328, time 449.64ms, mfu 1.60%\n",
            "iter 1620: loss 1.4991, time 453.59ms, mfu 1.62%\n",
            "iter 1630: loss 1.4377, time 467.82ms, mfu 1.63%\n",
            "iter 1640: loss 1.5256, time 450.83ms, mfu 1.65%\n",
            "iter 1650: loss 1.4859, time 461.92ms, mfu 1.66%\n",
            "iter 1660: loss 1.4575, time 456.29ms, mfu 1.67%\n",
            "iter 1670: loss 1.4683, time 459.74ms, mfu 1.68%\n",
            "iter 1680: loss 1.5192, time 474.49ms, mfu 1.68%\n",
            "iter 1690: loss 1.4256, time 471.90ms, mfu 1.68%\n",
            "iter 1700: loss 1.3849, time 481.78ms, mfu 1.68%\n",
            "iter 1710: loss 1.4487, time 454.04ms, mfu 1.69%\n",
            "iter 1720: loss 1.4341, time 453.89ms, mfu 1.70%\n",
            "iter 1730: loss 1.4201, time 510.78ms, mfu 1.69%\n",
            "iter 1740: loss 1.4795, time 473.22ms, mfu 1.69%\n",
            "iter 1750: loss 1.5706, time 455.25ms, mfu 1.70%\n",
            "iter 1760: loss 1.4566, time 459.09ms, mfu 1.71%\n",
            "iter 1770: loss 1.4365, time 449.05ms, mfu 1.72%\n",
            "iter 1780: loss 1.3804, time 463.64ms, mfu 1.72%\n",
            "iter 1790: loss 1.4429, time 461.73ms, mfu 1.72%\n",
            "step 1800: train loss 1.3475, val loss 1.5713\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_results/b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "iter 1800: loss 1.4845, time 2378.46ms, mfu 1.58%\n",
            "iter 1810: loss 1.4415, time 456.92ms, mfu 1.60%\n",
            "iter 1820: loss 1.4051, time 465.81ms, mfu 1.62%\n",
            "iter 1830: loss 1.4108, time 472.70ms, mfu 1.62%\n",
            "iter 1840: loss 1.4213, time 463.25ms, mfu 1.64%\n",
            "iter 1850: loss 1.4219, time 455.25ms, mfu 1.65%\n",
            "iter 1860: loss 1.4103, time 457.22ms, mfu 1.66%\n",
            "iter 1870: loss 1.3715, time 481.18ms, mfu 1.66%\n",
            "iter 1880: loss 1.4573, time 458.69ms, mfu 1.67%\n",
            "iter 1890: loss 1.4647, time 458.61ms, mfu 1.68%\n",
            "iter 1900: loss 1.3525, time 476.22ms, mfu 1.68%\n",
            "iter 1910: loss 1.3574, time 472.98ms, mfu 1.69%\n",
            "iter 1920: loss 1.4060, time 465.00ms, mfu 1.69%\n",
            "iter 1930: loss 1.4179, time 462.95ms, mfu 1.70%\n",
            "iter 1940: loss 1.4747, time 464.37ms, mfu 1.70%\n",
            "iter 1950: loss 1.4236, time 457.40ms, mfu 1.71%\n",
            "iter 1960: loss 1.4240, time 475.73ms, mfu 1.71%\n",
            "iter 1970: loss 1.4564, time 477.78ms, mfu 1.71%\n",
            "iter 1980: loss 1.4181, time 474.97ms, mfu 1.71%\n",
            "iter 1990: loss 1.3774, time 455.22ms, mfu 1.71%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/nanoGPT/train.py\", line 258, in <module>\n",
            "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nanoGPT/train.py\", line 239, in get_lr\n",
            "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
            "                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/nanoGPT_results\"\n",
        "samples_dir = os.path.join(base_dir, \"samples\")\n",
        "\n",
        "os.makedirs(samples_dir, exist_ok=True)\n",
        "\n",
        "# iterate over each experiment folder\n",
        "exp_folders = sorted([\n",
        "    d for d in os.listdir(base_dir)\n",
        "    if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"b\")\n",
        "])\n",
        "\n",
        "print(f\"Found {len(exp_folders)} experiment folders.\")\n",
        "\n",
        "for i, exp in enumerate(exp_folders, 1):\n",
        "    exp_path = os.path.join(base_dir, exp)\n",
        "    ckpt_path = os.path.join(exp_path, \"ckpt.pt\")\n",
        "\n",
        "    if not os.path.isfile(ckpt_path):\n",
        "        print(f\"Skipping {exp} (no ckpt.pt found)\")\n",
        "        continue\n",
        "\n",
        "    out_sample = os.path.join(samples_dir, f\"{exp}_sample.txt\")\n",
        "\n",
        "    print(f\"[{i}/{len(exp_folders)}] Generating sample for {exp}\")\n",
        "\n",
        "    cmd = (\n",
        "        f\"python /content/nanoGPT/sample.py \"\n",
        "        f\"--out_dir={exp_path} \"\n",
        "        f\"--start=' ' \"\n",
        "        f\"--num_samples=3 \"\n",
        "        f\"--max_new_tokens=200 \"\n",
        "        f\"> '{out_sample}'\"\n",
        "    )\n",
        "    subprocess.run(cmd, shell=True)\n",
        "\n",
        "print(\" All samples generated and stored in:\", samples_dir)"
      ],
      "metadata": {
        "id": "P11EbUZNwEak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3928eed8-67f5-40dc-83cd-81bbc1705011"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32 experiment folders.\n",
            "[1/32] Generating sample for b128_L6_H4_E128_BS16_MI1000_D10_s5\n",
            "[2/32] Generating sample for b128_L6_H4_E128_BS16_MI1000_D20_s6\n",
            "[3/32] Generating sample for b128_L6_H4_E128_BS16_MI2000_D10_s7\n",
            "[4/32] Generating sample for b128_L6_H4_E128_BS16_MI2000_D20_s8\n",
            "[5/32] Generating sample for b128_L6_H4_E128_BS8_MI1000_D10_s1\n",
            "[6/32] Generating sample for b128_L6_H4_E128_BS8_MI1000_D20_s2\n",
            "[7/32] Generating sample for b128_L6_H4_E128_BS8_MI2000_D10_s3\n",
            "[8/32] Generating sample for b128_L6_H4_E128_BS8_MI2000_D20_s4\n",
            "[9/32] Generating sample for b128_L6_H4_E256_BS16_MI1000_D10_s13\n",
            "[10/32] Generating sample for b128_L6_H4_E256_BS16_MI1000_D20_s14\n",
            "[11/32] Generating sample for b128_L6_H4_E256_BS16_MI2000_D10_s15\n",
            "[12/32] Generating sample for b128_L6_H4_E256_BS16_MI2000_D20_s16\n",
            "[13/32] Generating sample for b128_L6_H4_E256_BS8_MI1000_D10_s9\n",
            "[14/32] Generating sample for b128_L6_H4_E256_BS8_MI1000_D20_s10\n",
            "[15/32] Generating sample for b128_L6_H4_E256_BS8_MI2000_D10_s11\n",
            "[16/32] Generating sample for b128_L6_H4_E256_BS8_MI2000_D20_s12\n",
            "[17/32] Generating sample for b128_L6_H8_E128_BS16_MI1000_D10_s21\n",
            "[18/32] Generating sample for b128_L6_H8_E128_BS16_MI1000_D20_s22\n",
            "[19/32] Generating sample for b128_L6_H8_E128_BS16_MI2000_D10_s23\n",
            "[20/32] Generating sample for b128_L6_H8_E128_BS16_MI2000_D20_s24\n",
            "[21/32] Generating sample for b128_L6_H8_E128_BS8_MI1000_D10_s17\n",
            "[22/32] Generating sample for b128_L6_H8_E128_BS8_MI1000_D20_s18\n",
            "[23/32] Generating sample for b128_L6_H8_E128_BS8_MI2000_D10_s19\n",
            "[24/32] Generating sample for b128_L6_H8_E128_BS8_MI2000_D20_s20\n",
            "[25/32] Generating sample for b128_L6_H8_E256_BS16_MI1000_D10_s29\n",
            "[26/32] Generating sample for b128_L6_H8_E256_BS16_MI1000_D20_s30\n",
            "[27/32] Generating sample for b128_L6_H8_E256_BS16_MI2000_D10_s31\n",
            "[28/32] Generating sample for b128_L6_H8_E256_BS16_MI2000_D20_s32\n",
            "[29/32] Generating sample for b128_L6_H8_E256_BS8_MI1000_D10_s25\n",
            "[30/32] Generating sample for b128_L6_H8_E256_BS8_MI1000_D20_s26\n",
            "[31/32] Generating sample for b128_L6_H8_E256_BS8_MI2000_D10_s27\n",
            "[32/32] Generating sample for b128_L6_H8_E256_BS8_MI2000_D20_s28\n",
            " All samples generated and stored in: /content/drive/MyDrive/nanoGPT_results/samples\n"
          ]
        }
      ]
    }
  ]
}